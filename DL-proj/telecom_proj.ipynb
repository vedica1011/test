{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot\n",
    "from keras.models import load_model\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wifi_1</th>\n",
       "      <th>wifi_2</th>\n",
       "      <th>wifi_3</th>\n",
       "      <th>wifi_4</th>\n",
       "      <th>wifi_5</th>\n",
       "      <th>wifi_6</th>\n",
       "      <th>wifi_7</th>\n",
       "      <th>Room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-64</td>\n",
       "      <td>-56</td>\n",
       "      <td>-61</td>\n",
       "      <td>-66</td>\n",
       "      <td>-71</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-68</td>\n",
       "      <td>-57</td>\n",
       "      <td>-61</td>\n",
       "      <td>-65</td>\n",
       "      <td>-71</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-63</td>\n",
       "      <td>-60</td>\n",
       "      <td>-60</td>\n",
       "      <td>-67</td>\n",
       "      <td>-76</td>\n",
       "      <td>-85</td>\n",
       "      <td>-84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-61</td>\n",
       "      <td>-60</td>\n",
       "      <td>-68</td>\n",
       "      <td>-62</td>\n",
       "      <td>-77</td>\n",
       "      <td>-90</td>\n",
       "      <td>-80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-63</td>\n",
       "      <td>-65</td>\n",
       "      <td>-60</td>\n",
       "      <td>-63</td>\n",
       "      <td>-77</td>\n",
       "      <td>-81</td>\n",
       "      <td>-87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wifi_1  wifi_2  wifi_3  wifi_4  wifi_5  wifi_6  wifi_7  Room\n",
       "0     -64     -56     -61     -66     -71     -82     -81     1\n",
       "1     -68     -57     -61     -65     -71     -85     -85     1\n",
       "2     -63     -60     -60     -67     -76     -85     -84     1\n",
       "3     -61     -60     -68     -62     -77     -90     -80     1\n",
       "4     -63     -65     -60     -63     -77     -81     -87     1"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe1 = pd.read_table('wifi_localization.txt', delim_whitespace=True, names=('wifi_1','wifi_2','wifi_3','wifi_4','wifi_5','wifi_6','wifi_7','Room'))\n",
    "dataframe1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 8 columns):\n",
      "wifi_1    2000 non-null int64\n",
      "wifi_2    2000 non-null int64\n",
      "wifi_3    2000 non-null int64\n",
      "wifi_4    2000 non-null int64\n",
      "wifi_5    2000 non-null int64\n",
      "wifi_6    2000 non-null int64\n",
      "wifi_7    2000 non-null int64\n",
      "Room      2000 non-null int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 125.1 KB\n"
     ]
    }
   ],
   "source": [
    "dataframe1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe1['Room'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1['Room']=dataframe1['Room'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split Training and Testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We specify this so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "\n",
    "X , y = dataframe1.loc[:, dataframe1.columns != 'Room'] ,dataframe1.loc[:, dataframe1.columns == 'Room']\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, random_state = 0,train_size = 0.7, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y.Room)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=np.array(trainX)\n",
    "trainy=np.array(trainy)\n",
    "testy=np.array(testy)\n",
    "testX=np.array(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 7) (600, 7)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape,testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(trainy)\n",
    "trainy = encoder.transform(trainy)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "trainy = np_utils.to_categorical(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(testy)\n",
    "testy = encoder.transform(testy)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "testy = np_utils.to_categorical(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(340, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model with SGD\n",
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('best_model_mlp.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/200\n",
      "1400/1400 [==============================] - 0s 320us/step - loss: 2.5381 - accuracy: 0.2571 - val_loss: 1.3873 - val_accuracy: 0.2317\n",
      "Epoch 2/200\n",
      "1400/1400 [==============================] - 0s 89us/step - loss: 1.3866 - accuracy: 0.2579 - val_loss: 1.3879 - val_accuracy: 0.2317\n",
      "Epoch 3/200\n",
      " 640/1400 [============>.................] - ETA: 0s - loss: 1.3885 - accuracy: 0.2234"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 0s 114us/step - loss: 1.3874 - accuracy: 0.2393 - val_loss: 1.3880 - val_accuracy: 0.2317\n",
      "Epoch 4/200\n",
      "1400/1400 [==============================] - 0s 122us/step - loss: 1.3874 - accuracy: 0.2579 - val_loss: 1.3883 - val_accuracy: 0.2317\n",
      "Epoch 5/200\n",
      "1400/1400 [==============================] - 0s 121us/step - loss: 1.3868 - accuracy: 0.2450 - val_loss: 1.3864 - val_accuracy: 0.2517\n",
      "Epoch 6/200\n",
      "1400/1400 [==============================] - 0s 120us/step - loss: 1.3867 - accuracy: 0.2557 - val_loss: 1.3873 - val_accuracy: 0.2317\n",
      "Epoch 7/200\n",
      "1400/1400 [==============================] - 0s 131us/step - loss: 1.3868 - accuracy: 0.2579 - val_loss: 1.3880 - val_accuracy: 0.2317\n",
      "Epoch 8/200\n",
      "1400/1400 [==============================] - 0s 116us/step - loss: 1.3865 - accuracy: 0.2579 - val_loss: 1.3876 - val_accuracy: 0.2317\n",
      "Epoch 9/200\n",
      "1400/1400 [==============================] - 0s 119us/step - loss: 1.3869 - accuracy: 0.2357 - val_loss: 1.3870 - val_accuracy: 0.2317\n",
      "Epoch 10/200\n",
      "1400/1400 [==============================] - 0s 113us/step - loss: 1.3871 - accuracy: 0.2579 - val_loss: 1.3875 - val_accuracy: 0.2317\n",
      "Epoch 11/200\n",
      "1400/1400 [==============================] - 0s 88us/step - loss: 1.3870 - accuracy: 0.2350 - val_loss: 1.3868 - val_accuracy: 0.2317\n",
      "Epoch 12/200\n",
      "1400/1400 [==============================] - 0s 113us/step - loss: 1.3871 - accuracy: 0.2579 - val_loss: 1.3878 - val_accuracy: 0.2317\n",
      "Epoch 13/200\n",
      "1400/1400 [==============================] - 0s 110us/step - loss: 1.3870 - accuracy: 0.2579 - val_loss: 1.3874 - val_accuracy: 0.2317\n",
      "Epoch 14/200\n",
      "1400/1400 [==============================] - 0s 104us/step - loss: 1.3866 - accuracy: 0.2579 - val_loss: 1.3871 - val_accuracy: 0.2317\n",
      "Epoch 15/200\n",
      "1400/1400 [==============================] - 0s 117us/step - loss: 1.3869 - accuracy: 0.2579 - val_loss: 1.3882 - val_accuracy: 0.2317\n",
      "Epoch 16/200\n",
      "1400/1400 [==============================] - 0s 119us/step - loss: 1.3871 - accuracy: 0.2429 - val_loss: 1.3873 - val_accuracy: 0.2317\n",
      "Epoch 17/200\n",
      "1400/1400 [==============================] - 0s 123us/step - loss: 1.3870 - accuracy: 0.2579 - val_loss: 1.3878 - val_accuracy: 0.2317\n",
      "Epoch 18/200\n",
      "1400/1400 [==============================] - 0s 117us/step - loss: 1.3870 - accuracy: 0.2471 - val_loss: 1.3871 - val_accuracy: 0.2317\n",
      "Epoch 19/200\n",
      "1400/1400 [==============================] - 0s 119us/step - loss: 1.3872 - accuracy: 0.2579 - val_loss: 1.3877 - val_accuracy: 0.2317\n",
      "Epoch 20/200\n",
      "1400/1400 [==============================] - 0s 126us/step - loss: 1.3874 - accuracy: 0.2321 - val_loss: 1.3871 - val_accuracy: 0.2317\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=1, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "#saved_model = load_model('best_model_mlp.h5')\n",
    "saved_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.258, Test: 0.232\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = saved_model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAax0lEQVR4nO3dfXBc9X3v8fd3V1rbWqm2tFKosaF2Mym9eQQiCFxo60wbwOQWQtPLNCl56oPTmZQxMyFjSCekmf6TNFOGoS14SOOhvSG0aYCQNqZxuGMuyRBIZdcBPyU2Da2FHSz8hOVHafd7/zhnpfVqV1pZ+6D9nc9rRqOz5/x2z1c/nf3o6KdzfjJ3R0RE2l+q1QWIiEh9KNBFRAKhQBcRCYQCXUQkEAp0EZFAdLRqx/39/b5ixYpW7V5EpC1t2bLldXcfqLStZYG+YsUKhoaGWrV7EZG2ZGb/VW2bhlxERAKhQBcRCYQCXUQkEC0bQxcROR9jY2MMDw9z+vTpVpfSUAsXLmT58uV0dnbW/BwFuoi0leHhYXp6elixYgVm1upyGsLdOXToEMPDw6xcubLm52nIRUTayunTp8nlcsGGOYCZkcvlZv1biAJdRNpOyGFedD5fY9sF+k9+fpwvf3c3R06cbXUpIiLzStsF+s9eP8Hfbn6ZV4+eanUpIpJAR48e5YEHHpj182688UaOHj3agIomtV2g92UzABzWGbqItEC1QM/n89M+b+PGjSxZsqRRZQFteJWLAl1EWumuu+7i5Zdf5tJLL6Wzs5Pu7m6WLl3Ktm3b2LlzJx/4wAfYt28fp0+fZu3ataxZswaYnO5kdHSU1atXc+211/Lcc8+xbNkynnzySRYtWjTn2tou0HMKdBGJfeFfdrBz/xt1fc23XvgLfP6331Z1+xe/+EW2b9/Otm3beOaZZ3j/+9/P9u3bJy4v3LBhA319fZw6dYorrriCD37wg+RyuXNeY8+ePTz66KN85Stf4dZbb+Wxxx7jtttum3PtbRfoixd1kjIFuojMD1deeeU514rff//9PPHEEwDs27ePPXv2TAn0lStXcumllwLw7ne/m1deeaUutbRdoKdSRm9XhkMKdJHEm+5Mulmy2ezE8jPPPMPTTz/ND3/4Q7q6uli1alXFa8kXLFgwsZxOpzl1qj4XebTdH0UhGkc/fOJMq8sQkQTq6enh+PHjFbcdO3aM3t5eurq62L17N88//3xTa2u7M3SIAv3IibFWlyEiCZTL5bjmmmt4+9vfzqJFi7jgggsmtt1www2sX7+ed77znVxyySVcddVVTa2tLQM9153hJz+v/BNSRKTRvv71r1dcv2DBAp566qmK24rj5P39/Wzfvn1i/Z133lm3utpyyKW3K6M/ioqIlGnLQM9lMxw9NUa+4K0uRURk3mjLQO/LZnCHoyd1li4iUtSegd4dXfKjYRcRkUntGehd0d2iuhZdRGRSewa6bv8XEZmiLQM9161AF5HWON/pcwHuu+8+Tp48WeeKJrVloPd2KdBFpDXmc6C35Y1FmY4UPQs6FOgi0nSl0+e+733v401vehPf+MY3OHPmDLfccgtf+MIXOHHiBLfeeivDw8Pk83k+97nP8dprr7F//37e+9730t/fz+bNm+teW1sGOkBftyboEkm8p+6Cn79U39f8xXfA6i9W3Vw6fe6mTZv45je/yY9+9CPcnZtuuolnn32WkZERLrzwQr7zne8A0Rwvixcv5t5772Xz5s309/fXt+ZYWw65QHE+FwW6iLTOpk2b2LRpE5dddhmXX345u3fvZs+ePbzjHe/g6aefZt26dXz/+99n8eLFTamnbc/Qc9kMrx6dOi2liCTINGfSzeDu3H333Xzyk5+csm3Lli1s3LiRu+++m+uuu4577rmn4fXMeIZuZheZ2WYz22VmO8xs7TRtrzCzvJn9bn3LnCqaz0VT6IpIc5VOn3v99dezYcMGRkdHAXj11Vc5ePAg+/fvp6uri9tuu40777yTrVu3TnluI9Ryhj4OfNrdt5pZD7DFzL7n7jtLG5lZGvgS8N0G1DlFX3c0QZe7Y2bN2KWIyDnT565evZoPf/jDXH311QB0d3fzta99jb179/KZz3yGVCpFZ2cnDz74IABr1qxh9erVLF26tDV/FHX3A8CBePm4me0ClgE7y5reDjwGXFHvIivJZTOM5Z3RM+P0LOxsxi5FRICp0+euXXvuwMWb3/xmrr/++inPu/3227n99tsbVtes/ihqZiuAy4AXytYvA24B1s/w/DVmNmRmQyMjI7OrtExfVvO5iIiUqjnQzayb6Az8Dncv/zfb9wHr3D0/3Wu4+0PuPujugwMDA7OvtkRfNjor16WLIiKRmq5yMbNOojB/xN0fr9BkEPjHeCy7H7jRzMbd/Vt1q7TMxBn6qAJdJGmS8Lcz99n/v4cZA92iXvsqsMvd762y45Ul7R8G/rWRYQ7RGDrAYc2JLpIoCxcu5NChQ+RyuWBD3d05dOgQCxcunNXzajlDvwb4CPCSmW2L130WuDje8bTj5o2iGRdFkmn58uUMDw8z17/DzXcLFy5k+fLls3pOLVe5/ACo+cegu398VhWcp65MmgUdKQW6SMJ0dnaycuXKmRsmUNve+m9m9GUzHNIYuogI0MaBDvF8LhpDFxEBAgh0XbYoIhJp60DPZTWfi4hIUVsHem82o+vQRURibR3ouWyGE2fznB6b9gZVEZFEaOtAL94tqj+Mioi0faBHNxfp0kURkUACXWfoIiKBBLruFhURafNAz2nIRURkQlsH+uJFnaRMZ+giItDmgZ5KWfTPojWGLiLS3oEO0Ti6bi4SEQkl0DXkIiLS/oGe685wSPO5iIi0f6D3dmU4cnKs1WWIiLRc2wd6Lp4TPV+Y/T9UFREJSdsHel82gzsc1ZUuIpJw7R/o3dEEXfrDqIgkXfsHepdu/xcRgRACXfO5iIgAAQR6rjuez0WBLiIJ1/aB3qshFxERIIBAz3Sk6FnQoUAXkcSbMdDN7CIz22xmu8xsh5mtrdDm983sxfjjOTN7V2PKrayvW7f/i4h01NBmHPi0u281sx5gi5l9z913lrT5GfAb7n7EzFYDDwHvaUC9FWk+FxGRGs7Q3f2Au2+Nl48Du4BlZW2ec/cj8cPngeX1LnQ6uWxGfxQVkcSb1Ri6ma0ALgNemKbZHwJPVXn+GjMbMrOhkZGR2ex6Wr1dGY4o0EUk4WoOdDPrBh4D7nD3N6q0eS9RoK+rtN3dH3L3QXcfHBgYOJ96KyqOobtrPhcRSa6aAt3MOonC/BF3f7xKm3cCfwfc7O6H6lfizHLZDGfzBUbPjDdztyIi80otV7kY8FVgl7vfW6XNxcDjwEfc/af1LXFmfVnN5yIiUstVLtcAHwFeMrNt8brPAhcDuPt64B4gBzwQ5T/j7j5Y/3Ir68t2AlGg/1Iu26zdiojMKzMGurv/ALAZ2vwR8Ef1Kmq2dIYuIhLAnaIQjaGD5nMRkWQLItA146KISCCB3pVJk+lI6Vp0EUm0IALdzHS3qIgkXhCBDprPRUQkqEDXGbqIJFlQga4xdBFJsqACXUMuIpJkwQR6Lpth9Mw4Z8bzrS5FRKQlggl03S0qIkkXUKBPzuciIpJEAQW6ztBFJNkCCnTd/i8iyRZMoE9M0DWqQBeRZAom0Bcv6iRlcOSkAl1EkimYQE+ljN4u3S0qIskVTKBDfHORhlxEJKHCC3SdoYtIQoUX6BpDF5GECi/QdYYuIgkVVKDnshmOnDxLvuCtLkVEpOmCCvS+bAZ3OKphFxFJoKACvTe+uUjXootIEgUV6Ll4PhfdLSoiSRRUoGs+FxFJshkD3cwuMrPNZrbLzHaY2doKbczM7jezvWb2opld3phyp5frjudzUaCLSAJ11NBmHPi0u281sx5gi5l9z913lrRZDbwl/ngP8GD8uamWdEVzout/i4pIEs14hu7uB9x9a7x8HNgFLCtrdjPwDx55HlhiZkvrXu0MFnSk6VnQoTN0EUmkWY2hm9kK4DLghbJNy4B9JY+HmRr6TdHXrZuLRCSZag50M+sGHgPucPc3yjdXeMqUu3vMbI2ZDZnZ0MjIyOwqrZHuFhWRpKop0M2skyjMH3H3xys0GQYuKnm8HNhf3sjdH3L3QXcfHBgYOJ96Z9TXpUAXkWSq5SoXA74K7HL3e6s0+zbw0fhql6uAY+5+oI511kxn6CKSVLVc5XIN8BHgJTPbFq/7LHAxgLuvBzYCNwJ7gZPAJ+pfam2KY+juTvSzSEQkGWYMdHf/AZXHyEvbOPCpehU1F7lshrP5AqNnxulZ2NnqckREmiaoO0UBervi+VxOjLW4EhGR5gou0CfvFj3T4kpERJoruEDviyfo0h9GRSRpggv0XFbzuYhIMgUX6BNzoivQRSRhggv0bCZNpiOlIRcRSZzgAt3MyGUzGnIRkcQJLtBBd4uKSDIp0EVEAqFAFxEJhAJdRCQQQQZ6Lpth9Mw4Z8bzrS5FRKRpggz04t2ims9FRJIk0ECPZlnUfC4ikiSBBrrmcxGR5Ak00KPb/xXoIpIkQQZ6ToEuIgkUZKAvXtRJyhToIpIsQQZ6KmX0dmk+FxFJliADHeKbi0YV6CKSHGEH+kkFuogkR9iBriEXEUkQBbqISCCCDfRcNsORk2fJF7zVpYiINEWwgd6XzeAOx05pPhcRSYZgA7134uYizeciIskwY6Cb2QYzO2hm26tsX2xm/2JmPzazHWb2ifqXOXu5eD6XQ7p0UUQSopYz9IeBG6bZ/ilgp7u/C1gF/JWZZeZe2txoPhcRSZoZA93dnwUOT9cE6DEzA7rjtuP1Ke/85brjQNe16CKSEPUYQ/8b4H8A+4GXgLXuXqjU0MzWmNmQmQ2NjIzUYdfVLemK5kTX3aIikhT1CPTrgW3AhcClwN+Y2S9UaujuD7n7oLsPDgwM1GHX1S3oSNOzoEPzuYhIYtQj0D8BPO6RvcDPgF+tw+vOWV+3bi4SkeSoR6D/N/CbAGZ2AXAJ8J91eN0564tvLhIRSYKOmRqY2aNEV6/0m9kw8HmgE8Dd1wN/ATxsZi8BBqxz99cbVvEs9HVlOHDsdKvLEBFpihkD3d0/NMP2/cB1dauojvqyGXbsf6PVZYiINEWwd4rC5Bi6u+ZzEZHwBR3ouWyGs/kCJ87mW12KiEjDBR3ovV3xzUW6Fl1EEiDoQC/eLXpIE3SJSAIEHeh98QRduhZdRJIg6EDPaYIuEUmQoAO9V4EuIgkSdKBnM2kyHSkFuogkQtCBbmbkshlN0CUiiRB0oEM8n4sCXUQSIBGBrjN0EUmCRAS6xtBFJAkU6CIigQg+0HPZDKNnxjkzrvlcRCRswQd68Vr0IyfGWlyJiEhjBR/oxbtFNZ+LiIQu+EDXfC4ikhQJCHTd/i8iyaBAFxEJRPCBvmRRJylToItI+IIP9FTK6O3S3aIiEr7gAx00n4uIJEMiAr1X87mISAIkItBzuv1fRBIgEYGu+VxEJAlmDHQz22BmB81s+zRtVpnZNjPbYWb/r74lzl0um+HoybPkC97qUkREGqaWM/SHgRuqbTSzJcADwE3u/jbgf9entPrpzWYoOBw7pflcRCRcMwa6uz8LHJ6myYeBx939v+P2B+tUW91M3lyk+VxEJFz1GEP/FaDXzJ4xsy1m9tFqDc1sjZkNmdnQyMhIHXZdm1w8n8uhUY2ji0i46hHoHcC7gfcD1wOfM7NfqdTQ3R9y90F3HxwYGKjDrmtTPEM/clKBLiLh6qjDawwDr7v7CeCEmT0LvAv4aR1euy76JqbQVaCLSLjqcYb+JPBrZtZhZl3Ae4BddXjduunNdgJwWEMuIhKwGc/QzexRYBXQb2bDwOeBTgB3X+/uu8zs34AXgQLwd+5e9RLHVljQkaZnQYfO0EUkaDMGurt/qIY2Xwa+XJeKGqSvO6MxdBEJWiLuFAXo7dLdoiIStsQEei6b0WWLIhK0xAS65nMRkdAlJ9C7Mxw+eRZ3zeciImFKTqB3ZTg7XuDE2XyrSxERaYjkBHpxPheNo4tIoBIT6Lnu4t2imqBLRMKUmEDviyfo0rXoIhKq5AR6V3yGriEXEQlUcgK9uzgnugJdRMKUmEDPZtJkOlIKdBEJVmIC3czI6eYiEQlYYgIdNJ+LiIQtUYGe685oCl0RCVaiAl3zuYhIyBIX6EcU6CISqGQFeleG42fGOTOu+VxEJDzJCvT4WvQjJ8ZaXImISP0lKtBzWc3nIiLhSlSgT8znojN0EQlQwgJdZ+giEq5EBrouXRSRECUq0Jcs6iRlCnQRCVOiAj2VMt3+LyLBSlSgg+4WFZFwzRjoZrbBzA6a2fYZ2l1hZnkz+936lVd/vVnN5yIiYarlDP1h4IbpGphZGvgS8N061NRQmkJXREI1Y6C7+7PA4Rma3Q48BhysR1GNpPlcRCRUcx5DN7NlwC3A+rmX03i5bIYjJ89SKHirSxERqauOOrzGfcA6d8+b2bQNzWwNsAbg4osvntte3eOPAhB/9sLkunPWT7Zd2nGcnB/h2Mg+euN/HI2Xh7tP3dfEFo9/GHjJ+pLlKesqt7NUB9bRiaUzkO6EVAeULs/Ql3NW2k/l/Tal7yr0a/RVxHWWf+bc5UptLDX5Qeljq+/XXl5/8XtQXkO9+9sdCnnwfNnnYh8Sf+1M1nJOH6WmX25EHxXyUBg/t9Yp6/JQKEzWnErHNaVLlovr0xWWK5xDVnwv+/TLVPj+nfN4Dt/Tc94LVd4XzT6Oa2Q+JcwqNDJbAfyru7+9wrafAcXK+4GTwBp3/9Z0rzk4OOhDQ0OzrRd2PAH//PHZP6/NjHmaMToYJ824pRmnI/5IkyeN4aQoxB9OumR5cv2569IUsLjtfJcnhWNxxRYvp+LH0QEXPSJuFT2mZH2q/AfzNAo+ua/J/VRftpI+L//cYc3t38k+guJbsfi42HdFxcfpkuOj2cfDuKcmqkpZY39Tzlc8fqL+SHmh5Djy6H1S53rybvE7kPhdGB1n/7H8Nq7943vP6zXNbIu7D1baNuczdHdfWbKjh4mCf9own5P+S+A31jHlbKXiT8ip606cLfD07oOMF6K35cTTSU2cPJhZ9AGkrNgmio6orcXvm5I3i5W+ceI3Vfyc8jcUgHmeVGEMK4yR8nGsMI75OKnCWdKFPOZjWGGctI+TitukJpbzuBUDL02huGxRtLsVD6L4LWuTy27p6OCy9MRBjkUHG2YTr+ukcLPJ9cWInFgu+W2DQnTS5I4Xo8QpaRNHy8RvMQXMIOWOWQFzx8xJuZ/zlit/Cxa/KvMCxHVO1DZRt018HcRfR/S9iB8Xz3TjelLko/0X9xOfhZkXzllX+pmS/RcsjVtp36aix3H/ukXrCyXrKTkemHjNcyMYL/ZrcX0UPnixRib6tbSPJ36Gefm2c9d5ed3FmifWpydqn/waisspUhR/kBZIeWEiqlJewMoep+JYnWjn+fj7luKcHzpmFLx4PBa3R++1AsXvp018iUah5HtXwJwq37NC/J4rrstPHj/FYzr+bSk63lOTj+Pl4hFYeuY/8XrFUw/3ycdecrJR/B6XbOt9y9U0woyBbmaPAquAfjMbBj4PdAK4e/PHzS94a/RxnrLAzdfWrxwRkflixkB39w/V+mLu/vE5VSMiIuctcXeKioiESoEuIhIIBbqISCAU6CIigVCgi4gEQoEuIhIIBbqISCBquvW/ITs2GwH+6zyf3g+8Xsdy6m2+1wfzv0bVNzeqb27mc32/5O4DlTa0LNDnwsyGqs1lMB/M9/pg/teo+uZG9c3NfK+vGg25iIgEQoEuIhKIdg30h1pdwAzme30w/2tUfXOj+uZmvtdXUVuOoYuIyFTteoYuIiJlFOgiIoGY14FuZjeY2U/MbK+Z3VVhu5nZ/fH2F83s8ibWdpGZbTazXWa2w8zWVmizysyOmdm2+OOeZtUX7/8VM3sp3veU//fX4v67pKRftpnZG2Z2R1mbpvefmW0ws4Nmtr1kXZ+Zfc/M9sSfe6s8d9rjtYH1fdnMdsffwyfMbEmV5057PDSwvj83s1dLvo83Vnluq/rvn0pqe8XMtlV5bsP7b87cfV5+AGngZeCXgQzwY+CtZW1uBJ4i+p9eVwEvNLG+pcDl8XIP8NMK9a0i+pd8rerDV4D+aba3rP8qfK9/TnTDREv7D/h14HJge8m6vwTuipfvAr5U5WuY9nhtYH3XAR3x8pcq1VfL8dDA+v4cuLOGY6Al/Ve2/a+Ae1rVf3P9mM9n6FcCe939P939LPCPwM1lbW4G/sEjzwNLzGxpM4pz9wPuvjVePg7sApY1Y9911LL+K/ObwMvufr53DteNuz8LHC5bfTPw9/Hy3wMfqPDUWo7XhtTn7pvcfTx++DywvN77rVWV/qtFy/qvyKJ/HHwr8Gi999ss8znQlwH7Sh4PMzUwa2nTcGa2ArgMeKHC5qvN7Mdm9pSZva2phUX/HXiTmW0xszUVts+L/gN+j+pvolb2X9EF7n4Aoh/kwJsqtJkvffkHRL91VTLT8dBIfxoPCW2oMmQ1H/rv14DX3H1Ple2t7L+azOdAtwrryq+xrKVNQ5lZN/AYcIe7v1G2eSvRMMK7gL8GvtXM2oBr3P1yYDXwKTP79bLt86H/MsBNwD9X2Nzq/puN+dCXfwaMA49UaTLT8dAoDwJvBi4FDhANa5Rref8BH2L6s/NW9V/N5nOgDwMXlTxeDuw/jzYNY2adRGH+iLs/Xr7d3d9w99F4eSPQaWb9zarP3ffHnw8CTxD9Wluqpf0XWw1sdffXyje0uv9KvFYcioo/H6zQptXH4seA/wX8vscDvuVqOB4awt1fc/e8uxeAr1TZb6v7rwP4HeCfqrVpVf/NxnwO9H8H3mJmK+OzuN8Dvl3W5tvAR+OrNa4CjhV/NW60eLztq8Aud7+3SptfjNthZlcS9fehJtWXNbOe4jLRH862lzVrWf+VqHpW1Mr+K/Nt4GPx8seAJyu0qeV4bQgzuwFYB9zk7iertKnleGhUfaV/l7mlyn5b1n+x3wJ2u/twpY2t7L9ZafVfZaf7ILoK46dEf/3+s3jdnwB/Ei8b8Lfx9peAwSbWdi3Rr4QvAtvijxvL6vtTYAfRX+yfB/5nE+v75Xi/P45rmFf9F++/iyigF5esa2n/Ef1wOQCMEZ01/iGQA/4vsCf+3Be3vRDYON3x2qT69hKNPxePw/Xl9VU7HppU3/+Jj68XiUJ66Xzqv3j9w8XjrqRt0/tvrh+69V9EJBDzechFRERmQYEuIhIIBbqISCAU6CIigVCgi4gEQoEuIhIIBbqISCD+P/ex+Mvuywb0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24455766, 0.2503374 , 0.24961333, 0.25549158],\n",
       "       [0.24455766, 0.2503374 , 0.24961333, 0.25549158],\n",
       "       [0.24455766, 0.2503374 , 0.24961333, 0.25549158],\n",
       "       ...,\n",
       "       [0.24455766, 0.2503374 , 0.24961333, 0.25549158],\n",
       "       [0.24455766, 0.2503374 , 0.24961333, 0.25549158],\n",
       "       [0.24455766, 0.2503374 , 0.24961333, 0.25549158]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predicted=saved_model.predict(trainX)\n",
    "train_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24455766, 0.2503374 , 0.24961333, 0.25549158],\n",
       "       [0.24455766, 0.2503374 , 0.24961333, 0.25549158],\n",
       "       [0.24455766, 0.2503374 , 0.24961333, 0.25549158],\n",
       "       ...,\n",
       "       [0.24455766, 0.2503374 , 0.24961333, 0.25549158],\n",
       "       [0.24455766, 0.2503374 , 0.24961333, 0.25549158],\n",
       "       [0.24455766, 0.2503374 , 0.24961333, 0.25549158]], dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted=saved_model.predict(testX)\n",
    "test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 343]\n",
      " [  0   0   0 349]\n",
      " [  0   0   0 347]\n",
      " [  0   0   0 361]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix for Training\n",
    "from sklearn import metrics\n",
    "confusion = metrics.confusion_matrix(trainy.argmax(axis=1), train_predicted.argmax(axis=1))\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25785714285714284\n"
     ]
    }
   ],
   "source": [
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(trainy.argmax(axis=1), train_predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 157]\n",
      " [  0   0   0 151]\n",
      " [  0   0   0 153]\n",
      " [  0   0   0 139]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix for Testing\n",
    "from sklearn import metrics\n",
    "confusion1 = metrics.confusion_matrix(testy.argmax(axis=1), test_predicted.argmax(axis=1))\n",
    "print(confusion1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23166666666666666\n"
     ]
    }
   ],
   "source": [
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(testy.argmax(axis=1), test_predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also use pycm for the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1.]\n",
      "[1. 1. 1. 0.]\n",
      "[0.73833333 0.74833333 0.745      0.23166667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved deo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\ved deo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\ved deo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "FP = confusion1.sum(axis=0) - np.diag(confusion1)  \n",
    "FN = confusion1.sum(axis=1) - np.diag(confusion1)\n",
    "TP = np.diag(confusion1)\n",
    "TN = confusion1.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(TPR)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "print(TNR)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Regularization Parameter + Drop Out + ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model with Regularization and drop out for stopping Overfitting\n",
    "from keras import regularizers\n",
    "model_adam = Sequential()\n",
    "model_adam.add(Dense(300,activation='relu',kernel_regularizer=regularizers.l1(0.01)))\n",
    "model_adam.add(Dropout(0.6, noise_shape=None, seed=None))\n",
    "model_adam.add(Dense(200, activation='relu',kernel_regularizer=regularizers.l1(0.01)))\n",
    "model_adam.add(Dense(50, activation='relu'))\n",
    "model_adam.add(Dense(4, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Model with adam\n",
    "model_adam.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('best_model_mlp_reg.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/200\n",
      "1400/1400 [==============================] - 0s 248us/step - loss: 42.5630 - accuracy: 0.2800 - val_loss: 36.1958 - val_accuracy: 0.3450\n",
      "Epoch 2/200\n",
      "1400/1400 [==============================] - 0s 53us/step - loss: 33.2981 - accuracy: 0.3486 - val_loss: 30.1154 - val_accuracy: 0.2517\n",
      "Epoch 3/200\n",
      "1400/1400 [==============================] - 0s 42us/step - loss: 28.3948 - accuracy: 0.3771 - val_loss: 25.3428 - val_accuracy: 0.5367\n",
      "Epoch 4/200\n",
      " 128/1400 [=>............................] - ETA: 0s - loss: 26.1516 - accuracy: 0.4766"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 0s 43us/step - loss: 24.7030 - accuracy: 0.4507 - val_loss: 22.3478 - val_accuracy: 0.6583\n",
      "Epoch 5/200\n",
      "1400/1400 [==============================] - 0s 34us/step - loss: 21.6568 - accuracy: 0.4686 - val_loss: 19.6482 - val_accuracy: 0.9383\n",
      "Epoch 6/200\n",
      "1400/1400 [==============================] - 0s 70us/step - loss: 19.0722 - accuracy: 0.5414 - val_loss: 17.4913 - val_accuracy: 0.7950\n",
      "Epoch 7/200\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 16.8981 - accuracy: 0.5764 - val_loss: 15.5149 - val_accuracy: 0.9200\n",
      "Epoch 8/200\n",
      "1400/1400 [==============================] - 0s 40us/step - loss: 15.1482 - accuracy: 0.6071 - val_loss: 13.9287 - val_accuracy: 0.9483\n",
      "Epoch 9/200\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 13.6638 - accuracy: 0.6386 - val_loss: 12.6510 - val_accuracy: 0.9717\n",
      "Epoch 10/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 12.5894 - accuracy: 0.6729 - val_loss: 11.8000 - val_accuracy: 0.9567\n",
      "Epoch 11/200\n",
      "1400/1400 [==============================] - 0s 43us/step - loss: 11.8006 - accuracy: 0.6857 - val_loss: 11.0899 - val_accuracy: 0.9567\n",
      "Epoch 12/200\n",
      "1400/1400 [==============================] - 0s 41us/step - loss: 11.0554 - accuracy: 0.7264 - val_loss: 10.4549 - val_accuracy: 0.9500\n",
      "Epoch 13/200\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 10.4298 - accuracy: 0.7521 - val_loss: 9.8976 - val_accuracy: 0.9317\n",
      "Epoch 14/200\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 9.8673 - accuracy: 0.7657 - val_loss: 9.3699 - val_accuracy: 0.9300\n",
      "Epoch 15/200\n",
      "1400/1400 [==============================] - 0s 68us/step - loss: 9.3658 - accuracy: 0.7686 - val_loss: 8.8549 - val_accuracy: 0.9517\n",
      "Epoch 16/200\n",
      "1400/1400 [==============================] - 0s 32us/step - loss: 8.8536 - accuracy: 0.7857 - val_loss: 8.4209 - val_accuracy: 0.9183\n",
      "Epoch 17/200\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 8.3632 - accuracy: 0.8393 - val_loss: 7.9747 - val_accuracy: 0.9400\n",
      "Epoch 18/200\n",
      "1400/1400 [==============================] - 0s 58us/step - loss: 7.9455 - accuracy: 0.8171 - val_loss: 7.5468 - val_accuracy: 0.9583\n",
      "Epoch 19/200\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 7.5299 - accuracy: 0.8471 - val_loss: 7.1534 - val_accuracy: 0.9683\n",
      "Epoch 20/200\n",
      "1400/1400 [==============================] - 0s 36us/step - loss: 7.1536 - accuracy: 0.8500 - val_loss: 6.8276 - val_accuracy: 0.9333\n",
      "Epoch 21/200\n",
      "1400/1400 [==============================] - 0s 35us/step - loss: 6.7941 - accuracy: 0.8643 - val_loss: 6.4591 - val_accuracy: 0.9600\n",
      "Epoch 22/200\n",
      "1400/1400 [==============================] - 0s 34us/step - loss: 6.4325 - accuracy: 0.8764 - val_loss: 6.1342 - val_accuracy: 0.9633\n",
      "Epoch 23/200\n",
      "1400/1400 [==============================] - 0s 35us/step - loss: 6.1250 - accuracy: 0.8729 - val_loss: 5.8327 - val_accuracy: 0.9633\n",
      "Epoch 24/200\n",
      "1400/1400 [==============================] - 0s 42us/step - loss: 5.8278 - accuracy: 0.8886 - val_loss: 5.5602 - val_accuracy: 0.9517\n",
      "Epoch 25/200\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 5.5547 - accuracy: 0.8829 - val_loss: 5.2936 - val_accuracy: 0.9533\n",
      "Epoch 26/200\n",
      "1400/1400 [==============================] - 0s 31us/step - loss: 5.3100 - accuracy: 0.8786 - val_loss: 5.0335 - val_accuracy: 0.9683\n",
      "Epoch 27/200\n",
      "1400/1400 [==============================] - 0s 41us/step - loss: 5.0344 - accuracy: 0.8964 - val_loss: 4.7921 - val_accuracy: 0.9800\n",
      "Epoch 28/200\n",
      "1400/1400 [==============================] - 0s 31us/step - loss: 4.7800 - accuracy: 0.9157 - val_loss: 4.5542 - val_accuracy: 0.9667\n",
      "Epoch 29/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 4.5831 - accuracy: 0.8900 - val_loss: 4.3456 - val_accuracy: 0.9783\n",
      "Epoch 30/200\n",
      "1400/1400 [==============================] - 0s 33us/step - loss: 4.3561 - accuracy: 0.9093 - val_loss: 4.1556 - val_accuracy: 0.9783\n",
      "Epoch 31/200\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 4.1655 - accuracy: 0.9100 - val_loss: 3.9635 - val_accuracy: 0.9700\n",
      "Epoch 32/200\n",
      "1400/1400 [==============================] - 0s 73us/step - loss: 3.9845 - accuracy: 0.9229 - val_loss: 3.7929 - val_accuracy: 0.9700\n",
      "Epoch 33/200\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 3.8134 - accuracy: 0.9207 - val_loss: 3.6247 - val_accuracy: 0.9833\n",
      "Epoch 34/200\n",
      "1400/1400 [==============================] - 0s 43us/step - loss: 3.6565 - accuracy: 0.9121 - val_loss: 3.4656 - val_accuracy: 0.9800\n",
      "Epoch 35/200\n",
      "1400/1400 [==============================] - 0s 43us/step - loss: 3.5027 - accuracy: 0.9186 - val_loss: 3.3284 - val_accuracy: 0.9650\n",
      "Epoch 36/200\n",
      "1400/1400 [==============================] - 0s 71us/step - loss: 3.3638 - accuracy: 0.9121 - val_loss: 3.1835 - val_accuracy: 0.9783\n",
      "Epoch 37/200\n",
      "1400/1400 [==============================] - 0s 72us/step - loss: 3.2181 - accuracy: 0.9221 - val_loss: 3.0535 - val_accuracy: 0.9750\n",
      "Epoch 38/200\n",
      "1400/1400 [==============================] - 0s 52us/step - loss: 3.0943 - accuracy: 0.9171 - val_loss: 2.9324 - val_accuracy: 0.9817\n",
      "Epoch 39/200\n",
      "1400/1400 [==============================] - 0s 58us/step - loss: 2.9753 - accuracy: 0.9164 - val_loss: 2.8311 - val_accuracy: 0.9650\n",
      "Epoch 40/200\n",
      "1400/1400 [==============================] - 0s 63us/step - loss: 2.8642 - accuracy: 0.9143 - val_loss: 2.7106 - val_accuracy: 0.9767\n",
      "Epoch 41/200\n",
      "1400/1400 [==============================] - 0s 55us/step - loss: 2.7567 - accuracy: 0.9143 - val_loss: 2.6195 - val_accuracy: 0.9617\n",
      "Epoch 42/200\n",
      "1400/1400 [==============================] - 0s 36us/step - loss: 2.6405 - accuracy: 0.9300 - val_loss: 2.5053 - val_accuracy: 0.9733\n",
      "Epoch 43/200\n",
      "1400/1400 [==============================] - 0s 56us/step - loss: 2.5530 - accuracy: 0.9243 - val_loss: 2.4109 - val_accuracy: 0.9783\n",
      "Epoch 44/200\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 2.4700 - accuracy: 0.9214 - val_loss: 2.3237 - val_accuracy: 0.9683\n",
      "Epoch 45/200\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 2.3634 - accuracy: 0.9300 - val_loss: 2.2646 - val_accuracy: 0.9533\n",
      "Epoch 46/200\n",
      "1400/1400 [==============================] - 0s 36us/step - loss: 2.2875 - accuracy: 0.9314 - val_loss: 2.1662 - val_accuracy: 0.9717\n",
      "Epoch 47/200\n",
      "1400/1400 [==============================] - 0s 70us/step - loss: 2.2106 - accuracy: 0.9200 - val_loss: 2.0774 - val_accuracy: 0.9817\n",
      "Epoch 48/200\n",
      "1400/1400 [==============================] - 0s 39us/step - loss: 2.1234 - accuracy: 0.9307 - val_loss: 2.0002 - val_accuracy: 0.9767\n",
      "Epoch 49/200\n",
      "1400/1400 [==============================] - 0s 33us/step - loss: 2.0491 - accuracy: 0.9336 - val_loss: 1.9251 - val_accuracy: 0.9767\n",
      "Epoch 50/200\n",
      "1400/1400 [==============================] - 0s 58us/step - loss: 1.9757 - accuracy: 0.9314 - val_loss: 1.8593 - val_accuracy: 0.9800\n",
      "Epoch 51/200\n",
      "1400/1400 [==============================] - 0s 59us/step - loss: 1.9009 - accuracy: 0.9393 - val_loss: 1.7956 - val_accuracy: 0.9700\n",
      "Epoch 52/200\n",
      "1400/1400 [==============================] - 0s 34us/step - loss: 1.8526 - accuracy: 0.9293 - val_loss: 1.7422 - val_accuracy: 0.9717\n",
      "Epoch 53/200\n",
      "1400/1400 [==============================] - 0s 29us/step - loss: 1.7703 - accuracy: 0.9464 - val_loss: 1.6749 - val_accuracy: 0.9733\n",
      "Epoch 54/200\n",
      "1400/1400 [==============================] - 0s 64us/step - loss: 1.7297 - accuracy: 0.9364 - val_loss: 1.6267 - val_accuracy: 0.9667\n",
      "Epoch 55/200\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 1.6847 - accuracy: 0.9293 - val_loss: 1.5773 - val_accuracy: 0.9750\n",
      "Epoch 56/200\n",
      "1400/1400 [==============================] - 0s 33us/step - loss: 1.6281 - accuracy: 0.9293 - val_loss: 1.5196 - val_accuracy: 0.9717\n",
      "Epoch 57/200\n",
      "1400/1400 [==============================] - 0s 52us/step - loss: 1.5676 - accuracy: 0.9443 - val_loss: 1.4674 - val_accuracy: 0.9750\n",
      "Epoch 58/200\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 1.5274 - accuracy: 0.9329 - val_loss: 1.4268 - val_accuracy: 0.9750\n",
      "Epoch 59/200\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 1.4889 - accuracy: 0.9329 - val_loss: 1.3883 - val_accuracy: 0.9767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "1400/1400 [==============================] - 0s 42us/step - loss: 1.4481 - accuracy: 0.9429 - val_loss: 1.3702 - val_accuracy: 0.9683\n",
      "Epoch 61/200\n",
      "1400/1400 [==============================] - 0s 32us/step - loss: 1.4196 - accuracy: 0.9264 - val_loss: 1.3114 - val_accuracy: 0.9750\n",
      "Epoch 62/200\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 1.3589 - accuracy: 0.9486 - val_loss: 1.2754 - val_accuracy: 0.9733\n",
      "Epoch 63/200\n",
      "1400/1400 [==============================] - 0s 62us/step - loss: 1.3325 - accuracy: 0.9429 - val_loss: 1.2334 - val_accuracy: 0.9767\n",
      "Epoch 64/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 1.2838 - accuracy: 0.9464 - val_loss: 1.2094 - val_accuracy: 0.9733\n",
      "Epoch 65/200\n",
      "1400/1400 [==============================] - 0s 63us/step - loss: 1.2758 - accuracy: 0.9393 - val_loss: 1.1917 - val_accuracy: 0.9683\n",
      "Epoch 66/200\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 1.2405 - accuracy: 0.9350 - val_loss: 1.1621 - val_accuracy: 0.9567\n",
      "Epoch 67/200\n",
      "1400/1400 [==============================] - 0s 56us/step - loss: 1.1964 - accuracy: 0.9421 - val_loss: 1.1109 - val_accuracy: 0.9767\n",
      "Epoch 68/200\n",
      "1400/1400 [==============================] - 0s 31us/step - loss: 1.1796 - accuracy: 0.9371 - val_loss: 1.0994 - val_accuracy: 0.9683\n",
      "Epoch 69/200\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 1.1694 - accuracy: 0.9286 - val_loss: 1.0794 - val_accuracy: 0.9617\n",
      "Epoch 70/200\n",
      "1400/1400 [==============================] - 0s 37us/step - loss: 1.1420 - accuracy: 0.9286 - val_loss: 1.0506 - val_accuracy: 0.9683\n",
      "Epoch 71/200\n",
      "1400/1400 [==============================] - 0s 33us/step - loss: 1.0921 - accuracy: 0.9436 - val_loss: 1.0059 - val_accuracy: 0.9733\n",
      "Epoch 72/200\n",
      "1400/1400 [==============================] - 0s 32us/step - loss: 1.0540 - accuracy: 0.9493 - val_loss: 0.9890 - val_accuracy: 0.9733\n",
      "Epoch 73/200\n",
      "1400/1400 [==============================] - 0s 66us/step - loss: 1.0448 - accuracy: 0.9429 - val_loss: 0.9673 - val_accuracy: 0.9717\n",
      "Epoch 74/200\n",
      "1400/1400 [==============================] - 0s 43us/step - loss: 1.0371 - accuracy: 0.9407 - val_loss: 0.9433 - val_accuracy: 0.9717\n",
      "Epoch 75/200\n",
      "1400/1400 [==============================] - 0s 34us/step - loss: 0.9981 - accuracy: 0.9500 - val_loss: 0.9244 - val_accuracy: 0.9767\n",
      "Epoch 76/200\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.9636 - accuracy: 0.9600 - val_loss: 0.8942 - val_accuracy: 0.9767\n",
      "Epoch 77/200\n",
      "1400/1400 [==============================] - 0s 40us/step - loss: 0.9659 - accuracy: 0.9400 - val_loss: 0.8823 - val_accuracy: 0.9750\n",
      "Epoch 78/200\n",
      "1400/1400 [==============================] - 0s 50us/step - loss: 0.9352 - accuracy: 0.9471 - val_loss: 0.8616 - val_accuracy: 0.9767\n",
      "Epoch 79/200\n",
      "1400/1400 [==============================] - 0s 35us/step - loss: 0.9313 - accuracy: 0.9393 - val_loss: 0.8426 - val_accuracy: 0.9750\n",
      "Epoch 80/200\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.9008 - accuracy: 0.9479 - val_loss: 0.8345 - val_accuracy: 0.9767\n",
      "Epoch 81/200\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.8860 - accuracy: 0.9500 - val_loss: 0.8110 - val_accuracy: 0.9800\n",
      "Epoch 82/200\n",
      "1400/1400 [==============================] - 0s 66us/step - loss: 0.8760 - accuracy: 0.9457 - val_loss: 0.8058 - val_accuracy: 0.9733\n",
      "Epoch 83/200\n",
      "1400/1400 [==============================] - 0s 52us/step - loss: 0.8584 - accuracy: 0.9493 - val_loss: 0.7944 - val_accuracy: 0.9717\n",
      "Epoch 84/200\n",
      "1400/1400 [==============================] - 0s 62us/step - loss: 0.8686 - accuracy: 0.9471 - val_loss: 0.7744 - val_accuracy: 0.9767\n",
      "Epoch 85/200\n",
      "1400/1400 [==============================] - 0s 81us/step - loss: 0.8395 - accuracy: 0.9514 - val_loss: 0.7679 - val_accuracy: 0.9800\n",
      "Epoch 86/200\n",
      "1400/1400 [==============================] - 0s 56us/step - loss: 0.8432 - accuracy: 0.9357 - val_loss: 0.7695 - val_accuracy: 0.9700\n",
      "Epoch 87/200\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.8138 - accuracy: 0.9414 - val_loss: 0.7397 - val_accuracy: 0.9767\n",
      "Epoch 88/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 0.7978 - accuracy: 0.9436 - val_loss: 0.7278 - val_accuracy: 0.9783\n",
      "Epoch 89/200\n",
      "1400/1400 [==============================] - 0s 65us/step - loss: 0.7893 - accuracy: 0.9493 - val_loss: 0.7257 - val_accuracy: 0.9750\n",
      "Epoch 90/200\n",
      "1400/1400 [==============================] - 0s 33us/step - loss: 0.7854 - accuracy: 0.9521 - val_loss: 0.7121 - val_accuracy: 0.9733\n",
      "Epoch 91/200\n",
      "1400/1400 [==============================] - 0s 74us/step - loss: 0.7798 - accuracy: 0.9493 - val_loss: 0.6930 - val_accuracy: 0.9783\n",
      "Epoch 92/200\n",
      "1400/1400 [==============================] - 0s 43us/step - loss: 0.7535 - accuracy: 0.9493 - val_loss: 0.6985 - val_accuracy: 0.9650\n",
      "Epoch 93/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 0.7474 - accuracy: 0.9450 - val_loss: 0.6831 - val_accuracy: 0.9683\n",
      "Epoch 94/200\n",
      "1400/1400 [==============================] - 0s 56us/step - loss: 0.7504 - accuracy: 0.9500 - val_loss: 0.6670 - val_accuracy: 0.9767\n",
      "Epoch 95/200\n",
      "1400/1400 [==============================] - 0s 56us/step - loss: 0.7545 - accuracy: 0.9457 - val_loss: 0.6692 - val_accuracy: 0.9733\n",
      "Epoch 96/200\n",
      "1400/1400 [==============================] - 0s 33us/step - loss: 0.7181 - accuracy: 0.9493 - val_loss: 0.6451 - val_accuracy: 0.9817\n",
      "Epoch 97/200\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 0.7109 - accuracy: 0.9450 - val_loss: 0.6365 - val_accuracy: 0.9750\n",
      "Epoch 98/200\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.7128 - accuracy: 0.9393 - val_loss: 0.6291 - val_accuracy: 0.9783\n",
      "Epoch 99/200\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 0.6918 - accuracy: 0.9500 - val_loss: 0.6240 - val_accuracy: 0.9783\n",
      "Epoch 100/200\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.6862 - accuracy: 0.9443 - val_loss: 0.6141 - val_accuracy: 0.9767\n",
      "Epoch 101/200\n",
      "1400/1400 [==============================] - 0s 43us/step - loss: 0.6703 - accuracy: 0.9521 - val_loss: 0.6026 - val_accuracy: 0.9800\n",
      "Epoch 102/200\n",
      "1400/1400 [==============================] - 0s 36us/step - loss: 0.6679 - accuracy: 0.9486 - val_loss: 0.5988 - val_accuracy: 0.9767\n",
      "Epoch 103/200\n",
      "1400/1400 [==============================] - 0s 78us/step - loss: 0.6584 - accuracy: 0.9514 - val_loss: 0.5932 - val_accuracy: 0.9783\n",
      "Epoch 104/200\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.6469 - accuracy: 0.9464 - val_loss: 0.5943 - val_accuracy: 0.9783\n",
      "Epoch 105/200\n",
      "1400/1400 [==============================] - 0s 31us/step - loss: 0.6489 - accuracy: 0.9486 - val_loss: 0.5789 - val_accuracy: 0.9767\n",
      "Epoch 106/200\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.6453 - accuracy: 0.9493 - val_loss: 0.5707 - val_accuracy: 0.9783\n",
      "Epoch 107/200\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.6422 - accuracy: 0.9486 - val_loss: 0.5816 - val_accuracy: 0.9683\n",
      "Epoch 108/200\n",
      "1400/1400 [==============================] - 0s 69us/step - loss: 0.6167 - accuracy: 0.9536 - val_loss: 0.5618 - val_accuracy: 0.9783\n",
      "Epoch 109/200\n",
      "1400/1400 [==============================] - 0s 42us/step - loss: 0.6250 - accuracy: 0.9479 - val_loss: 0.5616 - val_accuracy: 0.9750\n",
      "Epoch 110/200\n",
      "1400/1400 [==============================] - 0s 37us/step - loss: 0.6157 - accuracy: 0.9493 - val_loss: 0.5568 - val_accuracy: 0.9733\n",
      "Epoch 111/200\n",
      "1400/1400 [==============================] - 0s 32us/step - loss: 0.6185 - accuracy: 0.9507 - val_loss: 0.5552 - val_accuracy: 0.9717\n",
      "Epoch 112/200\n",
      "1400/1400 [==============================] - 0s 37us/step - loss: 0.6012 - accuracy: 0.9493 - val_loss: 0.5556 - val_accuracy: 0.9667\n",
      "Epoch 113/200\n",
      "1400/1400 [==============================] - 0s 58us/step - loss: 0.6060 - accuracy: 0.9464 - val_loss: 0.5341 - val_accuracy: 0.9767\n",
      "Epoch 114/200\n",
      "1400/1400 [==============================] - 0s 58us/step - loss: 0.6016 - accuracy: 0.9500 - val_loss: 0.5271 - val_accuracy: 0.9850\n",
      "Epoch 115/200\n",
      "1400/1400 [==============================] - 0s 58us/step - loss: 0.5785 - accuracy: 0.9529 - val_loss: 0.5360 - val_accuracy: 0.9717\n",
      "Epoch 116/200\n",
      "1400/1400 [==============================] - 0s 43us/step - loss: 0.5667 - accuracy: 0.9571 - val_loss: 0.5388 - val_accuracy: 0.9650\n",
      "Epoch 117/200\n",
      "1400/1400 [==============================] - 0s 34us/step - loss: 0.5772 - accuracy: 0.9493 - val_loss: 0.5080 - val_accuracy: 0.9800\n",
      "Epoch 118/200\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.5612 - accuracy: 0.9571 - val_loss: 0.5003 - val_accuracy: 0.9800\n",
      "Epoch 119/200\n",
      "1400/1400 [==============================] - 0s 36us/step - loss: 0.5648 - accuracy: 0.9493 - val_loss: 0.5128 - val_accuracy: 0.9733\n",
      "Epoch 120/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 0.5729 - accuracy: 0.9443 - val_loss: 0.4973 - val_accuracy: 0.9783\n",
      "Epoch 121/200\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.5610 - accuracy: 0.9429 - val_loss: 0.4950 - val_accuracy: 0.9783\n",
      "Epoch 122/200\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.5448 - accuracy: 0.9536 - val_loss: 0.4895 - val_accuracy: 0.9767\n",
      "Epoch 123/200\n",
      "1400/1400 [==============================] - 0s 50us/step - loss: 0.5517 - accuracy: 0.9500 - val_loss: 0.4826 - val_accuracy: 0.9783\n",
      "Epoch 124/200\n",
      "1400/1400 [==============================] - 0s 63us/step - loss: 0.5282 - accuracy: 0.9571 - val_loss: 0.4763 - val_accuracy: 0.9783\n",
      "Epoch 125/200\n",
      "1400/1400 [==============================] - 0s 71us/step - loss: 0.5397 - accuracy: 0.9493 - val_loss: 0.4749 - val_accuracy: 0.9783\n",
      "Epoch 126/200\n",
      "1400/1400 [==============================] - 0s 115us/step - loss: 0.5408 - accuracy: 0.9529 - val_loss: 0.4707 - val_accuracy: 0.9817\n",
      "Epoch 127/200\n",
      "1400/1400 [==============================] - 0s 54us/step - loss: 0.5492 - accuracy: 0.9493 - val_loss: 0.4725 - val_accuracy: 0.9800\n",
      "Epoch 128/200\n",
      "1400/1400 [==============================] - 0s 37us/step - loss: 0.5193 - accuracy: 0.9550 - val_loss: 0.4690 - val_accuracy: 0.9767\n",
      "Epoch 129/200\n",
      "1400/1400 [==============================] - 0s 75us/step - loss: 0.5388 - accuracy: 0.9493 - val_loss: 0.4738 - val_accuracy: 0.9733\n",
      "Epoch 130/200\n",
      "1400/1400 [==============================] - 0s 55us/step - loss: 0.5223 - accuracy: 0.9521 - val_loss: 0.4579 - val_accuracy: 0.9767\n",
      "Epoch 131/200\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.5117 - accuracy: 0.9593 - val_loss: 0.4545 - val_accuracy: 0.9767\n",
      "Epoch 132/200\n",
      "1400/1400 [==============================] - 0s 41us/step - loss: 0.5075 - accuracy: 0.9579 - val_loss: 0.4559 - val_accuracy: 0.9767\n",
      "Epoch 133/200\n",
      "1400/1400 [==============================] - 0s 66us/step - loss: 0.5342 - accuracy: 0.9407 - val_loss: 0.4643 - val_accuracy: 0.9700\n",
      "Epoch 134/200\n",
      "1400/1400 [==============================] - 0s 68us/step - loss: 0.5362 - accuracy: 0.9414 - val_loss: 0.4580 - val_accuracy: 0.9767\n",
      "Epoch 135/200\n",
      "1400/1400 [==============================] - 0s 65us/step - loss: 0.4981 - accuracy: 0.9529 - val_loss: 0.4607 - val_accuracy: 0.9700\n",
      "Epoch 136/200\n",
      "1400/1400 [==============================] - 0s 87us/step - loss: 0.4989 - accuracy: 0.9493 - val_loss: 0.4393 - val_accuracy: 0.9850\n",
      "Epoch 137/200\n",
      "1400/1400 [==============================] - 0s 65us/step - loss: 0.5029 - accuracy: 0.9514 - val_loss: 0.4489 - val_accuracy: 0.9717\n",
      "Epoch 138/200\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.4828 - accuracy: 0.9586 - val_loss: 0.4495 - val_accuracy: 0.9700\n",
      "Epoch 139/200\n",
      "1400/1400 [==============================] - 0s 80us/step - loss: 0.4964 - accuracy: 0.9493 - val_loss: 0.4322 - val_accuracy: 0.9800\n",
      "Epoch 140/200\n",
      "1400/1400 [==============================] - 0s 40us/step - loss: 0.4950 - accuracy: 0.9507 - val_loss: 0.4357 - val_accuracy: 0.9717\n",
      "Epoch 141/200\n",
      "1400/1400 [==============================] - 0s 34us/step - loss: 0.4982 - accuracy: 0.9514 - val_loss: 0.4325 - val_accuracy: 0.9767\n",
      "Epoch 142/200\n",
      "1400/1400 [==============================] - 0s 36us/step - loss: 0.4952 - accuracy: 0.9521 - val_loss: 0.4226 - val_accuracy: 0.9817\n",
      "Epoch 143/200\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.5055 - accuracy: 0.9429 - val_loss: 0.4339 - val_accuracy: 0.9767\n",
      "Epoch 144/200\n",
      "1400/1400 [==============================] - 0s 34us/step - loss: 0.4875 - accuracy: 0.9486 - val_loss: 0.4236 - val_accuracy: 0.9783\n",
      "Epoch 145/200\n",
      "1400/1400 [==============================] - 0s 56us/step - loss: 0.4860 - accuracy: 0.9436 - val_loss: 0.4518 - val_accuracy: 0.9517\n",
      "Epoch 146/200\n",
      "1400/1400 [==============================] - 0s 54us/step - loss: 0.4960 - accuracy: 0.9379 - val_loss: 0.4224 - val_accuracy: 0.9750\n",
      "Epoch 147/200\n",
      "1400/1400 [==============================] - 0s 33us/step - loss: 0.4950 - accuracy: 0.9464 - val_loss: 0.4435 - val_accuracy: 0.9650\n",
      "Epoch 148/200\n",
      "1400/1400 [==============================] - 0s 41us/step - loss: 0.4810 - accuracy: 0.9471 - val_loss: 0.4199 - val_accuracy: 0.9750\n",
      "Epoch 149/200\n",
      "1400/1400 [==============================] - 0s 34us/step - loss: 0.4782 - accuracy: 0.9500 - val_loss: 0.4154 - val_accuracy: 0.9783\n",
      "Epoch 150/200\n",
      "1400/1400 [==============================] - 0s 50us/step - loss: 0.4814 - accuracy: 0.9529 - val_loss: 0.4164 - val_accuracy: 0.9783\n",
      "Epoch 151/200\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.4895 - accuracy: 0.9464 - val_loss: 0.4121 - val_accuracy: 0.9800\n",
      "Epoch 152/200\n",
      "1400/1400 [==============================] - 0s 94us/step - loss: 0.4790 - accuracy: 0.9493 - val_loss: 0.4100 - val_accuracy: 0.9800\n",
      "Epoch 153/200\n",
      "1400/1400 [==============================] - 0s 34us/step - loss: 0.4670 - accuracy: 0.9493 - val_loss: 0.4101 - val_accuracy: 0.9767\n",
      "Epoch 154/200\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 0.4667 - accuracy: 0.9507 - val_loss: 0.4058 - val_accuracy: 0.9750\n",
      "Epoch 155/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 0.4662 - accuracy: 0.9500 - val_loss: 0.4078 - val_accuracy: 0.9750\n",
      "Epoch 156/200\n",
      "1400/1400 [==============================] - 0s 55us/step - loss: 0.4684 - accuracy: 0.9479 - val_loss: 0.4017 - val_accuracy: 0.9767\n",
      "Epoch 157/200\n",
      "1400/1400 [==============================] - 0s 55us/step - loss: 0.4749 - accuracy: 0.9443 - val_loss: 0.4242 - val_accuracy: 0.9683\n",
      "Epoch 158/200\n",
      "1400/1400 [==============================] - 0s 36us/step - loss: 0.4592 - accuracy: 0.9457 - val_loss: 0.4080 - val_accuracy: 0.9667\n",
      "Epoch 159/200\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.4569 - accuracy: 0.9493 - val_loss: 0.4041 - val_accuracy: 0.9683\n",
      "Epoch 160/200\n",
      "1400/1400 [==============================] - 0s 66us/step - loss: 0.4465 - accuracy: 0.9529 - val_loss: 0.3952 - val_accuracy: 0.9733\n",
      "Epoch 161/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 0.4480 - accuracy: 0.9507 - val_loss: 0.3850 - val_accuracy: 0.9800\n",
      "Epoch 162/200\n",
      "1400/1400 [==============================] - 0s 39us/step - loss: 0.4521 - accuracy: 0.9550 - val_loss: 0.3956 - val_accuracy: 0.9783\n",
      "Epoch 163/200\n",
      "1400/1400 [==============================] - 0s 57us/step - loss: 0.4503 - accuracy: 0.9514 - val_loss: 0.3814 - val_accuracy: 0.9783\n",
      "Epoch 164/200\n",
      "1400/1400 [==============================] - 0s 75us/step - loss: 0.4580 - accuracy: 0.9457 - val_loss: 0.3891 - val_accuracy: 0.9800\n",
      "Epoch 165/200\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.4378 - accuracy: 0.9579 - val_loss: 0.3846 - val_accuracy: 0.9767\n",
      "Epoch 166/200\n",
      "1400/1400 [==============================] - 0s 50us/step - loss: 0.4384 - accuracy: 0.9543 - val_loss: 0.3774 - val_accuracy: 0.9800\n",
      "Epoch 167/200\n",
      "1400/1400 [==============================] - 0s 52us/step - loss: 0.4575 - accuracy: 0.9436 - val_loss: 0.3857 - val_accuracy: 0.9750\n",
      "Epoch 168/200\n",
      "1400/1400 [==============================] - 0s 42us/step - loss: 0.4367 - accuracy: 0.9529 - val_loss: 0.3798 - val_accuracy: 0.9783\n",
      "Epoch 169/200\n",
      "1400/1400 [==============================] - 0s 64us/step - loss: 0.4328 - accuracy: 0.9550 - val_loss: 0.3742 - val_accuracy: 0.9800\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.4291 - accuracy: 0.9529 - val_loss: 0.3734 - val_accuracy: 0.9817\n",
      "Epoch 171/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 0.4472 - accuracy: 0.9493 - val_loss: 0.3856 - val_accuracy: 0.9700\n",
      "Epoch 172/200\n",
      "1400/1400 [==============================] - 0s 62us/step - loss: 0.4427 - accuracy: 0.9493 - val_loss: 0.3720 - val_accuracy: 0.9800\n",
      "Epoch 173/200\n",
      "1400/1400 [==============================] - 0s 34us/step - loss: 0.4465 - accuracy: 0.9529 - val_loss: 0.3958 - val_accuracy: 0.9683\n",
      "Epoch 174/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 0.4483 - accuracy: 0.9400 - val_loss: 0.3700 - val_accuracy: 0.9817\n",
      "Epoch 175/200\n",
      "1400/1400 [==============================] - 0s 63us/step - loss: 0.4748 - accuracy: 0.9371 - val_loss: 0.3966 - val_accuracy: 0.9667\n",
      "Epoch 176/200\n",
      "1400/1400 [==============================] - 0s 127us/step - loss: 0.4529 - accuracy: 0.9443 - val_loss: 0.3778 - val_accuracy: 0.9750\n",
      "Epoch 177/200\n",
      "1400/1400 [==============================] - 0s 53us/step - loss: 0.4464 - accuracy: 0.9436 - val_loss: 0.3705 - val_accuracy: 0.9750\n",
      "Epoch 178/200\n",
      "1400/1400 [==============================] - 0s 42us/step - loss: 0.4340 - accuracy: 0.9521 - val_loss: 0.3681 - val_accuracy: 0.9767\n",
      "Epoch 179/200\n",
      "1400/1400 [==============================] - 0s 56us/step - loss: 0.4230 - accuracy: 0.9507 - val_loss: 0.3797 - val_accuracy: 0.9750\n",
      "Epoch 180/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 0.4420 - accuracy: 0.9450 - val_loss: 0.3902 - val_accuracy: 0.9683\n",
      "Epoch 181/200\n",
      "1400/1400 [==============================] - 0s 36us/step - loss: 0.4280 - accuracy: 0.9507 - val_loss: 0.3688 - val_accuracy: 0.9767\n",
      "Epoch 182/200\n",
      "1400/1400 [==============================] - 0s 89us/step - loss: 0.4286 - accuracy: 0.9500 - val_loss: 0.3806 - val_accuracy: 0.9733\n",
      "Epoch 183/200\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.4473 - accuracy: 0.9486 - val_loss: 0.3876 - val_accuracy: 0.9650\n",
      "Epoch 184/200\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 0.4491 - accuracy: 0.9407 - val_loss: 0.3713 - val_accuracy: 0.9750\n",
      "Epoch 185/200\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.4463 - accuracy: 0.9457 - val_loss: 0.3661 - val_accuracy: 0.9817\n",
      "Epoch 186/200\n",
      "1400/1400 [==============================] - 0s 53us/step - loss: 0.4394 - accuracy: 0.9500 - val_loss: 0.3654 - val_accuracy: 0.9767\n",
      "Epoch 187/200\n",
      "1400/1400 [==============================] - 0s 54us/step - loss: 0.4464 - accuracy: 0.9479 - val_loss: 0.3599 - val_accuracy: 0.9767\n",
      "Epoch 188/200\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.4281 - accuracy: 0.9514 - val_loss: 0.3774 - val_accuracy: 0.9683\n",
      "Epoch 189/200\n",
      "1400/1400 [==============================] - 0s 70us/step - loss: 0.4179 - accuracy: 0.9593 - val_loss: 0.3527 - val_accuracy: 0.9800\n",
      "Epoch 190/200\n",
      "1400/1400 [==============================] - 0s 42us/step - loss: 0.4261 - accuracy: 0.9514 - val_loss: 0.3663 - val_accuracy: 0.9750\n",
      "Epoch 191/200\n",
      "1400/1400 [==============================] - 0s 53us/step - loss: 0.4371 - accuracy: 0.9464 - val_loss: 0.3914 - val_accuracy: 0.9617\n",
      "Epoch 192/200\n",
      "1400/1400 [==============================] - 0s 92us/step - loss: 0.4344 - accuracy: 0.9393 - val_loss: 0.3678 - val_accuracy: 0.9767\n",
      "Epoch 193/200\n",
      "1400/1400 [==============================] - 0s 64us/step - loss: 0.4445 - accuracy: 0.9386 - val_loss: 0.3638 - val_accuracy: 0.9800\n",
      "Epoch 194/200\n",
      "1400/1400 [==============================] - 0s 35us/step - loss: 0.4293 - accuracy: 0.9529 - val_loss: 0.3545 - val_accuracy: 0.9767\n",
      "Epoch 195/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 0.4243 - accuracy: 0.9507 - val_loss: 0.3679 - val_accuracy: 0.9750\n",
      "Epoch 196/200\n",
      "1400/1400 [==============================] - 0s 58us/step - loss: 0.4139 - accuracy: 0.9493 - val_loss: 0.3531 - val_accuracy: 0.9783\n",
      "Epoch 197/200\n",
      "1400/1400 [==============================] - 0s 58us/step - loss: 0.4232 - accuracy: 0.9471 - val_loss: 0.3539 - val_accuracy: 0.9733\n",
      "Epoch 198/200\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 0.4324 - accuracy: 0.9407 - val_loss: 0.3642 - val_accuracy: 0.9767\n",
      "Epoch 199/200\n",
      "1400/1400 [==============================] - 0s 73us/step - loss: 0.4268 - accuracy: 0.9507 - val_loss: 0.3518 - val_accuracy: 0.9800\n",
      "Epoch 200/200\n",
      "1400/1400 [==============================] - 0s 39us/step - loss: 0.4037 - accuracy: 0.9593 - val_loss: 0.3497 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "# batch size should always in multiple of 2.\n",
    "history = model_adam.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=1, callbacks=[es, mc],batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "#saved_model = load_model('best_model_mlp_reg.h5')\n",
    "saved_model = model_adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.975, Test: 0.980\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = saved_model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de5zcdX3v8dfnN9e9b7K7CZsLJEDAcBGIkYIgSjVKEAVLS9WD5qgt7XnY1p5KCxxbjnh6wVOl9iJQFCxVwaKoBIU2EEBAboYQIJLIJuGSzXWzue595jef/jG/DUvIJptkd2Z/O+/n4zGPmfnOb3Y++c7kPd/5/m7m7oiISPwE5S5AREQOjwJcRCSmFOAiIjGlABcRiSkFuIhITCVL+WLNzc0+a9asUr6kiEjsPfvss9vcvWXf9pIG+KxZs1i2bFkpX1JEJPbM7LX9tWsKRUQkphTgIiIxpQAXEYmpks6Bi4gcqlwuR3t7O319feUuZcxls1lmzJhBKpUa0fIKcBEZ19rb26mrq2PWrFmYWbnLGTPuTmdnJ+3t7cyePXtEz9EUioiMa319fTQ1NU3o8AYwM5qamg7pl4YCXETGvYke3oMO9d8ZiwBfumoLNz6yptxliIiMK7EI8J+/3MEtj64rdxkiUqF27tzJjTfeeMjPu/DCC9m5c+cYVFQUiwDPphL05cJylyEiFWq4AA/DA+fSfffdR2Nj41iVFY+tULLJgL5cAXevmLkwERk/rr76atauXcvpp59OKpWitraW1tZWVqxYwUsvvcQll1zC+vXr6evr4/Of/zxXXHEF8MbhQ7q6uli4cCHnnnsuTzzxBNOnT+eee+6hqqrqiOqKRYBnUgkA+vMFstFtEak81937K17auHtU/+ZJ0+r5vx8++YDLXH/99axcuZIVK1bwyCOP8KEPfYiVK1fu3dzvtttuY/LkyfT29vLOd76TSy+9lKampjf9jba2Nu68806++c1vctlll3H33Xdz+eWXH1HtsZlCAejPFcpciYgInHnmmW/aVvuf/umfOO200zjrrLNYv349bW1tb3nO7NmzOf300wF4xzvewauvvnrEdcRiBJ5NFb9n+vIhDYxsDyURmXgONlIulZqamr23H3nkER588EGefPJJqquree9737vfbbkzmcze24lEgt7e3iOuIx4j8GRxBK4VmSJSDnV1dezZs2e/j+3atYtJkyZRXV3N6tWreeqpp0pWV0xG4IMBrikUESm9pqYmzjnnHE455RSqqqqYOnXq3scuuOACbr75Zt7+9rdz4oknctZZZ5WsrpgEeDSFohG4iJTJHXfcsd/2TCbD/fffv9/HBue5m5ubWbly5d72K6+8clRqGvEUipklzOw5M/tpdH+ymT1gZm3R9aRRqWg/3hiBK8BFRAYdyhz454FVQ+5fDSx19znA0uj+mHhjJaamUEREBo0owM1sBvAh4FtDmi8Gbo9u3w5cMrqlvSETrcTsHdAIXERk0EhH4F8H/gIYOgSe6u6bAKLrKft7opldYWbLzGxZR0fHYRW5dzvwvAJcRGTQQQPczC4Ctrr7s4fzAu5+i7vPd/f5LS0th/MntBJTRGQ/RrIVyjnAR8zsQiAL1JvZd4EtZtbq7pvMrBXYOlZFajNCEZG3OugI3N2vcfcZ7j4L+BjwkLtfDiwGFkWLLQLuGasitRWKiJTT4R5OFuDrX/86PT09o1xR0ZHsiXk9sMDM2oAF0f0xkU0OTqFoBC4ipTdeA/yQduRx90eAR6LbncD7Rr+kt0omAlIJo08rMUWkDIYeTnbBggVMmTKFu+66i/7+fj760Y9y3XXX0d3dzWWXXUZ7ezthGPJXf/VXbNmyhY0bN3L++efT3NzMww8/PKp1xWJPTCgeD0VTKCIV7v6rYfOLo/s3jzoVFh54AmHo4WSXLFnCD3/4Q5555hncnY985CM8+uijdHR0MG3aNH72s58BxWOkNDQ0cMMNN/Dwww/T3Nw8unUTk4NZQfGY4JpCEZFyW7JkCUuWLOGMM85g3rx5rF69mra2Nk499VQefPBBrrrqKh577DEaGhrGvJb4jMBTAf0agYtUtoOMlEvB3bnmmmv4gz/4g7c89uyzz3LfffdxzTXX8IEPfIBrr712TGuJzQg8m0poDlxEymLo4WQ/+MEPctttt9HV1QXAhg0b2Lp1Kxs3bqS6uprLL7+cK6+8kuXLl7/luaMtViNwTaGISDkMPZzswoUL+cQnPsHZZ58NQG1tLd/97ndZs2YNf/7nf04QBKRSKW666SYArrjiChYuXEhra+uor8Q0dx/VP3gg8+fP92XLlh3Wc3/7pidIJwPu+P3SHWtXRMpv1apVzJ07t9xllMz+/r1m9qy7z9932XhNoWgOXERkrxgFuKZQRESGik2AZ7QSU6RilXKqt5wO9d8ZmwDPJhP0awQuUnGy2SydnZ0TPsTdnc7OTrLZ7IifE7OtUDQCF6k0M2bMoL29ncM9n0CcZLNZZsyYMeLl4xHgv7yV312/hJ/kPl3uSkSkxFKpFLNnzy53GeNSPKZQtrVx4q7HdE5MEZEh4hHgmTrSYQ9hoUAuVIiLiECMAtxwqunXPLiISCQmAV4LQC292hZcRCQSkwCvB6DOejQCFxGJxCTA6wCooY9+7cwjIgLELMBrTVMoIiKD4hHg6eIceB29mkIREYnEI8AHR+BaiSkisldMAry4ErPGNAIXERkUkwAfshmhVmKKiABxCfBkBg/S1GklpojIXvEIcMAzddEcuEbgIiIQowAnU0eN9SnARUQisQlwy9ZRRy+7e3PlLkVEZFyIT4Cn62hI9LFLAS4iAsQowMnU0WC9CnARkUisArzWNAIXERkUqwCvQSNwEZFBsQrwau9RgIuIRGIV4Gnvp6unv9yViIiMC7EKcICwbzfuXuZiRETKL3YBngm7tTu9iAgxDPBabUooIgLEKcDTbxyRUAEuIhKnAN97YmMFuIgIjCDAzSxrZs+Y2fNm9iszuy5qn2xmD5hZW3Q9aUwrHXJi4509A2P6UiIicTCSEXg/8JvufhpwOnCBmZ0FXA0sdfc5wNLo/tjRHLiIyJscNMC9qCu6m4ouDlwM3B613w5cMiYVDooCvA7tzCMiAiOcAzezhJmtALYCD7j708BUd98EEF1PGea5V5jZMjNb1tHRcfiVpmtxC2iwbh1SVkSEEQa4u4fufjowAzjTzE4Z6Qu4+y3uPt/d57e0tBxunRAEWLaRlqRG4CIicIhbobj7TuAR4AJgi5m1AkTXW0e9un1VNdKU0By4iAiMbCuUFjNrjG5XAe8HVgOLgUXRYouAe8aqyL2qJjE56FaAi4gAyREs0wrcbmYJioF/l7v/1MyeBO4ys88CrwO/M4Z1FlVNopHXFeAiIowgwN39BeCM/bR3Au8bi6KGlW2kjlUKcBER4rQnJkDVJGoLe9jVmy93JSIiZTeSKZTxo6qRbNjF7lwf7o6ZlbsiEZGyid0IPKBANuxhd59G4SJS2eIV4NlGAOqtm84unZlHRCpbvAK8qni8rEa62NalA1qJSGWLWYAXR+AN1s02jcBFpMLFLMAHR+CaQhERiVeAZ98YgXdoCkVEKly8AjyaQmlN92oKRUQqXrwCPFUFySxTU72aQhGRihevHXkAqibREvZqKxQRqXjxGoEDZBuZFPRoBC4iFS9+AV41iQZtBy4iEscAb6TOu+jqz9OXC8tdjYhI2cQwwCdRFe4G0JYoIlLR4hfg2UYy+cEA1zSKiFSu+AV47RSS+R5q6GXbHo3ARaRyxS/A66cDcJRtp7NbAS4ilSuGAT4NgKm2Q1MoIlLRYhvgx6Z3smV3X5mLEREpn/gFeF0rAMdndrN5lwJcRCpX/HalT2WhuomZwU42awQuIhUsfiNwgPpptNp2jcBFpKLFNMCn01zYRkdXP7mwUO5qRETKIqYBPo36XAfu0KFtwUWkQsU2wLMDO8gwoHlwEalYMQ3w4s48U22H5sFFpGLFNMCL24K3ohWZIlK5YhrgxRH4jOQOTaGISMWKZ4BHO/OckN2lEbiIVKx4BnimFrKNzEppDlxEKlc8AxygcSYzbJumUESkYsU3wBuOpqXQwebdfbh7uasRESm5+AZ440waBzYzkA91WFkRqUjxDfCGmaTDburpZsPO3nJXIyJScvEN8MaZAMywbazf3lPmYkRESi++Ad5QDPDpto32HRqBi0jliW+ANx4NwJzMDtp3aAQuIpXnoAFuZjPN7GEzW2VmvzKzz0ftk83sATNri64njX25Q1Q3QbKKEzI7Wa8RuIhUoJGMwPPAF9x9LnAW8DkzOwm4Gljq7nOApdH90jGDhhkcnezUCFxEKtJBA9zdN7n78uj2HmAVMB24GLg9Wux24JKxKnJYjTNp9Q7ad/RSKGhbcBGpLIc0B25ms4AzgKeBqe6+CYohD0wZ5jlXmNkyM1vW0dFxZNXuq2Emk3KbGcgX2NalEzuISGUZcYCbWS1wN/Cn7r57pM9z91vcfb67z29paTmcGofXeDTZgR1U0ad5cBGpOCMKcDNLUQzv77n7j6LmLWbWGj3eCmwdmxIPoOk4AGbbZs2Di0jFGclWKAbcCqxy9xuGPLQYWBTdXgTcM/rlHUTTHACOtU3aFlxEKk5yBMucA3wSeNHMVkRt/we4HrjLzD4LvA78ztiUeADRCPyUbAfrOrtL/vIiIuV00AB398cBG+bh941uOYcoVQUNMzm5fwtLtynARaSyxHdPzEFNxzPLNrGuQwEuIpUl/gHePIepA+vp7O5nV0+u3NWIiJRM/AO8aQ7psJsWdrFuW1e5qxERKZkJEODFFZnH2iZe0Ty4iFSQ+Ad4c3FTwuMTCnARqSzxD/D6GZCs4u3ZrVqRKSIVJf4BHgTQfDwnpTaxTiNwEakg8Q9wgJa5zAzX88q2Lh2VUEQqxgQJ8BNpHNhMIqcTHItI5ZggAf42AI63DazaNOIDJYqIxNqECvA5wQZeUoCLSIWYGAE+aRYkMsyv3qoRuIhUjIkR4IkkNM/hlPRGjcBFpGJMjAAHaDmRo8P1rN/ey65eHRNFRCa+CRTgc6nv20g1fazWKFxEKsDECfCpJwNwkr2qeXARqQgTJ8CnzwPg7KrXWblRAS4iE9/ECfC6o6BuGu+qep0V63eWuxoRkTE3cQIcYPo85hbWsGZrl1ZkisiEN7ECfNoZNPa+Tj3dPK9RuIhMcBMuwAFODV5h+es7ylyMiMjYmpAB/r76dp57XSNwEZnYJlaAV0+GycdxVnodK9bv1KFlRWRCm1gBDjDrXI7veZ49vf20bdVJjkVk4pp4AT77PNL5PZxsr7J09ZZyVyMiMmYmXoDPOheAj05ax4MvKcBFZOKaeAFedxQ0n8hvZlbz3PqddOzpL3dFIiJjYuIFOMDsdzNzzwoSnufh1VvLXY2IyJiYmAF+7Pkk8j18uO5lfvbipnJXIyIyJiZmgM9ZAFWT+cP6p3i0rYNXt3WXuyIRkVE3MQM8mYG3/y4n7HyUJuvi3598rdwViYiMuokZ4ABnXI6FA1w940V+sGw93f35clckIjKqJm6AH3UKTJvHRf0/o6t/gB89t6HcFYmIjKqJG+AA7/ojsrvW8ZmW1fz7E6/irl3rRWTimNgBPvdiaDya/5X8KW1bu3hibWe5KxIRGTUTO8ATSTj7j2nesYL3V7dx6+OvlLsiEZFRM7EDHGDeJ6H2KK6r/QkPrd7CczpOuIhMEBM/wFNVcN6VTN/9HBdWr+arS35d7opEREbFQQPczG4zs61mtnJI22Qze8DM2qLrSWNb5hGa9ylomMmXa37Ak2s6eKyto9wViYgcsZGMwP8NuGCftquBpe4+B1ga3R+/khlYcB3Ne1bzubrH+PK9L5EPC+WuSkTkiBw0wN39UWD7Ps0XA7dHt28HLhnlukbfyb8Fs8/jT7iTzq0b+e5T2jtTROLtcOfAp7r7JoDoespwC5rZFWa2zMyWdXSUcerCDC78Ksmwh39o+jFfW/Iym3f1la8eEZEjNOYrMd39Fnef7+7zW1paxvrlDqzlROzsz/Ge7v/i5MJq/vInL2rnHhGJrcMN8C1m1goQXcfnoNvn/QXUT+cbDd/lkVUbWfz8xnJXJCJyWA43wBcDi6Lbi4B7RqecEsjUwsKv0NT1Mn/Z9AjX3fsSnV06a4+IxM9INiO8E3gSONHM2s3ss8D1wAIzawMWRPfjY+6H4W0X8an+O5jUt54v3ftSuSsSETlkI9kK5ePu3uruKXef4e63ununu7/P3edE1/tupTL+Xfj3BMksdzbexJLnX+UBnQBZRGJm4u+JOZz6afBbtzCl+2W+Xn8HX/zxi+zqzZW7KhGREavcAAc44YPw7i+wcGAJ7+19gKt++IK2ShGR2KjsAAc4/4sw+zz+Nv1tXnvpaf710XXlrkhEZEQU4EECLr2NRM1kbq/9F276z+X8Ys22clclInJQCnCA2hbst79NS34z/1JzK398x3I27Owtd1UiIgekAB90zNnYgi/z7vyTfDy8l898+5daqSki45oCfKizPwdzP8yVwfeY0vkUv//vy+jLheWuSkRkvxTgQ5nBxd/Amufw7cwNBK89zp/dtYKwoC1TRGT8UYDvK9sAi+4lOfkYvpP9KutXPsH/++lL2rxQRMYdBfj+1E6BTy0mVT+FO2u+xkNPavNCERl/FODDqZsKl/+ImpRxT83fcNd/PsSNj6zRSFxExg0F+IE0z8EW3Utjxrin+m+4578e4O/uX60QF5FxQQF+MEedgv3P+6itruLH1X/L048t4aq7XyCnc2qKSJkpwEei5QTsM/dTVTeJu6v+hv7l3+fybz2t44iLSFkpwEdq0izs9x8iOfOd/GP6RhZs+AaX/POjrNywq9yViUiFUoAfippm+NRP4J2/x+8F9/KV3N/y6Zsf0GnZRKQsFOCHKpGCD30NLvoHzuYFfpK+lhu/fw9/d98q8poXF5ESUoAfrvmfwRbdy7SqPPdmr6X7F//KJ7/1NOu395S7MhGpEArwI3HMu7A//AWp487jr1Pf5tMbr+V3/2ExN/98rXa/F5ExpwA/UrUt8IkfwAf+mgWJ53gg9QXal/wzH7/5cV7esqfc1YnIBGal3Cll/vz5vmzZspK9Xsl1vIzf9wXslUdZyXF8aeCTvO3M9/O/338CTbWZclcnIjFlZs+6+/x92zUCH00tJ2CfWgyX3spJNV38MP0l3rX8C1z+1e/zz0vb2NOn44uLyOhRgI82Mzj1twn+ZDm89xouSL/AvfwZkx6+ikuv/wH/8lAbuxXkIjIKNIUy1vZshp9/hcLy71AoOHfm38sdwUWc/c7f4NPnzGLm5OpyVygi49xwUygK8FLZuR4ev4HC8u8QFHI8XjiF74XvJzn3IhadexzvOGYSZlbuKkVkHFKAjxd7NsPy7xAu+zaJPRvYwiS+nz+fx+su5Jx3nMYlp09nVnNNuasUkXFEAT7ehHloW0L+mVtJrFuKYzxRmMuScD6bjzqfs844nQ+echTTG6vKXamIlJkCfDzb/go89x1yKxeT2tEGwMrCLJaE83ml+T287bSz+cDJR3H8lFpNs4hUIAV4XGxrg9U/o2/lYjKbl2M46wstPFB4B09nziZ73DmcedwUzjq2iWObaxToIhVAAR5He7bAy/fTt/JeUq89SqIwwABJfl2YwS8Kp/JcZr4CXaQCKMDjrr8L1j6Ety+j77Vfkt74DAnP002W5eHxLPcTWJM+iezsMzltzizOOnYys5trSQQKdJG4U4BPNP17YN3P8bUPkXv1SZLbVhNQPJzt2kIrq30maziG3fUn0DD7NI46+m3MaqljdnMNzbVpjdRFYkQBPtH174ENy/H1z9Dz+nIKm1ZS27Meo/j+dnuGNp/OK97KxmAa3XWzCJqOo6b1bUxvncr0xixHNVQxtS5DMqEddEXGk+ECPFmOYmQMZOrg2Pdgx76HvVuRD3TD1tWEm1cSvv48R29ZxfG71lHd9wRBl0MX8Bp0eD2v+lGs8EZ2UcuO9DS6ao4h3zibzOQZNE6ewrRJ1bQ2ZJnWWEVzbUZTMyLjgEbglSjXW9x0cftaclvb6N70a+hcg/V0kurfQXV+55sW7/cUW72R7dSx02vZSR2d6en0VLXimVosU4tl6qGmmfrJU5k6ZSpHN9dSn02RSgSkkwF1mSSBQl/ksGgELm9IVcHUk2DqSaTmQuO+j/ftgs61sOMVfPcmfMcm6nZsoKqrk+m920n2raO+/0mCrkJxFL+PvAfsoI5Or2eH19FJHTupZyAzGa9qIp+uYyDIkqmuI5GppZCsIl1dT3VtHVXV9SSrakinUmSSCdLJgHQiIJMqXqeTxUsmmSATPaYvBqlUCnB5q2wDTJ8H0+dhQDa6vEmuD7q3Fqdp+ruKod/TSe/OLezevpn+XVuo7d3O5P4dzB3YTKZ/FVX53TDCc1z0eYoeMvSSodcz9JEmB+wiyW6vZjfVdHkVAyQJLUUuyNAXVBMGGSxIQiIJiTRhIkMhkcWTWTxZBckslsyQSKVJJJMkEmmS6TTJZJpEMk0qlSKZLl4Xv0SiL41E4k1fInvbkwGpICAwIwggMCMRGJlkoBXFMuaOKMDN7ALgH4EE8C13v35UqpLxL5WFxqPf0lwVXfYrzEPv9uIK14Hu4iXXDQM95Pu76OveQ1/PHgr9PfhAFz7QQyLXQ12uh7pcL+4OYY6Zud0kc5tI5bsICnmCQo5UoZ/AQwgpXkbhiL0FN/IE5ElG1wlCEuRIEHqCARL0kiAftfWTos/TDJACIBlAwoqX0JL0WDU9QQ0FS5ImR4GAHEnylqQQpLAghSUSJIIEFiSKr1kwcl68JBNJMukUfXkjbwkSiSSJRIJkorh8V65Af95xAuqq0tRk02CGW4AT4FjxPgZD2oqPF6/NjFTYTSbspjfZABjpsBdLZiFdjaerwQLAogt49KUVBAGBFX8RBVa8YEZgAQy2JZIQpEgkiv/mvCUouFFwcJxUovjlmEoEdPfnCQtONp0gm0yQShSXCwtOwYsXD0PwPJ7I4IWQIOwjDDIQJIqDj1SCbCpBMjC6e/sJ3UgO+Vv9uRz9IYShkwgMM/bWPviFXLxQ/Hd5WPx3Bon9L3OA59ZnU6STo7uBwGEHuJklgG8AC4B24JdmttjdXxqt4mSCSSShdkrxso8kUBtdDos75HogHIBCCGEOwv7iL4V875Dr3uIyYR4KeSjkoJCnkM+Rz+cIcwOEYY4wlyMMcxTyOQqD1/kBPMzjYQ4P8yQLORJhnkwhhxVyBIUcibCPoNCLO4QOBYcCRuA5smE72bCbpOcYsAwBBRKeJ0mOlFfuMeILXtxWyoDAiuvkQjcKBBQofuEUCHAoftHwxi+bGvoIzOnxDGlyJK24KW2fpxggVexjCiQJSVlI6EY3VSQIyUTL5z2gjzT9pCgw/K+mDHnqrXjS8h7P0Ft8RUICCl6sNSQgHPI3Bmt1jPUL/p4z3v2hUe27IxmBnwmscfd1AGb2feBiQAEupWcG6Rrg8I7kGADpUS3owN4yJeVe/OLxAngY3Y7uFwpDbueLjxWiLyAvFJ/rhX0u+2uLLviBl0vXFrdq6tlerC1dQ5jrJ9+3h7C/u/icaPPU4vOdghcoFAr44Mi44LgXL+C4F6K2kEKYgzCHFULM8yQ8X4w5M8IChO4UwgKpBAQ4YZgnH4Z4oRivZhRj3Iw9qRo8kSbZv4tCIkshXYOF/STyvZDvJ/SAHAEhCZLpKgLPEwzsIW9JPEgTpNKkPE+i0Ifl+6O+KX7xFn8T7P0n0h8k6Ew14hQIcr0E+R5s8P3wkMALBB4Wu4fikzzqI3eYPvWtA5cjdSQBPh1YP+R+O/AbR1aOSIUyK/5CGacS0UXGlyOZkNnfb423bJNoZleY2TIzW9bR0XEELyciIkMdSYC3AzOH3J8BbNx3IXe/xd3nu/v8lpaWI3g5EREZ6kgC/JfAHDObbWZp4GPA4tEpS0REDuawJ93cPW9mfwT8F8Xpsdvc/VejVpmIiBzQEa01cff7gPtGqRYRETkEOuyciEhMKcBFRGJKAS4iElMlPZysmXUArx3m05uBbaNYzmgZr3XB+K1NdR2a8VoXjN/aJlpdx7j7W7bDLmmAHwkzW7a/4+GW23itC8Zvbarr0IzXumD81lYpdWkKRUQkphTgIiIxFacAv6XcBQxjvNYF47c21XVoxmtdMH5rq4i6YjMHLiIibxanEbiIiAyhABcRialYBLiZXWBmvzazNWZ2dRnrmGlmD5vZKjP7lZl9Pmr/kpltMLMV0eXCMtT2qpm9GL3+sqhtspk9YGZt0fWkEtd04pA+WWFmu83sT8vVX2Z2m5ltNbOVQ9qG7SMzuyb6zP3azD5Y4rr+3sxWm9kLZvZjM2uM2meZWe+Qvru5xHUN+96Vub/+Y0hNr5rZiqi9lP01XD6M3Wds8LRH4/VC8UiHa4FjKZ716nngpDLV0grMi27XAS8DJwFfAq4scz+9CjTv0/b/gauj21cDXynz+7gZOKZc/QWcB8wDVh6sj6L39XkgA8yOPoOJEtb1ASAZ3f7KkLpmDV2uDP213/eu3P21z+NfA64tQ38Nlw9j9hmLwwh877k33X0AGDz3Zsm5+yZ3Xx7d3gOsonhqufHqYuD26PbtwCVlrOV9wFp3P9w9cY+Yuz8KbN+nebg+uhj4vrv3u/srwBqKn8WS1OXuS9w9H919iuIJU0pqmP4aTln7a5CZGXAZcOdYvPaBHCAfxuwzFocA39+5N8semmY2CzgDeDpq+qPo5+5tpZ6qiDiwxMyeNbMrorap7r4Jih8uYPTPqjpyH+PN/6nK3V+Dhuuj8fS5+wxw/5D7s83sOTP7uZm9uwz17O+9Gy/99W5gi7u3DWkreX/tkw9j9hmLQ4CP6NybpWRmtcDdwJ+6+27gJuA44HRgE8WfcKV2jrvPAxYCnzOz88pQw35Z8YxNHwF+EDWNh/46mHHxuTOzLwJ54HtR0ybgaHc/A/gz4A4zqy9hScO9d+Oiv4CP8+aBQsn7az/5MOyi+2k7pD6LQ4CP6NybpWJmKYpvzvfc/UcA7r7F3UN3LwDfZIx+Oh6Iu2+MrrcCPyQylcEAAAGLSURBVI5q2GJmrVHdrcDWUtcVWQgsd/ctUY1l768hhuujsn/uzGwRcBHwPzyaNI1+bndGt5+lOG96QqlqOsB7Nx76Kwn8FvAfg22l7q/95QNj+BmLQ4CPm3NvRvNrtwKr3P2GIe2tQxb7KLBy3+eOcV01ZlY3eJviCrCVFPtpUbTYIuCeUtY1xJtGReXur30M10eLgY+ZWcbMZgNzgGdKVZSZXQBcBXzE3XuGtLeYWSK6fWxU17oS1jXce1fW/oq8H1jt7u2DDaXsr+HygbH8jJVi7eworN29kOIa3bXAF8tYx7kUf+K8AKyILhcC3wFejNoXA60lrutYimuznwd+NdhHQBOwFGiLrieXoc+qgU6gYUhbWfqL4pfIJiBHcfTz2QP1EfDF6DP3a2BhietaQ3F+dPBzdnO07KXRe/w8sBz4cInrGva9K2d/Re3/BvzhPsuWsr+Gy4cx+4xpV3oRkZiKwxSKiIjshwJcRCSmFOAiIjGlABcRiSkFuIhITCnARURiSgEuIhJT/w2CX5znylPHWQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[341   0   1   1]\n",
      " [  0 339  10   0]\n",
      " [  4  16 326   1]\n",
      " [  0   0   2 359]]\n",
      "0.975\n",
      "[[156   0   1   0]\n",
      " [  0 146   5   0]\n",
      " [  1   4 147   1]\n",
      " [  0   0   0 139]]\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "train_predicted=saved_model.predict(trainX)\n",
    "test_predicted=saved_model.predict(testX)\n",
    "\n",
    "#Confusion Matrix for Training\n",
    "from sklearn import metrics\n",
    "confusion = metrics.confusion_matrix(trainy.argmax(axis=1), train_predicted.argmax(axis=1))\n",
    "print(confusion)\n",
    "\n",
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(trainy.argmax(axis=1), train_predicted.argmax(axis=1)))\n",
    "\n",
    "#Confusion Matrix for Testing\n",
    "from sklearn import metrics\n",
    "confusion1 = metrics.confusion_matrix(testy.argmax(axis=1), test_predicted.argmax(axis=1))\n",
    "print(confusion1)\n",
    "\n",
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(testy.argmax(axis=1), test_predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99363057 0.96688742 0.96078431 1.        ]\n",
      "[0.99774266 0.99109131 0.98657718 0.9978308 ]\n",
      "[0.99666667 0.985      0.98       0.99833333]\n"
     ]
    }
   ],
   "source": [
    "FP = confusion1.sum(axis=0) - np.diag(confusion1)  \n",
    "FN = confusion1.sum(axis=1) - np.diag(confusion1)\n",
    "TP = np.diag(confusion1)\n",
    "TN = confusion1.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(TPR)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "print(TNR)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Recurrent Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short Term Memory Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot\n",
    "from keras.models import load_model\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split Training and Testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We specify this so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "\n",
    "X , y = dataframe1.loc[:, dataframe1.columns != 'Room'] ,dataframe1.loc[:, dataframe1.columns == 'Room']\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, random_state = 0,train_size = 0.7, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln=len(trainX.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=np.array(trainX)\n",
    "trainy=np.array(trainy)\n",
    "testy=np.array(testy)\n",
    "testX=np.array(testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.reshape(len(trainX),1,ln)\n",
    "testX = testX.reshape(len(testX),1,ln)\n",
    "trainy = trainy.reshape(len(trainy),1)\n",
    "testy = testy.reshape(len(testy),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1, 7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 1, 7)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(trainy)\n",
    "trainy = encoder.transform(trainy)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "trainy = np_utils.to_categorical(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(testy)\n",
    "testy = encoder.transform(testy)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "testy = np_utils.to_categorical(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(300,activation='relu'))\n",
    "model_lstm.add(Dense(200, activation='relu'))\n",
    "model_lstm.add(Dense(50, activation='relu'))\n",
    "model_lstm.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model with SGD\n",
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('best_model_lstm.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/200\n",
      "1400/1400 [==============================] - 1s 789us/step - loss: nan - accuracy: 0.2464 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 2/200\n",
      " 544/1400 [==========>...................] - ETA: 0s - loss: nan - accuracy: 0.2537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n",
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 0s 347us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 3/200\n",
      "1400/1400 [==============================] - 0s 336us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 4/200\n",
      "1400/1400 [==============================] - 0s 329us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 5/200\n",
      "1400/1400 [==============================] - 0s 313us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 6/200\n",
      "1400/1400 [==============================] - 0s 344us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 7/200\n",
      "1400/1400 [==============================] - 1s 392us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 8/200\n",
      "1400/1400 [==============================] - 0s 347us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 9/200\n",
      "1400/1400 [==============================] - 1s 365us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 10/200\n",
      "1400/1400 [==============================] - 0s 334us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 11/200\n",
      "1400/1400 [==============================] - 0s 341us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 12/200\n",
      "1400/1400 [==============================] - 0s 332us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 13/200\n",
      "1400/1400 [==============================] - 0s 316us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 14/200\n",
      "1400/1400 [==============================] - 0s 319us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 15/200\n",
      "1400/1400 [==============================] - 1s 380us/step - loss: nan - accuracy: 0.2450 - val_loss: nan - val_accuracy: 0.2617\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model_lstm.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=1, callbacks=[es, mc])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "#saved_model = load_model('best_model_lstm.h5')\n",
    "saved_model = model_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.245, Test: 0.262\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = saved_model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[343   0   0   0]\n",
      " [349   0   0   0]\n",
      " [347   0   0   0]\n",
      " [361   0   0   0]]\n",
      "0.245\n",
      "[[157   0   0   0]\n",
      " [151   0   0   0]\n",
      " [153   0   0   0]\n",
      " [139   0   0   0]]\n",
      "0.26166666666666666\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "train_predicted=saved_model.predict(trainX)\n",
    "test_predicted=saved_model.predict(testX)\n",
    "\n",
    "#Confusion Matrix for Training\n",
    "from sklearn import metrics\n",
    "confusion = metrics.confusion_matrix(trainy.argmax(axis=1), train_predicted.argmax(axis=1))\n",
    "print(confusion)\n",
    "\n",
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(trainy.argmax(axis=1), train_predicted.argmax(axis=1)))\n",
    "\n",
    "#Confusion Matrix for Testing\n",
    "from sklearn import metrics\n",
    "confusion1 = metrics.confusion_matrix(testy.argmax(axis=1), test_predicted.argmax(axis=1))\n",
    "print(confusion1)\n",
    "\n",
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(testy.argmax(axis=1), test_predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0.]\n",
      "[0. 1. 1. 1.]\n",
      "[0.26166667 0.74833333 0.745      0.76833333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved deo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\ved deo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\ved deo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "FP = confusion1.sum(axis=0) - np.diag(confusion1)  \n",
    "FN = confusion1.sum(axis=1) - np.diag(confusion1)\n",
    "TP = np.diag(confusion1)\n",
    "TN = confusion1.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(TPR)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "print(TNR)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Regularization Parameter + Drop Out + ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model with Regularization and drop out for stopping Overfitting\n",
    "# try with diff regularisation\n",
    "from keras import regularizers\n",
    "model_lstm_adm = Sequential()\n",
    "model_lstm_adm.add(LSTM(300, activation='relu',kernel_regularizer=regularizers.l1(0.01)))\n",
    "model_lstm_adm.add(Dropout(0.6, noise_shape=None, seed=None))\n",
    "model_lstm_adm.add(Dense(200,activation='relu',kernel_regularizer=regularizers.l1(0.01)))\n",
    "model_lstm_adm.add(Dense(50, activation='relu'))\n",
    "model_lstm_adm.add(Dense(4, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Model\n",
    "model_lstm_adm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('best_model_lstm_reg.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/200\n",
      "1400/1400 [==============================] - 1s 539us/step - loss: 38.4818 - accuracy: 0.2421 - val_loss: 33.9613 - val_accuracy: 0.3967\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 0s 298us/step - loss: 34.9525 - accuracy: 0.2514 - val_loss: 33.4070 - val_accuracy: 0.2617\n",
      "Epoch 3/200\n",
      "1400/1400 [==============================] - 0s 309us/step - loss: 33.4944 - accuracy: 0.2507 - val_loss: 32.1683 - val_accuracy: 0.2617\n",
      "Epoch 4/200\n",
      "1400/1400 [==============================] - 0s 289us/step - loss: 32.0928 - accuracy: 0.2729 - val_loss: 30.8928 - val_accuracy: 0.2617\n",
      "Epoch 5/200\n",
      "1400/1400 [==============================] - 0s 305us/step - loss: 30.9472 - accuracy: 0.2343 - val_loss: 29.8495 - val_accuracy: 0.2633\n",
      "Epoch 6/200\n",
      "1400/1400 [==============================] - 0s 307us/step - loss: 29.8626 - accuracy: 0.2686 - val_loss: 28.8759 - val_accuracy: 0.4883\n",
      "Epoch 7/200\n",
      "1400/1400 [==============================] - 0s 308us/step - loss: 28.8392 - accuracy: 0.2593 - val_loss: 27.9263 - val_accuracy: 0.2667\n",
      "Epoch 8/200\n",
      "1400/1400 [==============================] - 0s 296us/step - loss: 27.8503 - accuracy: 0.2729 - val_loss: 26.9884 - val_accuracy: 0.2583\n",
      "Epoch 9/200\n",
      "1400/1400 [==============================] - 0s 294us/step - loss: 26.8915 - accuracy: 0.2979 - val_loss: 26.0824 - val_accuracy: 0.2533\n",
      "Epoch 10/200\n",
      "1400/1400 [==============================] - 0s 317us/step - loss: 25.9593 - accuracy: 0.2900 - val_loss: 25.1696 - val_accuracy: 0.2467\n",
      "Epoch 11/200\n",
      "1400/1400 [==============================] - 0s 308us/step - loss: 25.0444 - accuracy: 0.3029 - val_loss: 24.2668 - val_accuracy: 0.2917\n",
      "Epoch 12/200\n",
      "1400/1400 [==============================] - 0s 336us/step - loss: 24.1247 - accuracy: 0.3229 - val_loss: 23.3790 - val_accuracy: 0.2667\n",
      "Epoch 13/200\n",
      "1400/1400 [==============================] - 0s 312us/step - loss: 23.2367 - accuracy: 0.3364 - val_loss: 22.4925 - val_accuracy: 0.4033\n",
      "Epoch 14/200\n",
      "1400/1400 [==============================] - 0s 315us/step - loss: 22.3580 - accuracy: 0.3629 - val_loss: 21.6210 - val_accuracy: 0.2950\n",
      "Epoch 15/200\n",
      "1400/1400 [==============================] - 0s 286us/step - loss: 21.4953 - accuracy: 0.3786 - val_loss: 20.7838 - val_accuracy: 0.4550\n",
      "Epoch 16/200\n",
      "1400/1400 [==============================] - 1s 365us/step - loss: 20.6488 - accuracy: 0.4100 - val_loss: 19.8982 - val_accuracy: 0.3800\n",
      "Epoch 17/200\n",
      "1400/1400 [==============================] - 0s 347us/step - loss: 19.7934 - accuracy: 0.4093 - val_loss: 19.1325 - val_accuracy: 0.5683\n",
      "Epoch 18/200\n",
      "1400/1400 [==============================] - 0s 300us/step - loss: 18.9912 - accuracy: 0.4543 - val_loss: 18.2542 - val_accuracy: 0.6083\n",
      "Epoch 19/200\n",
      "1400/1400 [==============================] - 0s 301us/step - loss: 18.1918 - accuracy: 0.4857 - val_loss: 17.4928 - val_accuracy: 0.6650\n",
      "Epoch 20/200\n",
      "1400/1400 [==============================] - 0s 289us/step - loss: 17.4407 - accuracy: 0.4743 - val_loss: 16.9351 - val_accuracy: 0.3267\n",
      "Epoch 21/200\n",
      "1400/1400 [==============================] - 1s 364us/step - loss: 16.8379 - accuracy: 0.3757 - val_loss: 16.1871 - val_accuracy: 0.4333\n",
      "Epoch 22/200\n",
      "1400/1400 [==============================] - 0s 338us/step - loss: 16.0784 - accuracy: 0.4307 - val_loss: 15.2863 - val_accuracy: 0.6433\n",
      "Epoch 23/200\n",
      "1400/1400 [==============================] - 0s 322us/step - loss: 15.2738 - accuracy: 0.5129 - val_loss: 14.6264 - val_accuracy: 0.5367\n",
      "Epoch 24/200\n",
      "1400/1400 [==============================] - 0s 328us/step - loss: 14.5607 - accuracy: 0.5371 - val_loss: 13.9833 - val_accuracy: 0.6633\n",
      "Epoch 25/200\n",
      "1400/1400 [==============================] - 0s 341us/step - loss: 13.9157 - accuracy: 0.5600 - val_loss: 13.2286 - val_accuracy: 0.7000\n",
      "Epoch 26/200\n",
      "1400/1400 [==============================] - 0s 318us/step - loss: 13.1706 - accuracy: 0.6171 - val_loss: 12.5742 - val_accuracy: 0.6450\n",
      "Epoch 27/200\n",
      "1400/1400 [==============================] - 0s 323us/step - loss: 12.5451 - accuracy: 0.6086 - val_loss: 11.8178 - val_accuracy: 0.8433\n",
      "Epoch 28/200\n",
      "1400/1400 [==============================] - 1s 367us/step - loss: 11.8335 - accuracy: 0.6871 - val_loss: 11.2149 - val_accuracy: 0.7617\n",
      "Epoch 29/200\n",
      "1400/1400 [==============================] - 0s 320us/step - loss: 11.1993 - accuracy: 0.6950 - val_loss: 10.4908 - val_accuracy: 0.8667\n",
      "Epoch 30/200\n",
      "1400/1400 [==============================] - 0s 329us/step - loss: 10.5761 - accuracy: 0.7250 - val_loss: 9.8831 - val_accuracy: 0.8700\n",
      "Epoch 31/200\n",
      "1400/1400 [==============================] - 0s 287us/step - loss: 9.9183 - accuracy: 0.7886 - val_loss: 9.2431 - val_accuracy: 0.9233\n",
      "Epoch 32/200\n",
      "1400/1400 [==============================] - 0s 287us/step - loss: 9.3458 - accuracy: 0.8121 - val_loss: 8.7203 - val_accuracy: 0.9350\n",
      "Epoch 33/200\n",
      "1400/1400 [==============================] - 0s 284us/step - loss: 8.7834 - accuracy: 0.8436 - val_loss: 8.1873 - val_accuracy: 0.9367\n",
      "Epoch 34/200\n",
      "1400/1400 [==============================] - 0s 301us/step - loss: 8.2615 - accuracy: 0.8643 - val_loss: 7.7373 - val_accuracy: 0.9367\n",
      "Epoch 35/200\n",
      "1400/1400 [==============================] - 1s 362us/step - loss: 7.7901 - accuracy: 0.8771 - val_loss: 7.2713 - val_accuracy: 0.9283\n",
      "Epoch 36/200\n",
      "1400/1400 [==============================] - 1s 381us/step - loss: 7.2842 - accuracy: 0.9007 - val_loss: 6.7815 - val_accuracy: 0.9567\n",
      "Epoch 37/200\n",
      "1400/1400 [==============================] - 1s 387us/step - loss: 6.8023 - accuracy: 0.9357 - val_loss: 6.3882 - val_accuracy: 0.9517\n",
      "Epoch 38/200\n",
      "1400/1400 [==============================] - 0s 348us/step - loss: 6.4079 - accuracy: 0.9229 - val_loss: 5.9775 - val_accuracy: 0.9617\n",
      "Epoch 39/200\n",
      "1400/1400 [==============================] - 0s 308us/step - loss: 5.9911 - accuracy: 0.9421 - val_loss: 5.5969 - val_accuracy: 0.9617\n",
      "Epoch 40/200\n",
      "1400/1400 [==============================] - 1s 392us/step - loss: 5.6167 - accuracy: 0.9421 - val_loss: 5.2858 - val_accuracy: 0.9500\n",
      "Epoch 41/200\n",
      "1400/1400 [==============================] - 0s 316us/step - loss: 5.2685 - accuracy: 0.9386 - val_loss: 4.9341 - val_accuracy: 0.9567\n",
      "Epoch 42/200\n",
      "1400/1400 [==============================] - 0s 296us/step - loss: 4.9314 - accuracy: 0.9450 - val_loss: 4.6213 - val_accuracy: 0.9500\n",
      "Epoch 43/200\n",
      "1400/1400 [==============================] - 1s 378us/step - loss: 4.6179 - accuracy: 0.9443 - val_loss: 4.3047 - val_accuracy: 0.9617\n",
      "Epoch 44/200\n",
      "1400/1400 [==============================] - 0s 312us/step - loss: 4.3229 - accuracy: 0.9471 - val_loss: 4.0273 - val_accuracy: 0.9617\n",
      "Epoch 45/200\n",
      "1400/1400 [==============================] - 0s 296us/step - loss: 4.0184 - accuracy: 0.9543 - val_loss: 3.7488 - val_accuracy: 0.9633\n",
      "Epoch 46/200\n",
      "1400/1400 [==============================] - 0s 293us/step - loss: 3.7562 - accuracy: 0.9536 - val_loss: 3.5103 - val_accuracy: 0.9633\n",
      "Epoch 47/200\n",
      "1400/1400 [==============================] - 0s 343us/step - loss: 3.5255 - accuracy: 0.9514 - val_loss: 3.2899 - val_accuracy: 0.9667\n",
      "Epoch 48/200\n",
      "1400/1400 [==============================] - 0s 334us/step - loss: 3.3052 - accuracy: 0.9529 - val_loss: 3.0839 - val_accuracy: 0.9650\n",
      "Epoch 49/200\n",
      "1400/1400 [==============================] - 0s 296us/step - loss: 3.0917 - accuracy: 0.9564 - val_loss: 2.8902 - val_accuracy: 0.9650\n",
      "Epoch 50/200\n",
      "1400/1400 [==============================] - 0s 328us/step - loss: 2.8962 - accuracy: 0.9600 - val_loss: 2.7232 - val_accuracy: 0.9650\n",
      "Epoch 51/200\n",
      "1400/1400 [==============================] - 0s 301us/step - loss: 2.7174 - accuracy: 0.9629 - val_loss: 2.5711 - val_accuracy: 0.9650\n",
      "Epoch 52/200\n",
      "1400/1400 [==============================] - 0s 280us/step - loss: 2.5986 - accuracy: 0.9550 - val_loss: 2.4408 - val_accuracy: 0.9733\n",
      "Epoch 53/200\n",
      "1400/1400 [==============================] - 0s 280us/step - loss: 2.4599 - accuracy: 0.9614 - val_loss: 2.3216 - val_accuracy: 0.9683\n",
      "Epoch 54/200\n",
      "1400/1400 [==============================] - 0s 294us/step - loss: 2.3533 - accuracy: 0.9621 - val_loss: 2.2473 - val_accuracy: 0.9650\n",
      "Epoch 55/200\n",
      "1400/1400 [==============================] - 0s 277us/step - loss: 2.2530 - accuracy: 0.9664 - val_loss: 2.1506 - val_accuracy: 0.9750\n",
      "Epoch 56/200\n",
      "1400/1400 [==============================] - 0s 278us/step - loss: 2.1748 - accuracy: 0.9657 - val_loss: 2.0865 - val_accuracy: 0.9667\n",
      "Epoch 57/200\n",
      "1400/1400 [==============================] - 0s 278us/step - loss: 2.1167 - accuracy: 0.9621 - val_loss: 2.0169 - val_accuracy: 0.9667\n",
      "Epoch 58/200\n",
      "1400/1400 [==============================] - 0s 278us/step - loss: 2.0416 - accuracy: 0.9600 - val_loss: 1.9587 - val_accuracy: 0.9617\n",
      "Epoch 59/200\n",
      "1400/1400 [==============================] - 0s 277us/step - loss: 1.9699 - accuracy: 0.9564 - val_loss: 1.8747 - val_accuracy: 0.9667\n",
      "Epoch 60/200\n",
      "1400/1400 [==============================] - 0s 286us/step - loss: 1.8950 - accuracy: 0.9564 - val_loss: 1.7848 - val_accuracy: 0.9717\n",
      "Epoch 61/200\n",
      "1400/1400 [==============================] - 0s 311us/step - loss: 1.8230 - accuracy: 0.9643 - val_loss: 1.7244 - val_accuracy: 0.9767\n",
      "Epoch 62/200\n",
      "1400/1400 [==============================] - 0s 291us/step - loss: 1.7479 - accuracy: 0.9700 - val_loss: 1.6649 - val_accuracy: 0.9750\n",
      "Epoch 63/200\n",
      "1400/1400 [==============================] - 0s 274us/step - loss: 1.6891 - accuracy: 0.9693 - val_loss: 1.6225 - val_accuracy: 0.9767\n",
      "Epoch 64/200\n",
      "1400/1400 [==============================] - 0s 278us/step - loss: 1.6398 - accuracy: 0.9671 - val_loss: 1.5801 - val_accuracy: 0.9700\n",
      "Epoch 65/200\n",
      "1400/1400 [==============================] - 0s 276us/step - loss: 1.6027 - accuracy: 0.9643 - val_loss: 1.5460 - val_accuracy: 0.9667\n",
      "Epoch 66/200\n",
      "1400/1400 [==============================] - 0s 277us/step - loss: 1.5575 - accuracy: 0.9657 - val_loss: 1.5034 - val_accuracy: 0.9667\n",
      "Epoch 67/200\n",
      "1400/1400 [==============================] - 0s 280us/step - loss: 1.5145 - accuracy: 0.9650 - val_loss: 1.4698 - val_accuracy: 0.9683\n",
      "Epoch 68/200\n",
      "1400/1400 [==============================] - 0s 286us/step - loss: 1.4759 - accuracy: 0.9664 - val_loss: 1.4318 - val_accuracy: 0.9617\n",
      "Epoch 69/200\n",
      "1400/1400 [==============================] - 1s 412us/step - loss: 1.4681 - accuracy: 0.9550 - val_loss: 1.4593 - val_accuracy: 0.9483\n",
      "Epoch 70/200\n",
      "1400/1400 [==============================] - 1s 464us/step - loss: 1.4805 - accuracy: 0.9400 - val_loss: 1.3969 - val_accuracy: 0.9567\n",
      "Epoch 71/200\n",
      "1400/1400 [==============================] - 1s 363us/step - loss: 1.4443 - accuracy: 0.9357 - val_loss: 1.4135 - val_accuracy: 0.9400\n",
      "Epoch 72/200\n",
      "1400/1400 [==============================] - 1s 393us/step - loss: 1.4101 - accuracy: 0.9429 - val_loss: 1.4098 - val_accuracy: 0.9367\n",
      "Epoch 73/200\n",
      "1400/1400 [==============================] - 0s 305us/step - loss: 1.4289 - accuracy: 0.9314 - val_loss: 1.2911 - val_accuracy: 0.9700\n",
      "Epoch 74/200\n",
      "1400/1400 [==============================] - 0s 306us/step - loss: 1.3202 - accuracy: 0.9636 - val_loss: 1.2582 - val_accuracy: 0.9700\n",
      "Epoch 75/200\n",
      "1400/1400 [==============================] - 0s 296us/step - loss: 1.2670 - accuracy: 0.9686 - val_loss: 1.2427 - val_accuracy: 0.9667\n",
      "Epoch 76/200\n",
      "1400/1400 [==============================] - 0s 291us/step - loss: 1.2885 - accuracy: 0.9529 - val_loss: 1.1927 - val_accuracy: 0.9717\n",
      "Epoch 77/200\n",
      "1400/1400 [==============================] - 0s 294us/step - loss: 1.2222 - accuracy: 0.9636 - val_loss: 1.1572 - val_accuracy: 0.9767\n",
      "Epoch 78/200\n",
      "1400/1400 [==============================] - 0s 291us/step - loss: 1.1955 - accuracy: 0.9693 - val_loss: 1.1278 - val_accuracy: 0.9767\n",
      "Epoch 79/200\n",
      "1400/1400 [==============================] - 0s 312us/step - loss: 1.1651 - accuracy: 0.9671 - val_loss: 1.1135 - val_accuracy: 0.9733\n",
      "Epoch 80/200\n",
      "1400/1400 [==============================] - 0s 328us/step - loss: 1.1337 - accuracy: 0.9736 - val_loss: 1.0782 - val_accuracy: 0.9817\n",
      "Epoch 81/200\n",
      "1400/1400 [==============================] - 0s 297us/step - loss: 1.1079 - accuracy: 0.9700 - val_loss: 1.0603 - val_accuracy: 0.9767\n",
      "Epoch 82/200\n",
      "1400/1400 [==============================] - 0s 301us/step - loss: 1.0955 - accuracy: 0.9664 - val_loss: 1.0506 - val_accuracy: 0.9733\n",
      "Epoch 83/200\n",
      "1400/1400 [==============================] - 0s 333us/step - loss: 1.0763 - accuracy: 0.9714 - val_loss: 1.0226 - val_accuracy: 0.9767\n",
      "Epoch 84/200\n",
      "1400/1400 [==============================] - 1s 365us/step - loss: 1.0493 - accuracy: 0.9707 - val_loss: 1.0088 - val_accuracy: 0.9767\n",
      "Epoch 85/200\n",
      "1400/1400 [==============================] - 0s 336us/step - loss: 1.0348 - accuracy: 0.9750 - val_loss: 0.9780 - val_accuracy: 0.9817\n",
      "Epoch 86/200\n",
      "1400/1400 [==============================] - 0s 329us/step - loss: 0.9980 - accuracy: 0.9771 - val_loss: 0.9801 - val_accuracy: 0.9717\n",
      "Epoch 87/200\n",
      "1400/1400 [==============================] - 0s 291us/step - loss: 1.0033 - accuracy: 0.9679 - val_loss: 0.9587 - val_accuracy: 0.9783\n",
      "Epoch 88/200\n",
      "1400/1400 [==============================] - 0s 348us/step - loss: 0.9754 - accuracy: 0.9757 - val_loss: 0.9205 - val_accuracy: 0.9800\n",
      "Epoch 89/200\n",
      "1400/1400 [==============================] - 1s 392us/step - loss: 0.9485 - accuracy: 0.9736 - val_loss: 0.9064 - val_accuracy: 0.9817\n",
      "Epoch 90/200\n",
      "1400/1400 [==============================] - 0s 306us/step - loss: 0.9175 - accuracy: 0.9807 - val_loss: 0.8972 - val_accuracy: 0.9800\n",
      "Epoch 91/200\n",
      "1400/1400 [==============================] - 0s 299us/step - loss: 0.9128 - accuracy: 0.9779 - val_loss: 0.8742 - val_accuracy: 0.9800\n",
      "Epoch 92/200\n",
      "1400/1400 [==============================] - 0s 296us/step - loss: 0.8920 - accuracy: 0.9779 - val_loss: 0.8584 - val_accuracy: 0.9817\n",
      "Epoch 93/200\n",
      "1400/1400 [==============================] - 0s 334us/step - loss: 0.8768 - accuracy: 0.9786 - val_loss: 0.8484 - val_accuracy: 0.9817\n",
      "Epoch 94/200\n",
      "1400/1400 [==============================] - 0s 317us/step - loss: 0.8612 - accuracy: 0.9821 - val_loss: 0.8337 - val_accuracy: 0.9817\n",
      "Epoch 95/200\n",
      "1400/1400 [==============================] - 0s 293us/step - loss: 0.8524 - accuracy: 0.9793 - val_loss: 0.8246 - val_accuracy: 0.9817\n",
      "Epoch 96/200\n",
      "1400/1400 [==============================] - 0s 318us/step - loss: 0.8354 - accuracy: 0.9807 - val_loss: 0.8177 - val_accuracy: 0.9817\n",
      "Epoch 97/200\n",
      "1400/1400 [==============================] - 0s 335us/step - loss: 0.8290 - accuracy: 0.9743 - val_loss: 0.8124 - val_accuracy: 0.9783\n",
      "Epoch 98/200\n",
      "1400/1400 [==============================] - 0s 299us/step - loss: 0.8220 - accuracy: 0.9771 - val_loss: 0.7860 - val_accuracy: 0.9833\n",
      "Epoch 99/200\n",
      "1400/1400 [==============================] - 0s 303us/step - loss: 0.8049 - accuracy: 0.9764 - val_loss: 0.7825 - val_accuracy: 0.9817\n",
      "Epoch 100/200\n",
      "1400/1400 [==============================] - 0s 291us/step - loss: 0.8052 - accuracy: 0.9771 - val_loss: 0.7634 - val_accuracy: 0.9817\n",
      "Epoch 101/200\n",
      "1400/1400 [==============================] - 0s 299us/step - loss: 0.7824 - accuracy: 0.9800 - val_loss: 0.7558 - val_accuracy: 0.9833\n",
      "Epoch 102/200\n",
      "1400/1400 [==============================] - 0s 320us/step - loss: 0.7846 - accuracy: 0.9764 - val_loss: 0.7521 - val_accuracy: 0.9833\n",
      "Epoch 103/200\n",
      "1400/1400 [==============================] - 0s 291us/step - loss: 0.7676 - accuracy: 0.9836 - val_loss: 0.7413 - val_accuracy: 0.9817\n",
      "Epoch 104/200\n",
      "1400/1400 [==============================] - 0s 309us/step - loss: 0.7549 - accuracy: 0.9793 - val_loss: 0.7314 - val_accuracy: 0.9833\n",
      "Epoch 105/200\n",
      "1400/1400 [==============================] - 0s 294us/step - loss: 0.7397 - accuracy: 0.9800 - val_loss: 0.7148 - val_accuracy: 0.9817\n",
      "Epoch 106/200\n",
      "1400/1400 [==============================] - 0s 302us/step - loss: 0.7281 - accuracy: 0.9807 - val_loss: 0.7198 - val_accuracy: 0.9817\n",
      "Epoch 107/200\n",
      "1400/1400 [==============================] - 0s 300us/step - loss: 0.7352 - accuracy: 0.9743 - val_loss: 0.7000 - val_accuracy: 0.9833\n",
      "Epoch 108/200\n",
      "1400/1400 [==============================] - 0s 274us/step - loss: 0.7208 - accuracy: 0.9786 - val_loss: 0.6986 - val_accuracy: 0.9833\n",
      "Epoch 109/200\n",
      "1400/1400 [==============================] - 0s 283us/step - loss: 0.7142 - accuracy: 0.9750 - val_loss: 0.6923 - val_accuracy: 0.9800\n",
      "Epoch 110/200\n",
      "1400/1400 [==============================] - 0s 306us/step - loss: 0.7033 - accuracy: 0.9814 - val_loss: 0.6872 - val_accuracy: 0.9833\n",
      "Epoch 111/200\n",
      "1400/1400 [==============================] - 0s 306us/step - loss: 0.7017 - accuracy: 0.9800 - val_loss: 0.6821 - val_accuracy: 0.9817\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 0s 287us/step - loss: 0.6929 - accuracy: 0.9793 - val_loss: 0.6878 - val_accuracy: 0.9800\n",
      "Epoch 113/200\n",
      "1400/1400 [==============================] - 0s 303us/step - loss: 0.7026 - accuracy: 0.9750 - val_loss: 0.6542 - val_accuracy: 0.9817\n",
      "Epoch 114/200\n",
      "1400/1400 [==============================] - 0s 292us/step - loss: 0.6609 - accuracy: 0.9864 - val_loss: 0.6767 - val_accuracy: 0.9700\n",
      "Epoch 115/200\n",
      "1400/1400 [==============================] - 0s 292us/step - loss: 0.6773 - accuracy: 0.9764 - val_loss: 0.6530 - val_accuracy: 0.9750\n",
      "Epoch 116/200\n",
      "1400/1400 [==============================] - 0s 302us/step - loss: 0.6604 - accuracy: 0.9771 - val_loss: 0.6265 - val_accuracy: 0.9817\n",
      "Epoch 117/200\n",
      "1400/1400 [==============================] - 0s 276us/step - loss: 0.6447 - accuracy: 0.9786 - val_loss: 0.6224 - val_accuracy: 0.9833\n",
      "Epoch 118/200\n",
      "1400/1400 [==============================] - 0s 285us/step - loss: 0.6336 - accuracy: 0.9807 - val_loss: 0.6112 - val_accuracy: 0.9800\n",
      "Epoch 119/200\n",
      "1400/1400 [==============================] - 0s 287us/step - loss: 0.6185 - accuracy: 0.9829 - val_loss: 0.6152 - val_accuracy: 0.9817\n",
      "Epoch 120/200\n",
      "1400/1400 [==============================] - 0s 286us/step - loss: 0.6216 - accuracy: 0.9814 - val_loss: 0.6002 - val_accuracy: 0.9833\n",
      "Epoch 121/200\n",
      "1400/1400 [==============================] - 0s 290us/step - loss: 0.6277 - accuracy: 0.9750 - val_loss: 0.6448 - val_accuracy: 0.9650\n",
      "Epoch 122/200\n",
      "1400/1400 [==============================] - 0s 344us/step - loss: 0.6683 - accuracy: 0.9614 - val_loss: 0.6033 - val_accuracy: 0.9733\n",
      "Epoch 123/200\n",
      "1400/1400 [==============================] - 0s 335us/step - loss: 0.6371 - accuracy: 0.9686 - val_loss: 0.6013 - val_accuracy: 0.9800\n",
      "Epoch 124/200\n",
      "1400/1400 [==============================] - 0s 350us/step - loss: 0.6340 - accuracy: 0.9721 - val_loss: 0.5914 - val_accuracy: 0.9833\n",
      "Epoch 125/200\n",
      "1400/1400 [==============================] - 0s 345us/step - loss: 0.6126 - accuracy: 0.9786 - val_loss: 0.6138 - val_accuracy: 0.9733\n",
      "Epoch 126/200\n",
      "1400/1400 [==============================] - 0s 271us/step - loss: 0.6415 - accuracy: 0.9707 - val_loss: 0.6243 - val_accuracy: 0.9783\n",
      "Epoch 127/200\n",
      "1400/1400 [==============================] - 0s 347us/step - loss: 0.6474 - accuracy: 0.9707 - val_loss: 0.5883 - val_accuracy: 0.9833\n",
      "Epoch 128/200\n",
      "1400/1400 [==============================] - 0s 290us/step - loss: 0.6091 - accuracy: 0.9750 - val_loss: 0.5760 - val_accuracy: 0.9833\n",
      "Epoch 129/200\n",
      "1400/1400 [==============================] - 0s 322us/step - loss: 0.6012 - accuracy: 0.9793 - val_loss: 0.5771 - val_accuracy: 0.9800\n",
      "Epoch 130/200\n",
      "1400/1400 [==============================] - 0s 287us/step - loss: 0.5837 - accuracy: 0.9786 - val_loss: 0.5668 - val_accuracy: 0.9833\n",
      "Epoch 131/200\n",
      "1400/1400 [==============================] - 0s 296us/step - loss: 0.5795 - accuracy: 0.9829 - val_loss: 0.5573 - val_accuracy: 0.9833\n",
      "Epoch 132/200\n",
      "1400/1400 [==============================] - 0s 272us/step - loss: 0.5753 - accuracy: 0.9736 - val_loss: 0.5510 - val_accuracy: 0.9800\n",
      "Epoch 133/200\n",
      "1400/1400 [==============================] - 0s 272us/step - loss: 0.5567 - accuracy: 0.9793 - val_loss: 0.5548 - val_accuracy: 0.9783\n",
      "Epoch 134/200\n",
      "1400/1400 [==============================] - 0s 272us/step - loss: 0.5477 - accuracy: 0.9814 - val_loss: 0.5322 - val_accuracy: 0.9817\n",
      "Epoch 135/200\n",
      "1400/1400 [==============================] - 0s 281us/step - loss: 0.5411 - accuracy: 0.9829 - val_loss: 0.5208 - val_accuracy: 0.9817\n",
      "Epoch 136/200\n",
      "1400/1400 [==============================] - 0s 290us/step - loss: 0.5335 - accuracy: 0.9836 - val_loss: 0.5246 - val_accuracy: 0.9833\n",
      "Epoch 137/200\n",
      "1400/1400 [==============================] - 0s 295us/step - loss: 0.5265 - accuracy: 0.9829 - val_loss: 0.5134 - val_accuracy: 0.9767\n",
      "Epoch 138/200\n",
      "1400/1400 [==============================] - 0s 277us/step - loss: 0.5243 - accuracy: 0.9800 - val_loss: 0.5122 - val_accuracy: 0.9817\n",
      "Epoch 139/200\n",
      "1400/1400 [==============================] - 0s 270us/step - loss: 0.5327 - accuracy: 0.9757 - val_loss: 0.5010 - val_accuracy: 0.9833\n",
      "Epoch 140/200\n",
      "1400/1400 [==============================] - 0s 272us/step - loss: 0.5089 - accuracy: 0.9836 - val_loss: 0.5124 - val_accuracy: 0.9800\n",
      "Epoch 141/200\n",
      "1400/1400 [==============================] - 0s 272us/step - loss: 0.5169 - accuracy: 0.9793 - val_loss: 0.4936 - val_accuracy: 0.9833\n",
      "Epoch 142/200\n",
      "1400/1400 [==============================] - 0s 286us/step - loss: 0.5051 - accuracy: 0.9843 - val_loss: 0.5043 - val_accuracy: 0.9800\n",
      "Epoch 143/200\n",
      "1400/1400 [==============================] - 0s 274us/step - loss: 0.5073 - accuracy: 0.9800 - val_loss: 0.5057 - val_accuracy: 0.9833\n",
      "Epoch 144/200\n",
      "1400/1400 [==============================] - 0s 271us/step - loss: 0.4953 - accuracy: 0.9814 - val_loss: 0.4937 - val_accuracy: 0.9833\n",
      "Epoch 145/200\n",
      "1400/1400 [==============================] - 0s 271us/step - loss: 0.4943 - accuracy: 0.9786 - val_loss: 0.4757 - val_accuracy: 0.9867\n",
      "Epoch 146/200\n",
      "1400/1400 [==============================] - 0s 274us/step - loss: 0.4891 - accuracy: 0.9807 - val_loss: 0.4761 - val_accuracy: 0.9817\n",
      "Epoch 147/200\n",
      "1400/1400 [==============================] - 0s 272us/step - loss: 0.4875 - accuracy: 0.9836 - val_loss: 0.4795 - val_accuracy: 0.9800\n",
      "Epoch 148/200\n",
      "1400/1400 [==============================] - 0s 275us/step - loss: 0.4794 - accuracy: 0.9836 - val_loss: 0.4894 - val_accuracy: 0.9783\n",
      "Epoch 149/200\n",
      "1400/1400 [==============================] - 0s 273us/step - loss: 0.4805 - accuracy: 0.9807 - val_loss: 0.4750 - val_accuracy: 0.9817\n",
      "Epoch 150/200\n",
      "1400/1400 [==============================] - 0s 281us/step - loss: 0.4774 - accuracy: 0.9779 - val_loss: 0.4603 - val_accuracy: 0.9833\n",
      "Epoch 151/200\n",
      "1400/1400 [==============================] - 0s 274us/step - loss: 0.4755 - accuracy: 0.9793 - val_loss: 0.4623 - val_accuracy: 0.9833\n",
      "Epoch 152/200\n",
      "1400/1400 [==============================] - 0s 270us/step - loss: 0.4721 - accuracy: 0.9836 - val_loss: 0.4634 - val_accuracy: 0.9833\n",
      "Epoch 153/200\n",
      "1400/1400 [==============================] - 0s 274us/step - loss: 0.4654 - accuracy: 0.9836 - val_loss: 0.4566 - val_accuracy: 0.9833\n",
      "Epoch 154/200\n",
      "1400/1400 [==============================] - 0s 272us/step - loss: 0.4487 - accuracy: 0.9871 - val_loss: 0.4572 - val_accuracy: 0.9817\n",
      "Epoch 155/200\n",
      "1400/1400 [==============================] - 0s 275us/step - loss: 0.4620 - accuracy: 0.9786 - val_loss: 0.5030 - val_accuracy: 0.9633\n",
      "Epoch 156/200\n",
      "1400/1400 [==============================] - 0s 296us/step - loss: 0.4890 - accuracy: 0.9714 - val_loss: 0.4980 - val_accuracy: 0.9683\n",
      "Epoch 157/200\n",
      "1400/1400 [==============================] - 0s 334us/step - loss: 0.4808 - accuracy: 0.9700 - val_loss: 0.4854 - val_accuracy: 0.9683\n",
      "Epoch 158/200\n",
      "1400/1400 [==============================] - 0s 301us/step - loss: 0.4830 - accuracy: 0.9757 - val_loss: 0.4510 - val_accuracy: 0.9817\n",
      "Epoch 159/200\n",
      "1400/1400 [==============================] - 0s 274us/step - loss: 0.4745 - accuracy: 0.9771 - val_loss: 0.4437 - val_accuracy: 0.9833\n",
      "Epoch 160/200\n",
      "1400/1400 [==============================] - 0s 344us/step - loss: 0.4435 - accuracy: 0.9857 - val_loss: 0.4459 - val_accuracy: 0.9850\n",
      "Epoch 161/200\n",
      "1400/1400 [==============================] - 0s 338us/step - loss: 0.4517 - accuracy: 0.9850 - val_loss: 0.4635 - val_accuracy: 0.9750\n",
      "Epoch 162/200\n",
      "1400/1400 [==============================] - 1s 395us/step - loss: 0.4674 - accuracy: 0.9729 - val_loss: 0.4841 - val_accuracy: 0.9567\n",
      "Epoch 163/200\n",
      "1400/1400 [==============================] - 1s 360us/step - loss: 0.4863 - accuracy: 0.9643 - val_loss: 0.4493 - val_accuracy: 0.9783\n",
      "Epoch 164/200\n",
      "1400/1400 [==============================] - 1s 391us/step - loss: 0.4694 - accuracy: 0.9686 - val_loss: 0.4596 - val_accuracy: 0.9800\n",
      "Epoch 165/200\n",
      "1400/1400 [==============================] - 0s 339us/step - loss: 0.5065 - accuracy: 0.9629 - val_loss: 0.5251 - val_accuracy: 0.9517\n",
      "Epoch 166/200\n",
      "1400/1400 [==============================] - 1s 373us/step - loss: 0.5739 - accuracy: 0.9536 - val_loss: 0.4720 - val_accuracy: 0.9800\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 0s 312us/step - loss: 0.5139 - accuracy: 0.9693 - val_loss: 0.4732 - val_accuracy: 0.9817\n",
      "Epoch 168/200\n",
      "1400/1400 [==============================] - 0s 313us/step - loss: 0.4936 - accuracy: 0.9786 - val_loss: 0.4805 - val_accuracy: 0.9817\n",
      "Epoch 169/200\n",
      "1400/1400 [==============================] - 0s 296us/step - loss: 0.4976 - accuracy: 0.9764 - val_loss: 0.4622 - val_accuracy: 0.9833\n",
      "Epoch 170/200\n",
      "1400/1400 [==============================] - 0s 281us/step - loss: 0.4754 - accuracy: 0.9786 - val_loss: 0.4526 - val_accuracy: 0.9850\n",
      "Epoch 171/200\n",
      "1400/1400 [==============================] - 0s 288us/step - loss: 0.4649 - accuracy: 0.9807 - val_loss: 0.4447 - val_accuracy: 0.9850\n",
      "Epoch 172/200\n",
      "1400/1400 [==============================] - 1s 383us/step - loss: 0.4544 - accuracy: 0.9807 - val_loss: 0.4363 - val_accuracy: 0.9850\n",
      "Epoch 173/200\n",
      "1400/1400 [==============================] - 1s 465us/step - loss: 0.4428 - accuracy: 0.9857 - val_loss: 0.4256 - val_accuracy: 0.9817\n",
      "Epoch 174/200\n",
      "1400/1400 [==============================] - 1s 445us/step - loss: 0.4339 - accuracy: 0.9800 - val_loss: 0.4157 - val_accuracy: 0.9817\n",
      "Epoch 175/200\n",
      "1400/1400 [==============================] - 1s 455us/step - loss: 0.4259 - accuracy: 0.9829 - val_loss: 0.4042 - val_accuracy: 0.9850\n",
      "Epoch 176/200\n",
      "1400/1400 [==============================] - 1s 385us/step - loss: 0.4056 - accuracy: 0.9871 - val_loss: 0.3978 - val_accuracy: 0.9850\n",
      "Epoch 177/200\n",
      "1400/1400 [==============================] - 0s 313us/step - loss: 0.4061 - accuracy: 0.9814 - val_loss: 0.3942 - val_accuracy: 0.9800\n",
      "Epoch 178/200\n",
      "1400/1400 [==============================] - 0s 301us/step - loss: 0.3996 - accuracy: 0.9821 - val_loss: 0.3871 - val_accuracy: 0.9850\n",
      "Epoch 179/200\n",
      "1400/1400 [==============================] - 0s 290us/step - loss: 0.3854 - accuracy: 0.9871 - val_loss: 0.3831 - val_accuracy: 0.9800\n",
      "Epoch 180/200\n",
      "1400/1400 [==============================] - 0s 288us/step - loss: 0.3804 - accuracy: 0.9857 - val_loss: 0.3750 - val_accuracy: 0.9783\n",
      "Epoch 181/200\n",
      "1400/1400 [==============================] - 0s 348us/step - loss: 0.3728 - accuracy: 0.9864 - val_loss: 0.3684 - val_accuracy: 0.9817\n",
      "Epoch 182/200\n",
      "1400/1400 [==============================] - 1s 367us/step - loss: 0.3679 - accuracy: 0.9879 - val_loss: 0.3685 - val_accuracy: 0.9800\n",
      "Epoch 183/200\n",
      "1400/1400 [==============================] - 0s 343us/step - loss: 0.3689 - accuracy: 0.9843 - val_loss: 0.3761 - val_accuracy: 0.9767\n",
      "Epoch 184/200\n",
      "1400/1400 [==============================] - 0s 291us/step - loss: 0.3714 - accuracy: 0.9850 - val_loss: 0.3620 - val_accuracy: 0.9817\n",
      "Epoch 185/200\n",
      "1400/1400 [==============================] - 1s 389us/step - loss: 0.3641 - accuracy: 0.9850 - val_loss: 0.3586 - val_accuracy: 0.9800\n",
      "Epoch 186/200\n",
      "1400/1400 [==============================] - 0s 318us/step - loss: 0.3649 - accuracy: 0.9871 - val_loss: 0.3686 - val_accuracy: 0.9850\n",
      "Epoch 187/200\n",
      "1400/1400 [==============================] - 0s 333us/step - loss: 0.3695 - accuracy: 0.9836 - val_loss: 0.3968 - val_accuracy: 0.9750\n",
      "Epoch 188/200\n",
      "1400/1400 [==============================] - 0s 330us/step - loss: 0.3757 - accuracy: 0.9821 - val_loss: 0.3881 - val_accuracy: 0.9717\n",
      "Epoch 189/200\n",
      "1400/1400 [==============================] - 0s 313us/step - loss: 0.3875 - accuracy: 0.9750 - val_loss: 0.3741 - val_accuracy: 0.9817\n",
      "Epoch 190/200\n",
      "1400/1400 [==============================] - 0s 306us/step - loss: 0.3934 - accuracy: 0.9757 - val_loss: 0.3825 - val_accuracy: 0.9767\n",
      "Epoch 191/200\n",
      "1400/1400 [==============================] - 0s 321us/step - loss: 0.3881 - accuracy: 0.9843 - val_loss: 0.3932 - val_accuracy: 0.9767\n",
      "Epoch 192/200\n",
      "1400/1400 [==============================] - 1s 413us/step - loss: 0.3897 - accuracy: 0.9786 - val_loss: 0.4010 - val_accuracy: 0.9717\n",
      "Epoch 193/200\n",
      "1400/1400 [==============================] - 1s 424us/step - loss: 0.4004 - accuracy: 0.9779 - val_loss: 0.3802 - val_accuracy: 0.9783\n",
      "Epoch 194/200\n",
      "1400/1400 [==============================] - 0s 349us/step - loss: 0.3947 - accuracy: 0.9771 - val_loss: 0.3669 - val_accuracy: 0.9833\n",
      "Epoch 195/200\n",
      "1400/1400 [==============================] - 0s 331us/step - loss: 0.3794 - accuracy: 0.9807 - val_loss: 0.3751 - val_accuracy: 0.9783\n",
      "Epoch 196/200\n",
      "1400/1400 [==============================] - 0s 346us/step - loss: 0.3731 - accuracy: 0.9850 - val_loss: 0.3710 - val_accuracy: 0.9833\n",
      "Epoch 197/200\n",
      "1400/1400 [==============================] - 0s 294us/step - loss: 0.3774 - accuracy: 0.9821 - val_loss: 0.3691 - val_accuracy: 0.9817\n",
      "Epoch 198/200\n",
      "1400/1400 [==============================] - 0s 295us/step - loss: 0.3716 - accuracy: 0.9807 - val_loss: 0.3782 - val_accuracy: 0.9750\n",
      "Epoch 199/200\n",
      "1400/1400 [==============================] - 0s 284us/step - loss: 0.3642 - accuracy: 0.9807 - val_loss: 0.3562 - val_accuracy: 0.9817\n",
      "Epoch 200/200\n",
      "1400/1400 [==============================] - 0s 338us/step - loss: 0.3554 - accuracy: 0.9843 - val_loss: 0.3665 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model_lstm_adm.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=1, callbacks=[es, mc],batch_size=1024)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "#saved_model = load_model('best_model_lstm_reg.h5')\n",
    "saved_model = model_lstm_adm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.984, Test: 0.980\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = saved_model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD6CAYAAAC4RRw1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZSU9Z3v8fe39t5o6AVoRAIiKiDaKjGiWVwiglHRZOJoxuhMMiFzrt6bTMZM9OQkMTOZGWfJcjN3NENGJ84kJnFijCbRxCUQNFGxUZZGQEARmrVplm56qa7le/+owrTYDU1vT1f353VOnap6+qmuD08Vn37qV89i7o6IiBSeUNABRESkb1TgIiIFSgUuIlKgVOAiIgVKBS4iUqBU4CIiBarXBW5mYTN7xcx+kb9fYWZPmdmm/PW4wYspIiJHs95uB25mnwPmAmPc/Soz+ydgv7vfbWZ3AOPc/QvH+h1VVVU+derU/mYWERlVVq5cuc/dq4+eHunNg81sMvAh4O+Az+UnLwIuzt9+AFgGHLPAp06dSl1dXe8Si4gIAGb2ZnfTezuE8i3gr4Fsl2kT3H0XQP56fA9PvNjM6sysrrGx8QQii4jIsRy3wM3sKmCvu6/syxO4+xJ3n+vuc6ur3/EJQERE+qg3QygXAdeY2ZVAAhhjZt8H9phZjbvvMrMaYO9gBhURkbc7boG7+53AnQBmdjFwu7vfZGb/DNwC3J2/fnQQc4rIKJVKpWhoaKCjoyPoKIMukUgwefJkotFor+bv1ZeYPbgbeMjMPglsAz7aj98lItKthoYGysrKmDp1KmYWdJxB4+40NTXR0NDAtGnTevWYEypwd19GbmsT3L0JuOwEM4qInJCOjo4RX94AZkZlZSUnsrGH9sQUkWFvpJf3ESf67yyIAv/Nhj3cs2xz0DFERIaVgijw5a/t496lW4KOISKj1MGDB7nnnntO+HFXXnklBw8eHIREOQVR4FWlMVqSaZLpTNBRRGQU6qnAM5ljd9Ljjz/O2LFjBytWYRR4RUkcgAOtqYCTiMhodMcdd7BlyxZqa2t597vfzSWXXMLHPvYx5syZA8C1117Leeedx+zZs1myZMlbj5s6dSr79u1j69atzJw5k0996lPMnj2b+fPn097e3u9c/dmMcMhUlMQA2Hc4ycTyRMBpRCQoX/35Ol7d2Tygv3PWpDF85erZx5zn7rvvpr6+nlWrVrFs2TI+9KEPUV9f/9bmfvfffz8VFRW0t7fz7ne/m4985CNUVla+7Xds2rSJH/7wh3z3u9/l+uuv5+GHH+amm27qV/aCKPCq0lyB72/tDDiJiAicf/75b9tW+9vf/jaPPPIIANu3b2fTpk3vKPBp06ZRW1sLwHnnncfWrVv7naMgCvzIGnhTazLgJCISpOOtKQ+VkpKSt24vW7aMp59+mueff57i4mIuvvjibvcajcfjb90Oh8MDMoRSEGPglaW5f3jTYa2Bi8jQKysro6WlpdufHTp0iHHjxlFcXMyGDRt44YUXhixXQayBj0lEiIaNJg2hiEgAKisrueiiizjzzDMpKipiwoQJb/1swYIFfOc73+Gss87i9NNP54ILLhiyXAVR4GbGuOIY+7UGLiIBefDBB7udHo/HeeKJJ7r92ZFx7qqqKurr69+afvvttw9IpoIYQoHcMIrWwEVE/qBwCrwkpi8xRUS6KJgCryiJaTNCEZEuCqbAK0tj2gpFRKSLwinwkhiHk2k6UjoeiogIFFCBHzkeioZRRERyenNW+oSZrTCz1Wa2zsy+mp9+l5ntMLNV+cuVgxm0UrvTi0hA+no4WYBvfetbtLW1DXCinN6sgSeBS939bKAWWGBmR7ZU/6a71+Yvjw9KwrzKt3anV4GLyNAargXem7PSO3A4fzeav/igpDmGP+xOr00JRWRodT2c7OWXX8748eN56KGHSCaTXHfddXz1q1+ltbWV66+/noaGBjKZDF/60pfYs2cPO3fu5JJLLqGqqoqlS5cOaK5e7YlpZmFgJXAq8G/u/qKZLQRuM7ObgTrgr9z9QDePXQwsBpgyZUqfgx45IuHu5nceJEZERokn7oDdawf2d06cAwvvPuYsXQ8n++STT/KTn/yEFStW4O5cc801LF++nMbGRiZNmsQvf/lLIHeMlPLycr7xjW+wdOlSqqqqBjY3vfwS090z7l4LTAbON7MzgXuB6eSGVXYBX+/hsUvcfa67z62uru5z0LJElMnjilg3wMcCFhE5EU8++SRPPvkk55xzDueeey4bNmxg06ZNzJkzh6effpovfOELPPvss5SXlw96lhM6Foq7HzSzZcACd/+XI9PN7LvALwY42zucPXksaxoG7/xyIjLMHWdNeSi4O3feeSef/vSn3/GzlStX8vjjj3PnnXcyf/58vvzlLw9qlt5shVJtZmPzt4uADwIbzKymy2zXAfXdPX4gzZlczvb97doSRUSGVNfDyV5xxRXcf//9HD6c+2pwx44d7N27l507d1JcXMxNN93E7bffzssvv/yOxw603qyB1wAP5MfBQ8BD7v4LM/tvM6sl94XmVuCdf44GSjYLh7Zx1uTcR5I1DQe5+PTxg/Z0IiJddT2c7MKFC/nYxz7GvHnzACgtLeX73/8+mzdv5vOf/zyhUIhoNMq9994LwOLFi1m4cCE1NTUD/iWm5TYyGRpz5871urq6E3/gz26F15fS8qkXOOvvn+UvP3ga/+eyGQMfUESGnfXr1zNz5sygYwyZ7v69ZrbS3ecePW9h7Il59g3QvIOytQ9wSlUJaxoOBZ1IRCRwhVHg094H0y+DZ7/Oe2oi+iJTRIRCKXCAD34F2g9wLb9hb0uS3Ye0PbjIaDGUQ71BOtF/Z+EUeM3ZUHEKp7WvBmC11sJFRoVEIkFTU9OIL3F3p6mpiUQi0evHFMQ5Md8yZR7lG58gGvoz1jQc5IrZE4NOJCKDbPLkyTQ0NNDY2Bh0lEGXSCSYPHlyr+cvuAK3VT/g0qpmfZEpMkpEo1GmTZsWdIxhqXCGUACm5La7vKLsddY0HBrxH6lERI6lsAq8cjoUV1HLRg61p9i2f3AO0SgiUggKq8DNYMoFTG5eBcBqDaOIyChWWAUOMGUesZZtTIke5OU333H0WhGRUaMgCxzgo+N38rvN+wIOIyISnMIr8JqzIFLExUVb2LT3MHt0ggcRGaUKr8DDUZg8l1M7cmfl+P0WrYWLyOhUeAUOMGUeiaZXOakozXObmoJOIyISiAIt8Aswz3JDzR5+t3mftgcXkVGpMAv85PPBwlxS9Bq7mzvY0tgadCIRkSFXmAUeL4OTz+e05hcAjYOLyOjUm3NiJsxshZmtNrN1ZvbV/PQKM3vKzDblr8cNftwuZswn1riWs8e289wmFbiIjD69WQNPApe6+9lALbDAzC4A7gCecfcZwDP5+0PntCsA+Hjlazz/ehPpTHZIn15EJGjHLXDPOZy/G81fHFgEPJCf/gBw7aAk7Mn4WTDmJC7KrqSlI039zuYhfXoRkaD1agzczMJmtgrYCzzl7i8CE9x9F0D+utvTxJvZYjOrM7O6AT2erxnMmM/Efc8TI8Vzm0b+sYJFRLrqVYG7e8bda4HJwPlmdmZvn8Ddl7j7XHefW11d3dec3TvtCizVykert7NsowpcREaXE9oKxd0PAsuABcAeM6sByF/vHfB0xzPt/RCO8+HSel7edoADrZ1DHkFEJCi92Qql2szG5m8XAR8ENgCPAbfkZ7sFeHSwQvYoVgLT3sfs1hfJOizXMIqIjCK9WQOvAZaa2RrgJXJj4L8A7gYuN7NNwOX5+0NvxhUkmt+gtriJ32wY+g8BIiJBOe45Md19DXBON9ObgMsGI9QJOW0+PPF5/rR6I3e9NpFM1gmHLOhUIiKDrjD3xOxq3FSonsl7sy9xsC3FK9t0kgcRGR0Kv8ABzvgQlfteoirUomEUERk1RkaBz7wK8yyfrN6oAheRUWNkFHhNLZSfzMJIHRt2t7DzYHvQiUREBt3IKHAzOOMqphx8kWI6tBYuIqPCyChwgJlXEcok+ciY9Tyzfk/QaUREBt3IKfAp86C4kutLV/O7zU0cTqaDTiQiMqhGToGHwnD6Qma2PI9nOlm2UcMoIjKyjZwCBzjjaiKpFq4ofo1fr9MwioiMbCOrwE+5GGKlfLx8DUs37CWZzgSdSERk0IysAo8m4NQPUtv+e9qSnTy/pSnoRCIig2ZkFTjAzKuJd+zjwtgWDaOIyIg28gp8xnwIx/jTinU89eoeslkPOpGIyKAYeQWeGAPTPsC8zufZd7iDV7br4FYiMjKNvAIHmHkVJW3bmRPermEUERmxRmaBn3EVWIg/r1zLr9ftxl3DKCIy8ozMAi+pgqnv5eLM73izqZXX9hwOOpGIyIDrzTkxTzazpWa23szWmdln8tPvMrMdZrYqf7ly8OOegFmLKG/dymmhHfx63e6g04iIDLjerIGngb9y95nABcCtZjYr/7Nvuntt/vL4oKXsizOuBoxPjFvDk6+qwEVk5Dlugbv7Lnd/OX+7BVgPnDTYwfqtbAK860Iu5wXqdzTTcKAt6EQiIgPqhMbAzWwquRMcv5ifdJuZrTGz+81sXA+PWWxmdWZW19jY2K+wJ2zWIipbNzPddvCreq2Fi8jI0usCN7NS4GHgs+7eDNwLTAdqgV3A17t7nLsvcfe57j63urp6ACKfgJlXA3BL+WqeUIGLyAjTqwI3syi58v6Bu/8UwN33uHvG3bPAd4HzBy9mH42ZBCdfwMLwCla+eYDdhzqCTiQiMmB6sxWKAfcB6939G12m13SZ7TqgfuDjDYBZi6hufY2ptktbo4jIiNKbNfCLgI8Dlx61yeA/mdlaM1sDXAL85WAG7bP8MMpNY1bzRP2ugMOIiAycyPFmcPfnAOvmR8Nrs8GejD0ZTprLVQdX8PdvLKCxJUl1WTzoVCIi/TYy98Q82qxFTGzdwCT2aptwERkxRkmBXwPAn5S+os0JRWTEGB0FPm4qTDqHRbE6fr+liQOtnUEnEhHpt9FR4ACzFjGpdR0Ts3u1NYqIjAijp8Bn5oZRbhyzml+s0dYoIlL4Rk+BV06HiXO4Ll7H77fsY9/hZNCJRET6ZfQUOMCsRZzUsobx3sQTa7UWLiKFbZQV+LUA3Fy+ip9rGEVECtzoKvCqGblhlNgKXtq6X8dGEZGCNroKHGD2h6lpWctJNPJLDaOISAEbhQV+HQCfGPsKP1+9M+AwIiJ9N/oKvGIanHQeV4dfYNX2g2zfrzP1iEhhGn0FDjD7w1Qf3sBU26VtwkWkYI3SAs9tjfKpcav4xRoNo4hIYRqdBV4+GabMY6E9z7qdzbzeeDjoRCIiJ2x0FjjA7A9T0bqZ00INGkYRkYI0egt81iKwEIsrVvHY6p24e9CJREROSG/OiXmymS01s/Vmts7MPpOfXmFmT5nZpvz1uMGPO4DKJsDU9zI/+zs2723h1V3NQScSETkhvVkDTwN/5e4zgQuAW81sFnAH8Iy7zwCeyd8vLLM/zJi2N5kT3sajq/RlpogUluMWuLvvcveX87dbgPXAScAi4IH8bA8A1w5WyEEz8xqwMP+rahWPrtpBJqthFBEpHCc0Bm5mU4FzgBeBCe6+C3IlD4zv4TGLzazOzOoaGxv7l3aglVTC9Ev4QOpZ9ja38+LrTUEnEhHptV4XuJmVAg8Dn3X3Xg8Yu/sSd5/r7nOrq6v7knFwnX0jxW07uTS+kZ+t2hF0GhGRXutVgZtZlFx5/8Ddf5qfvMfMavI/rwH2Dk7EQXbGVZAYy63lz/PE2t10pDJBJxIR6ZXebIViwH3Aenf/RpcfPQbckr99C/DowMcbAtEEnHU9tYeXY8mDLN1QmH+HRGT06c0a+EXAx4FLzWxV/nIlcDdwuZltAi7P3y9M59xEKNvJjcV1GkYRkYIROd4M7v4cYD38+LKBjROQiWdB1WnckFzJ/A2XsL+1k4qSWNCpRESOafTuidmVGcy+jqmHX2Fs5gCPai1cRAqACvyI2ddhnuUTlWv5n7qGoNOIiByXCvyI8TOh+gyui63g1V3N1O84FHQiEZFjUoF3deYfMfHASk6J7OMnK7UWLiLDmwq8q9obAePz41/iZ6t2kExrm3ARGb5U4F2VT4ZTL+OSjqdobkvy9KvaJlxEhi8V+NHO+TiJtt1cW7qeh+q2B51GRKRHKvCjnX4llE3i9sSjLN+0l817dbo1ERmeVOBHi8Tg4i8w6XA9CyOruGfp5qATiYh0SwXendqboPJU7ip9mEdX7+DNptagE4mIvIMKvDvhCLzvrxjf/jrzwuu577k3gk4kIvIOKvCezLoW4uV8dtzz/OyVHTrMrIgMOyrwnsSK4azrOffwcqzjIL+q3x10IhGRt1GBH8t5txDKdvKJshX8+CVtUigiw4sK/FgmzoEJZ/LRopd4/vUmfZkpIsOKCvx4Zi1iUvNqJtoB7dgjIsOKCvx4Zi0C4LaaDfxkZQPpTDbgQCIiOb05J+b9ZrbXzOq7TLvLzHYcdYq1kan6dKg+gyvDL7KnOclvX2sMOpGICNC7NfDvAQu6mf5Nd6/NXx4f2FjDzKxFjNtXx5ySQ/oyU0SGjeMWuLsvB/YPQZbh69xbMAvxperf8syGvext6Qg6kYhIv8bAbzOzNfkhlnE9zWRmi82szszqGhsLdPih/CQ484+Yu+8xSrIt/PRlnTNTRILX1wK/F5gO1AK7gK/3NKO7L3H3ue4+t7q6uo9PNwxceBuhdBtfqHqBH7+0HXcPOpGIjHJ9KnB33+PuGXfPAt8Fzh/YWMPQxDlwyiV8OPVzGvYdYvmmfUEnEpFRrk8FbmY1Xe5eB9T3NO+IcuH/pijZyE0lK1iyfEvQaURklIscbwYz+yFwMVBlZg3AV4CLzawWcGAr8OlBzDh8TL8Uxs/mttZfcd7medTvOMSZJ5UHnUpERqnebIVyo7vXuHvU3Se7+33u/nF3n+PuZ7n7Ne6+ayjCBs4M5t1KZetmLo5v0mFmRSRQ2hPzRM2+DuJj+GzF8/xy7S4OtnUGnUhERikV+ImKFcOcj3JW8zIS6RYeeUWbFIpIMFTgfXHuzYQySf5X5cv8aIU2KRSRYKjA+2JSLdTUciO/4rU9h3jh9dG9o6qIBEMF3lfzbqO89Q0WFddz72+1SaGIDD0VeF/NvhbGTOb2sqdY/loj9TsOBZ1IREYZFXhfhaNwwV8w+dBK5sYb+PflrwedSERGGRV4f9T+CYTj/PWEFTyxdpeOUigiQ0oF3h/FFTDzas479BThbJIfr9CxwkVk6KjA++vcmwknD/GZSRt4cMU2nXJNRIaMCry/pr4Pxk3lY/yKXYfaeaJ+d9CJRGSUUIH3VygEF/5vxu5fxUfGbeGeZVu0Y4+IDAkV+ECovQnKarij6DHW72pmmU58LCJDQAU+EKIJuOgzVO+vY37Zm9y7VDv2iMjgU4EPlHM+DrEy/rrqd6zYup+Xtmr3ehEZXCrwgRIvhbP/mOl7n2JacZJ7lm4OOpGIjHAq8IE09xNYJsnfTl3N0o2NrNup3etFZPAct8DN7H4z22tm9V2mVZjZU2a2KX89bnBjFogJs2HKPC5s+inlcePeZRoLF5HB05s18O8BC46adgfwjLvPAJ7J3xeAC/8PoUPb+NqpG3l87S7e2NcadCIRGaF6c07M5cDR38gtAh7I334AuHaAcxWu0xZA9UwWHvwRsTD8uw41KyKDpK9j4BOOnMg4fz2+pxnNbLGZ1ZlZXWPjKNg+OhSC9/4lkaYNfGnGNh5+uYHdh3SQKxEZeIP+Jaa7L3H3ue4+t7q6erCfbng48yMwdgp/1P4/ZN357rM61KyIDLy+FvgeM6sByF/vHbhII0A4Ahd9hvjulXzu1L08+OI29rfq7PUiMrD6WuCPAbfkb98CPDowcUaQ2pugZDx/lvkJHemMxsJFZMD1ZjPCHwLPA6ebWYOZfRK4G7jczDYBl+fvS1fRBLzvcxTveI47Z+zgP3+/lR0H24NOJSIjSG+2QrnR3WvcPeruk939PndvcvfL3H1G/lr7jXdn7ieh4hT+rPU/CJPh609uDDqRiIwg2hNzMEVi8MGvEm3ayDdOXcsjr+zg1Z3NQacSkRFCBT7YZl4NUy7kir33MTGe5u5fbQg6kYiMECrwwWYGV3yNUFsj97xrOctfa+TZTaNge3gRGXQq8KFw0nkw53pqG/6L947dz12PraMzrXNnikj/qMCHyhV/h0WL+X+l/8nrjS3c99wbQScSkQKnAh8qpeNhwT8wdt9KvnbSCr79zCZtVigi/aICH0pn3winXMKNzfcxgUb+9uevBp1IRAqYCnwomcHV3yKE873qH/GrdbtYtlFHIRCRvlGBD7VxU+GSLzJ1/3N8fGw9X3lsHR2pTNCpRKQAqcCD8J5Pw/hZfDH8AHuaDujMPSLSJyrwIISjcOW/kGjdyXcm/oJ7lm1mbYPOnykiJ0YFHpSpF8F7/oKLDz7MR4pWceuDL9PckQo6lYgUEBV4kC7/G6ip5Wuhe+HgNu58eC3uHnQqESkQKvAgReLw0e8RMfifyiU8uXY7339xW9CpRKRAqMCDVjENrvlXJrTU86/Vj/K3v3iVdTs1Hi4ix6cCHw5mXwvv/hQLWh7m6sQqbnvwFQ4n00GnEpFhTgU+XMz/Gkw8i38M3UN8/wY+9+NVZLIaDxeRnvWrwM1sq5mtNbNVZlY3UKFGpWgC/vi/icSK+WnpP7Nx/WrufmJ90KlEZBgbiDXwS9y91t3nDsDvGt3GTYWbH6Uo4jw85ps89Oxa/vuFN4NOJSLDlIZQhpvxZ2A3PEhleg8/GnsvX3t0Fb/ZsCfoVCIyDPW3wB140sxWmtni7mYws8VmVmdmdY2NOhNNr0y5ALvmX5nZ8Qr/UbaEW79fx+837ws6lYgMM/0t8Ivc/VxgIXCrmb3/6BncfYm7z3X3udXV1f18ulHk7Btg/t/xvs7n+GbR/XzygZd4aev+oFOJyDDSrwJ39535673AI8D5AxFK8i68DT7wBRaknuZvEg/yZ/+5gle2HQg6lYgME30ucDMrMbOyI7eB+UD9QAWTvIvvhPf8BR9NPcaXo9/n5vtfpH6HdvQREYj047ETgEfM7MjvedDdfzUgqeQPzOCKfwALcf0L91AUbuPm/3D+8xPzOPvksUGnE5EA9bnA3f114OwBzCI9CYXgir+H+Biu/u3dlITbuXlJim987D1cNnNC0OlEJCDajLBQmMEld8L8v+PSzO/5SeyrfOW/nuDrT27UHpsio5QKvNBceBvc8CCnRvbw6+IvsXrZw9x8/4vsO5wMOpmIDDEVeCE640PY4t9SUnkyD8T+iUu3fZtrvvmMdvgRGWVU4IWqcjr8+dPYeX/KJ0O/5If+13zrgR9z50/X0qojGYqMCirwQhYrhqu/BTc9zJSSND+L38WsV+7ixm89xjPrtTYuMtLZUJ7Ca+7cuV5Xp4MWDor2g/CbvyVb9z2SHmFJ+kp+X309V79nFotqJ1GWiAadUET6yMxWdnfAQBX4SNO0hczTf0N4/c/oIM5P0xfyY1vIjLMu4MbzT+bcKePIb7svIgVCBT7a7F6Lv7gEX/MQoUwHW72G5zKzWDPmA4w/81LOPWU8502poLxYa+Yiw50KfLRq2w9rHiK9eSn+xm+JZtrp8CirfTovZU9nd3ktpdMvpPa0d3H+tEoqSmJBJxaRo6jABVLtsGUpqdefpWPL7yjeX0/YM2Td2OiT+V32TDaXX8TY6e9WoYsMIypweafOVtixkvTW52nbtJziXSuIeCcADV7F+uy7aIidQqpiBiUTplMy8RQqx09m0rhiJpUXURQLB/wPEBkdVOByfMnDsO0F0jtX07z1FdhTz9i2NwmRfWuWNo+z3avZ7tU0hifSVlRDdTxNPBrmjeipxIvLqC4OUVUSYX/5bLy4mg+cXk1pvD/HTRMZ3VTg0jepdjiwlXTT67Ts2kJH4+v4gTeJtWyntH0HiWwbWQzHCHcpeoBOD/Ncdg47bCLRcScRGlPDXioIjanhXdNmUFVRQWVpnMqSGOVFUUIhbR0j0p2eClyrRXJs0SIYP5PI+JmMm3nUz9wh2UwoWgyZTtizDjKdtKaN/S3tjNn6BPO2LsVaXiNxqA26HsZ8HRz2BHt8HOt9HHuooC0ylmysDBJjsMQYYsXlREvGEisZS7S4nHHjqigbW0kmHKc0EWVcSYyyeESbRcqopQKXvjODRHnudjgKJ+dOyFSSv3DOB/8wb7IFWnZDyy7SB3eyf/ebpA7uJNGyi+mtu5ndsYVE6iDxZDskeXvZHyXlYQ5TxEEvooFi2kMldEZKSUdKSEXLyMbK8CN/CIrKsXgZFi8lEisiHC8mGi8hkigmnighVlRCPF5MIh4mEQ2TiISJhk1/FKQgqMBlaMTLcpeqGUSA8T3Nl83kyj7ZDB3NpNoO0dZygOThA7Qc2k+q7RDR1GE8eQjvaCGWbCbR2UIktZ94ahtFyVaKvZXIUcM5x5Jxo5UEHcRpJkKnR0lZlJTFSIYSpEMJouakCdNpMdKhONlwHA/HyYZjeChOOpSbP2NRMqEYZaWlRGMJ2rIRwtE40XgRsUSCWLyIovxtD0XxVDvhg1vZ05mg0SqoKokRDzt4JrcsMp2QzdKSGE/RmComVYwhHo0QDYeIho1oJEQsHCIaDhHWENSoowKX4SUUhqKxuQsQBfLr+D2X/tHcIdWOdxyi/fBBUq0H6ew4TKq9lXSyjUxnG5nOdjLJdryzFe9sg1QrlmqHdDJXmpkk0UwnxelWwtlm0m6EPUMsm5se6ewk4p3EPEWUFCH6913S0aNTx9LpYTqJ0kmENqI0EyblYTKEyViYLGGylrtkiJANhfH8dA9FcrdDEdwiueWdv+2hCBaOkA3F8HCMTCiGhyKEzMj9bQhhZng4Ny+hKGYhCIUImWEWIpZpZUz7djo7U3R4hGw4Tme8ks6iakLhCOFwmKg5iWwroeQh0sk29ocqyYTilHoLJU1raGnr4JX2iRSXlFFRVkQ8GsEtBKEokVicaCxBNF5EKBInEosTjiYIx+JEYgmi0TiReIJorIhoPEEsFiceLyYej0S+lOoAAAeeSURBVBILh3r/PUuqA3AIRXKX/Ccyz6TwVAfZTJpstJSs5Q4nFY+EAvnU1q8CN7MFwP8FwsB/uPvdA5JKpD/MIFaMxYopHlMz+M/nDtk0pDsgnSv/ZEcbqc4OEqRJJdvp6Ggj2dFOMtlOMtlBKtlByFNYOE7nmClUR9opTe2npTNL2g0skjsTUziGmRFv20Wy9RCtra14OollOiHTiWWSkEnj2TSWzV2HshnC2RTmGcimMc9g3kkom8E8QyibJpTOECJDyDOEPU2YP1xHSRMn1efFcdgTdBIhTooEnYSt93/cmnwMHo7yfn4DreQuAyDtITqIkiJCighuxpG6fVs6hyKSlFr72x6f8dwX9RHLYvzhKICHPUEbifzX+BDK/1v9rSnky99onP9vzJx35cD8g/L6XOBmFgb+DbgcaABeMrPH3P3VgQonUhDMct8BhKMQz02Kj3nrJhGgqJe/qmwQ4vWJe374JnNkAu5ONpslk06TTSfxTCeZTJZsNnfJZDNkI8Wki6ooL45RHIuQzWRJHm4k3byHVDpNOp0hlXGSkVLCxeMoLSmhNLUPTyfpDBVTUXUyFgrlNmk98vyezQ0pZVJk0p20t7fR0d5GurODVCpJpjNJurOdTCpJJtVJJtVBNpXE00my6U48ncx/skrimRSWTpLJOg4YYEfK3HL3M6E4bbEK3EKEPJv/45YhRJZ0OEE2FAcz4tk24pnDRDLtZLKQdkhnc8vK3AEnm3WyniWbdSaUVQ34y9SfNfDzgc35c2NiZj8CFgEqcJFCZwaR+NsnkfuofSK7b4XCIeLlE4iXH+vcrWMAeNs+v/HSbucMA6X5i/TveOAnAdu73G/IT3sbM1tsZnVmVtfY2NiPpxMRka76U+Ddjdi/Y7DL3Ze4+1x3n1tdXd2PpxMRka76U+ANwMld7k8GdvYvjoiI9FZ/CvwlYIaZTTOzGHAD8NjAxBIRkePp85eY7p42s9uAX5P7buF+d183YMlEROSY+rUduLs/Djw+QFlEROQE6Kz0IiIFSgUuIlKghvR44GbWCLzZx4dXAfsGMM5AGa65YPhmU64TM1xzwfDNNtJyvcvd37Ed9pAWeH+YWV13BzQP2nDNBcM3m3KdmOGaC4ZvttGSS0MoIiIFSgUuIlKgCqnAlwQdoAfDNRcM32zKdWKGay4YvtlGRa6CGQMXEZG3K6Q1cBER6UIFLiJSoAqiwM1sgZltNLPNZnZHgDlONrOlZrbezNaZ2Wfy0+8ysx1mtip/GdjzJvUu21YzW5t//rr8tAoze8rMNuWvxw1xptO7LJNVZtZsZp8NanmZ2f1mttfM6rtM63EZmdmd+ffcRjO7Yohz/bOZbTCzNWb2iJmNzU+fambtXZbdd4Y4V4+vXcDL68ddMm01s1X56UO5vHrqh8F7j7n7sL6QO1DWFuAUciftWA3MCihLDXBu/nYZ8BowC7gLuD3g5bQVqDpq2j8Bd+Rv3wH8Y8Cv427gXUEtL+D9wLlA/fGWUf51XU3uzGjT8u/B8BDmmg9E8rf/sUuuqV3nC2B5dfvaBb28jvr514EvB7C8euqHQXuPFcIa+FunbnP3TuDIqduGnLvvcveX87dbgPV0cxaiYWQR8ED+9gPAtQFmuQzY4u593RO339x9ObD/qMk9LaNFwI/cPenubwCbyb0XhySXuz/p7un83RfIHW9/SPWwvHoS6PI6wnKnhr8e+OFgPPexHKMfBu09VggF3qtTtw01M5sKnAO8mJ90W/7j7v1DPVSR58CTZrbSzBbnp01w912Qe3MB4wPIdcQNvP0/VdDL64ieltFwet99Aniiy/1pZvaKmf3WzN4XQJ7uXrvhsrzeB+xx901dpg358jqqHwbtPVYIBd6rU7cNJTMrBR4GPuvuzcC9wHSgFthF7iPcULvI3c8FFgK3mtn7A8jQLcud8OMa4H/yk4bD8jqeYfG+M7MvAmngB/lJu4Ap7n4O8DngQTMbM4SRenrthsXyAm7k7SsKQ768uumHHmftZtoJLbNCKPBhdeo2M4uSe3F+4O4/BXD3Pe6ecfcs8F0G6aPjsbj7zvz1XuCRfIY9ZlaTz10D7B3qXHkLgZfdfU8+Y+DLq4uellHg7zszuwW4CvgTzw+a5j9uN+VvryQ3bnraUGU6xms3HJZXBPgw8OMj04Z6eXXXDwzie6wQCnzYnLotP752H7De3b/RZXpNl9muA+qPfuwg5yoxs7Ijt8l9AVZPbjndkp/tFuDRoczVxdvWioJeXkfpaRk9BtxgZnEzmwbMAFYMVSgzWwB8AbjG3du6TK82s3D+9in5XK8PYa6eXrtAl1feB4EN7t5wZMJQLq+e+oHBfI8NxbezA/Dt7pXkvtHdAnwxwBzvJfcRZw2wKn+5EvhvYG1++mNAzRDnOoXct9mrgXVHlhFQCTwDbMpfVwSwzIqBJqC8y7RAlhe5PyK7gBS5tZ9PHmsZAV/Mv+c2AguHONdmcuOjR95n38nP+5H8a7waeBm4eohz9fjaBbm88tO/B/zFUfMO5fLqqR8G7T2mXelFRApUIQyhiIhIN1TgIiIFSgUuIlKgVOAiIgVKBS4iUqBU4CIiBUoFLiJSoP4/cbwjalfDSUgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[343   0   0   0]\n",
      " [  0 343   6   0]\n",
      " [  0  14 332   1]\n",
      " [  1   0   1 359]]\n",
      "0.9835714285714285\n",
      "[[156   0   1   0]\n",
      " [  0 149   2   0]\n",
      " [  1   6 145   1]\n",
      " [  1   0   0 138]]\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "#confusion Matrix\n",
    "train_predicted=saved_model.predict(trainX)\n",
    "test_predicted=saved_model.predict(testX)\n",
    "\n",
    "#Confusion Matrix for Training\n",
    "from sklearn import metrics\n",
    "confusion = metrics.confusion_matrix(trainy.argmax(axis=1), train_predicted.argmax(axis=1))\n",
    "print(confusion)\n",
    "\n",
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(trainy.argmax(axis=1), train_predicted.argmax(axis=1)))\n",
    "\n",
    "#Confusion Matrix for Testing\n",
    "from sklearn import metrics\n",
    "confusion1 = metrics.confusion_matrix(testy.argmax(axis=1), test_predicted.argmax(axis=1))\n",
    "print(confusion1)\n",
    "\n",
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(testy.argmax(axis=1), test_predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99363057 0.98675497 0.94771242 0.99280576]\n",
      "[0.99548533 0.98663697 0.99328859 0.9978308 ]\n",
      "[0.995      0.98666667 0.98166667 0.99666667]\n"
     ]
    }
   ],
   "source": [
    "FP = confusion1.sum(axis=0) - np.diag(confusion1)  \n",
    "FN = confusion1.sum(axis=1) - np.diag(confusion1)\n",
    "TP = np.diag(confusion1)\n",
    "TN = confusion1.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(TPR)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "print(TNR)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################################\n",
    "#################################################################################################################################\n",
    "#################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot\n",
    "from keras.models import load_model\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split Training and Testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We specify this so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "\n",
    "X , y = dataframe1.loc[:, dataframe1.columns != 'Room'] ,dataframe1.loc[:, dataframe1.columns == 'Room']\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, random_state = 0,train_size = 0.7, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln=len(trainX.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=np.array(trainX)\n",
    "trainy=np.array(trainy)\n",
    "testy=np.array(testy)\n",
    "testX=np.array(testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 7)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 7)\n"
     ]
    }
   ],
   "source": [
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 7, 1)\n",
      "(1400, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape(len(trainX),ln,1)\n",
    "testX = testX.reshape(len(testX),ln,1)\n",
    "trainy = trainy.reshape(len(trainy),1)\n",
    "testy = testy.reshape(len(testy),1)\n",
    "print(trainX.shape)\n",
    "print(trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(trainy)\n",
    "trainy = encoder.transform(trainy)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "trainy = np_utils.to_categorical(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(testy)\n",
    "testy = encoder.transform(testy)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "testy = np_utils.to_categorical(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_cnn=Sequential()\n",
    "model_cnn.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(250, activation='relu'))\n",
    "model_cnn.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model with SGD\n",
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n",
    "model_cnn.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('best_model_cnn.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/200\n",
      "1400/1400 [==============================] - 0s 293us/step - loss: 223.2135 - accuracy: 0.2450 - val_loss: 1.3977 - val_accuracy: 0.2317\n",
      "Epoch 2/200\n",
      " 800/1400 [================>.............] - ETA: 0s - loss: 1.3908 - accuracy: 0.2375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 0s 137us/step - loss: 1.3895 - accuracy: 0.2464 - val_loss: 1.3971 - val_accuracy: 0.2517\n",
      "Epoch 3/200\n",
      "1400/1400 [==============================] - 0s 98us/step - loss: 1.3970 - accuracy: 0.2614 - val_loss: 1.4038 - val_accuracy: 0.2317\n",
      "Epoch 4/200\n",
      "1400/1400 [==============================] - 0s 120us/step - loss: 1.3878 - accuracy: 0.2771 - val_loss: 1.3895 - val_accuracy: 0.2617\n",
      "Epoch 5/200\n",
      "1400/1400 [==============================] - 0s 214us/step - loss: 1.3924 - accuracy: 0.2357 - val_loss: 1.3968 - val_accuracy: 0.2317\n",
      "Epoch 6/200\n",
      "1400/1400 [==============================] - 0s 239us/step - loss: 1.3912 - accuracy: 0.2464 - val_loss: 1.3926 - val_accuracy: 0.2550\n",
      "Epoch 7/200\n",
      "1400/1400 [==============================] - 0s 156us/step - loss: 1.3937 - accuracy: 0.2393 - val_loss: 1.3932 - val_accuracy: 0.2550\n",
      "Epoch 8/200\n",
      "1400/1400 [==============================] - 0s 82us/step - loss: 1.3919 - accuracy: 0.2493 - val_loss: 1.3862 - val_accuracy: 0.2550\n",
      "Epoch 9/200\n",
      "1400/1400 [==============================] - 0s 76us/step - loss: 1.3906 - accuracy: 0.2621 - val_loss: 1.3940 - val_accuracy: 0.2317\n",
      "Epoch 10/200\n",
      "1400/1400 [==============================] - 0s 68us/step - loss: 1.3914 - accuracy: 0.2493 - val_loss: 1.3858 - val_accuracy: 0.2617\n",
      "Epoch 11/200\n",
      "1400/1400 [==============================] - 0s 72us/step - loss: 1.3879 - accuracy: 0.2514 - val_loss: 1.3945 - val_accuracy: 0.2317\n",
      "Epoch 12/200\n",
      "1400/1400 [==============================] - 0s 100us/step - loss: 1.3897 - accuracy: 0.2464 - val_loss: 1.3973 - val_accuracy: 0.2617\n",
      "Epoch 13/200\n",
      "1400/1400 [==============================] - 0s 76us/step - loss: 1.3933 - accuracy: 0.2486 - val_loss: 1.3961 - val_accuracy: 0.2617\n",
      "Epoch 14/200\n",
      "1400/1400 [==============================] - 0s 86us/step - loss: 1.3923 - accuracy: 0.2329 - val_loss: 1.3920 - val_accuracy: 0.2617\n",
      "Epoch 15/200\n",
      "1400/1400 [==============================] - 0s 80us/step - loss: 1.3964 - accuracy: 0.2364 - val_loss: 1.3891 - val_accuracy: 0.2517\n",
      "Epoch 16/200\n",
      "1400/1400 [==============================] - 0s 95us/step - loss: 1.3939 - accuracy: 0.2486 - val_loss: 1.3938 - val_accuracy: 0.2517\n",
      "Epoch 17/200\n",
      "1400/1400 [==============================] - 0s 68us/step - loss: 1.3934 - accuracy: 0.2457 - val_loss: 1.3876 - val_accuracy: 0.2517\n",
      "Epoch 18/200\n",
      "1400/1400 [==============================] - 0s 85us/step - loss: 1.3937 - accuracy: 0.2421 - val_loss: 1.3965 - val_accuracy: 0.2317\n",
      "Epoch 19/200\n",
      "1400/1400 [==============================] - 0s 84us/step - loss: 1.3931 - accuracy: 0.2414 - val_loss: 1.3908 - val_accuracy: 0.2550\n",
      "Epoch 20/200\n",
      "1400/1400 [==============================] - 0s 80us/step - loss: 1.3995 - accuracy: 0.2450 - val_loss: 1.3861 - val_accuracy: 0.2550\n",
      "Epoch 21/200\n",
      "1400/1400 [==============================] - 0s 79us/step - loss: 1.3912 - accuracy: 0.2507 - val_loss: 1.3874 - val_accuracy: 0.2617\n",
      "Epoch 22/200\n",
      "1400/1400 [==============================] - 0s 83us/step - loss: 1.3937 - accuracy: 0.2393 - val_loss: 1.3989 - val_accuracy: 0.2317\n",
      "Epoch 23/200\n",
      "1400/1400 [==============================] - 0s 66us/step - loss: 1.3909 - accuracy: 0.2564 - val_loss: 1.3992 - val_accuracy: 0.2317\n",
      "Epoch 24/200\n",
      "1400/1400 [==============================] - 0s 67us/step - loss: 1.3915 - accuracy: 0.2593 - val_loss: 1.3970 - val_accuracy: 0.2317\n",
      "Epoch 25/200\n",
      "1400/1400 [==============================] - 0s 66us/step - loss: 1.3908 - accuracy: 0.2479 - val_loss: 1.3886 - val_accuracy: 0.2517\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model_cnn.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=1, callbacks=[es, mc])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "#saved_model = load_model('best_model_cnn.h5')\n",
    "saved_model = model_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.249, Test: 0.252\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = saved_model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 343   0   0]\n",
      " [  0 349   0   0]\n",
      " [  0 347   0   0]\n",
      " [  0 361   0   0]]\n",
      "0.24928571428571428\n",
      "[[  0 157   0   0]\n",
      " [  0 151   0   0]\n",
      " [  0 153   0   0]\n",
      " [  0 139   0   0]]\n",
      "0.25166666666666665\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "train_predicted=saved_model.predict(trainX)\n",
    "test_predicted=saved_model.predict(testX)\n",
    "\n",
    "#Confusion Matrix for Training\n",
    "from sklearn import metrics\n",
    "confusion = metrics.confusion_matrix(trainy.argmax(axis=1), train_predicted.argmax(axis=1))\n",
    "print(confusion)\n",
    "\n",
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(trainy.argmax(axis=1), train_predicted.argmax(axis=1)))\n",
    "\n",
    "#Confusion Matrix for Testing\n",
    "from sklearn import metrics\n",
    "confusion1 = metrics.confusion_matrix(testy.argmax(axis=1), test_predicted.argmax(axis=1))\n",
    "print(confusion1)\n",
    "\n",
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(testy.argmax(axis=1), test_predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0.]\n",
      "[1. 0. 1. 1.]\n",
      "[0.73833333 0.25166667 0.745      0.76833333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved deo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\ved deo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\ved deo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "FP = confusion1.sum(axis=0) - np.diag(confusion1)  \n",
    "FN = confusion1.sum(axis=1) - np.diag(confusion1)\n",
    "TP = np.diag(confusion1)\n",
    "TN = confusion1.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(TPR)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "print(TNR)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Regularization Parameter + Drop Out + ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_cnn_adm=Sequential()\n",
    "model_cnn_adm.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu',kernel_regularizer=regularizers.l1(0.05)))\n",
    "model_cnn_adm.add(MaxPooling1D(pool_size=2))\n",
    "model_cnn_adm.add(Flatten())\n",
    "model_cnn_adm.add(Dropout(0.6, noise_shape=None, seed=None))\n",
    "model_cnn_adm.add(Dense(250, activation='relu'))\n",
    "model_cnn_adm.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Model\n",
    "model_cnn_adm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('best_model_cnn_reg.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/200\n",
      "1400/1400 [==============================] - 0s 190us/step - loss: 18.6344 - accuracy: 0.2436 - val_loss: 8.0984 - val_accuracy: 0.2667\n",
      "Epoch 2/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 10.3391 - accuracy: 0.2764 - val_loss: 5.1312 - val_accuracy: 0.2517\n",
      "Epoch 3/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 7.4939 - accuracy: 0.2571 - val_loss: 4.6295 - val_accuracy: 0.2450\n",
      "Epoch 4/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 7.0890 - accuracy: 0.2743 - val_loss: 5.4903 - val_accuracy: 0.2317\n",
      "Epoch 5/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 7.3386 - accuracy: 0.2707 - val_loss: 4.6145 - val_accuracy: 0.2333\n",
      "Epoch 6/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 6.3124 - accuracy: 0.3071 - val_loss: 3.2699 - val_accuracy: 0.2967\n",
      "Epoch 7/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 5.0890 - accuracy: 0.3529 - val_loss: 2.3267 - val_accuracy: 0.4800\n",
      "Epoch 8/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 3.7739 - accuracy: 0.3743 - val_loss: 1.9761 - val_accuracy: 0.5800\n",
      "Epoch 9/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 3.3965 - accuracy: 0.4057 - val_loss: 2.0111 - val_accuracy: 0.7300\n",
      "Epoch 10/200\n",
      "1024/1400 [====================>.........] - ETA: 0s - loss: 3.4621 - accuracy: 0.4355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ved deo\\Anaconda3\\envs\\deep\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 0s 24us/step - loss: 3.4540 - accuracy: 0.4257 - val_loss: 2.0071 - val_accuracy: 0.7100\n",
      "Epoch 11/200\n",
      "1400/1400 [==============================] - 0s 33us/step - loss: 3.3742 - accuracy: 0.4421 - val_loss: 1.6897 - val_accuracy: 0.7383\n",
      "Epoch 12/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 2.6629 - accuracy: 0.4664 - val_loss: 1.3618 - val_accuracy: 0.7433\n",
      "Epoch 13/200\n",
      "1400/1400 [==============================] - 0s 13us/step - loss: 2.3090 - accuracy: 0.5114 - val_loss: 1.3399 - val_accuracy: 0.6433\n",
      "Epoch 14/200\n",
      "1400/1400 [==============================] - 0s 18us/step - loss: 2.3036 - accuracy: 0.5021 - val_loss: 1.4855 - val_accuracy: 0.4950\n",
      "Epoch 15/200\n",
      "1400/1400 [==============================] - 0s 17us/step - loss: 2.2576 - accuracy: 0.5207 - val_loss: 1.5625 - val_accuracy: 0.5050\n",
      "Epoch 16/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 2.1263 - accuracy: 0.5393 - val_loss: 1.5377 - val_accuracy: 0.5683\n",
      "Epoch 17/200\n",
      "1400/1400 [==============================] - 0s 25us/step - loss: 1.8655 - accuracy: 0.5807 - val_loss: 1.3948 - val_accuracy: 0.7050\n",
      "Epoch 18/200\n",
      "1400/1400 [==============================] - 0s 21us/step - loss: 1.7909 - accuracy: 0.5929 - val_loss: 1.2653 - val_accuracy: 0.7433\n",
      "Epoch 19/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 1.7005 - accuracy: 0.6150 - val_loss: 1.1849 - val_accuracy: 0.7433\n",
      "Epoch 20/200\n",
      "1400/1400 [==============================] - 0s 17us/step - loss: 1.6431 - accuracy: 0.6186 - val_loss: 1.0982 - val_accuracy: 0.7433\n",
      "Epoch 21/200\n",
      "1400/1400 [==============================] - 0s 32us/step - loss: 1.6349 - accuracy: 0.6043 - val_loss: 1.0492 - val_accuracy: 0.7500\n",
      "Epoch 22/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 1.4547 - accuracy: 0.6500 - val_loss: 1.0805 - val_accuracy: 0.7450\n",
      "Epoch 23/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 1.4486 - accuracy: 0.6607 - val_loss: 1.1602 - val_accuracy: 0.7167\n",
      "Epoch 24/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 1.3711 - accuracy: 0.6764 - val_loss: 1.1959 - val_accuracy: 0.7083\n",
      "Epoch 25/200\n",
      "1400/1400 [==============================] - 0s 15us/step - loss: 1.4209 - accuracy: 0.6507 - val_loss: 1.1264 - val_accuracy: 0.7267\n",
      "Epoch 26/200\n",
      "1400/1400 [==============================] - 0s 21us/step - loss: 1.3315 - accuracy: 0.6886 - val_loss: 1.0165 - val_accuracy: 0.7500\n",
      "Epoch 27/200\n",
      "1400/1400 [==============================] - 0s 18us/step - loss: 1.2973 - accuracy: 0.6971 - val_loss: 0.9519 - val_accuracy: 0.7783\n",
      "Epoch 28/200\n",
      "1400/1400 [==============================] - 0s 27us/step - loss: 1.2373 - accuracy: 0.7093 - val_loss: 0.9523 - val_accuracy: 0.7767\n",
      "Epoch 29/200\n",
      "1400/1400 [==============================] - 0s 13us/step - loss: 1.2532 - accuracy: 0.7193 - val_loss: 0.9933 - val_accuracy: 0.7500\n",
      "Epoch 30/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 1.1691 - accuracy: 0.7343 - val_loss: 1.0458 - val_accuracy: 0.7400\n",
      "Epoch 31/200\n",
      "1400/1400 [==============================] - 0s 31us/step - loss: 1.1961 - accuracy: 0.7193 - val_loss: 1.0888 - val_accuracy: 0.7333\n",
      "Epoch 32/200\n",
      "1400/1400 [==============================] - 0s 15us/step - loss: 1.1320 - accuracy: 0.7443 - val_loss: 1.0801 - val_accuracy: 0.7233\n",
      "Epoch 33/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 1.1363 - accuracy: 0.7386 - val_loss: 1.0244 - val_accuracy: 0.7367\n",
      "Epoch 34/200\n",
      "1400/1400 [==============================] - 0s 13us/step - loss: 1.0784 - accuracy: 0.7571 - val_loss: 0.9604 - val_accuracy: 0.7683\n",
      "Epoch 35/200\n",
      "1400/1400 [==============================] - 0s 24us/step - loss: 1.0864 - accuracy: 0.7593 - val_loss: 0.9443 - val_accuracy: 0.7783\n",
      "Epoch 36/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 1.0719 - accuracy: 0.7571 - val_loss: 0.9631 - val_accuracy: 0.7550\n",
      "Epoch 37/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 1.0653 - accuracy: 0.7714 - val_loss: 0.9828 - val_accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 1.0607 - accuracy: 0.7593 - val_loss: 0.9975 - val_accuracy: 0.7433\n",
      "Epoch 39/200\n",
      "1400/1400 [==============================] - 0s 30us/step - loss: 1.0373 - accuracy: 0.7736 - val_loss: 1.0031 - val_accuracy: 0.7417\n",
      "Epoch 40/200\n",
      "1400/1400 [==============================] - 0s 43us/step - loss: 1.0131 - accuracy: 0.7814 - val_loss: 1.0050 - val_accuracy: 0.7417\n",
      "Epoch 41/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 0.9968 - accuracy: 0.7807 - val_loss: 0.9870 - val_accuracy: 0.7433\n",
      "Epoch 42/200\n",
      "1400/1400 [==============================] - 0s 28us/step - loss: 1.0357 - accuracy: 0.7593 - val_loss: 0.9676 - val_accuracy: 0.7467\n",
      "Epoch 43/200\n",
      "1400/1400 [==============================] - 0s 21us/step - loss: 0.9912 - accuracy: 0.7921 - val_loss: 0.9455 - val_accuracy: 0.7583\n",
      "Epoch 44/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 1.0105 - accuracy: 0.7700 - val_loss: 0.9231 - val_accuracy: 0.7783\n",
      "Epoch 45/200\n",
      "1400/1400 [==============================] - 0s 24us/step - loss: 0.9965 - accuracy: 0.7786 - val_loss: 0.9302 - val_accuracy: 0.7667\n",
      "Epoch 46/200\n",
      "1400/1400 [==============================] - 0s 19us/step - loss: 0.9494 - accuracy: 0.8093 - val_loss: 0.9652 - val_accuracy: 0.7483\n",
      "Epoch 47/200\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.9561 - accuracy: 0.7886 - val_loss: 0.9860 - val_accuracy: 0.7417\n",
      "Epoch 48/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 0.9100 - accuracy: 0.8086 - val_loss: 0.9696 - val_accuracy: 0.7467\n",
      "Epoch 49/200\n",
      "1400/1400 [==============================] - 0s 17us/step - loss: 0.9212 - accuracy: 0.8164 - val_loss: 0.9445 - val_accuracy: 0.7600\n",
      "Epoch 50/200\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.9085 - accuracy: 0.8150 - val_loss: 0.9335 - val_accuracy: 0.7617\n",
      "Epoch 51/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 0.8787 - accuracy: 0.8171 - val_loss: 0.9233 - val_accuracy: 0.7700\n",
      "Epoch 52/200\n",
      "1400/1400 [==============================] - 0s 21us/step - loss: 0.8965 - accuracy: 0.8157 - val_loss: 0.9145 - val_accuracy: 0.7767\n",
      "Epoch 53/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 0.9017 - accuracy: 0.8121 - val_loss: 0.9156 - val_accuracy: 0.7767\n",
      "Epoch 54/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 0.8676 - accuracy: 0.8264 - val_loss: 0.9007 - val_accuracy: 0.7883\n",
      "Epoch 55/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 0.8918 - accuracy: 0.8114 - val_loss: 0.8783 - val_accuracy: 0.8000\n",
      "Epoch 56/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 0.8730 - accuracy: 0.8207 - val_loss: 0.8579 - val_accuracy: 0.8217\n",
      "Epoch 57/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 0.8917 - accuracy: 0.8164 - val_loss: 0.8701 - val_accuracy: 0.8133\n",
      "Epoch 58/200\n",
      "1400/1400 [==============================] - 0s 19us/step - loss: 0.8656 - accuracy: 0.8257 - val_loss: 0.8942 - val_accuracy: 0.7883\n",
      "Epoch 59/200\n",
      "1400/1400 [==============================] - 0s 27us/step - loss: 0.8441 - accuracy: 0.8393 - val_loss: 0.8992 - val_accuracy: 0.7817\n",
      "Epoch 60/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 0.8375 - accuracy: 0.8357 - val_loss: 0.8969 - val_accuracy: 0.7867\n",
      "Epoch 61/200\n",
      "1400/1400 [==============================] - 0s 13us/step - loss: 0.8361 - accuracy: 0.8271 - val_loss: 0.8950 - val_accuracy: 0.7917\n",
      "Epoch 62/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 0.8484 - accuracy: 0.8271 - val_loss: 0.8965 - val_accuracy: 0.7883\n",
      "Epoch 63/200\n",
      "1400/1400 [==============================] - 0s 15us/step - loss: 0.8410 - accuracy: 0.8321 - val_loss: 0.8850 - val_accuracy: 0.7933\n",
      "Epoch 64/200\n",
      "1400/1400 [==============================] - 0s 24us/step - loss: 0.8234 - accuracy: 0.8343 - val_loss: 0.8722 - val_accuracy: 0.8050\n",
      "Epoch 65/200\n",
      "1400/1400 [==============================] - 0s 18us/step - loss: 0.8161 - accuracy: 0.8357 - val_loss: 0.8642 - val_accuracy: 0.8133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      "1400/1400 [==============================] - 0s 21us/step - loss: 0.7886 - accuracy: 0.8600 - val_loss: 0.8696 - val_accuracy: 0.8067\n",
      "Epoch 67/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.8163 - accuracy: 0.8436 - val_loss: 0.8794 - val_accuracy: 0.8050\n",
      "Epoch 68/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.8163 - accuracy: 0.8329 - val_loss: 0.8847 - val_accuracy: 0.8017\n",
      "Epoch 69/200\n",
      "1400/1400 [==============================] - 0s 17us/step - loss: 0.7984 - accuracy: 0.8500 - val_loss: 0.8819 - val_accuracy: 0.8017\n",
      "Epoch 70/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.8120 - accuracy: 0.8429 - val_loss: 0.8594 - val_accuracy: 0.8183\n",
      "Epoch 71/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 0.7892 - accuracy: 0.8436 - val_loss: 0.8323 - val_accuracy: 0.8283\n",
      "Epoch 72/200\n",
      "1400/1400 [==============================] - 0s 20us/step - loss: 0.7663 - accuracy: 0.8564 - val_loss: 0.8183 - val_accuracy: 0.8267\n",
      "Epoch 73/200\n",
      "1400/1400 [==============================] - 0s 29us/step - loss: 0.7532 - accuracy: 0.8621 - val_loss: 0.8078 - val_accuracy: 0.8350\n",
      "Epoch 74/200\n",
      "1400/1400 [==============================] - 0s 52us/step - loss: 0.7550 - accuracy: 0.8586 - val_loss: 0.8057 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 0.7468 - accuracy: 0.8664 - val_loss: 0.8240 - val_accuracy: 0.8150\n",
      "Epoch 76/200\n",
      "1400/1400 [==============================] - 0s 20us/step - loss: 0.8069 - accuracy: 0.8479 - val_loss: 0.8539 - val_accuracy: 0.7883\n",
      "Epoch 77/200\n",
      "1400/1400 [==============================] - 0s 38us/step - loss: 0.7704 - accuracy: 0.8436 - val_loss: 0.8680 - val_accuracy: 0.7783\n",
      "Epoch 78/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 0.7364 - accuracy: 0.8607 - val_loss: 0.8587 - val_accuracy: 0.7917\n",
      "Epoch 79/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 0.7836 - accuracy: 0.8464 - val_loss: 0.8414 - val_accuracy: 0.8100\n",
      "Epoch 80/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 0.7583 - accuracy: 0.8614 - val_loss: 0.8190 - val_accuracy: 0.8233\n",
      "Epoch 81/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 0.7555 - accuracy: 0.8579 - val_loss: 0.8083 - val_accuracy: 0.8283\n",
      "Epoch 82/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 0.7501 - accuracy: 0.8729 - val_loss: 0.8025 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.7473 - accuracy: 0.8529 - val_loss: 0.8084 - val_accuracy: 0.8267\n",
      "Epoch 84/200\n",
      "1400/1400 [==============================] - 0s 24us/step - loss: 0.7241 - accuracy: 0.8629 - val_loss: 0.8181 - val_accuracy: 0.8133\n",
      "Epoch 85/200\n",
      "1400/1400 [==============================] - 0s 13us/step - loss: 0.7506 - accuracy: 0.8571 - val_loss: 0.8051 - val_accuracy: 0.8200\n",
      "Epoch 86/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.7260 - accuracy: 0.8643 - val_loss: 0.7941 - val_accuracy: 0.8233\n",
      "Epoch 87/200\n",
      "1400/1400 [==============================] - 0s 22us/step - loss: 0.7391 - accuracy: 0.8607 - val_loss: 0.8128 - val_accuracy: 0.8100\n",
      "Epoch 88/200\n",
      "1400/1400 [==============================] - 0s 43us/step - loss: 0.6927 - accuracy: 0.8729 - val_loss: 0.8236 - val_accuracy: 0.8050\n",
      "Epoch 89/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 0.7203 - accuracy: 0.8671 - val_loss: 0.7993 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 0.7233 - accuracy: 0.8721 - val_loss: 0.7719 - val_accuracy: 0.8500\n",
      "Epoch 91/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 0.6809 - accuracy: 0.8814 - val_loss: 0.7620 - val_accuracy: 0.8533\n",
      "Epoch 92/200\n",
      "1400/1400 [==============================] - 0s 37us/step - loss: 0.7061 - accuracy: 0.8729 - val_loss: 0.7602 - val_accuracy: 0.8450\n",
      "Epoch 93/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 0.7212 - accuracy: 0.8729 - val_loss: 0.7623 - val_accuracy: 0.8467\n",
      "Epoch 94/200\n",
      "1400/1400 [==============================] - 0s 15us/step - loss: 0.7006 - accuracy: 0.8629 - val_loss: 0.7769 - val_accuracy: 0.8400\n",
      "Epoch 95/200\n",
      "1400/1400 [==============================] - 0s 40us/step - loss: 0.7020 - accuracy: 0.8707 - val_loss: 0.7854 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "1400/1400 [==============================] - 0s 24us/step - loss: 0.6998 - accuracy: 0.8771 - val_loss: 0.7913 - val_accuracy: 0.8267\n",
      "Epoch 97/200\n",
      "1400/1400 [==============================] - 0s 15us/step - loss: 0.6914 - accuracy: 0.8857 - val_loss: 0.7805 - val_accuracy: 0.8283\n",
      "Epoch 98/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 0.7064 - accuracy: 0.8686 - val_loss: 0.7541 - val_accuracy: 0.8417\n",
      "Epoch 99/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6765 - accuracy: 0.8771 - val_loss: 0.7295 - val_accuracy: 0.8633\n",
      "Epoch 100/200\n",
      "1400/1400 [==============================] - 0s 21us/step - loss: 0.7054 - accuracy: 0.8693 - val_loss: 0.7279 - val_accuracy: 0.8617\n",
      "Epoch 101/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6869 - accuracy: 0.8843 - val_loss: 0.7306 - val_accuracy: 0.8567\n",
      "Epoch 102/200\n",
      "1400/1400 [==============================] - 0s 10us/step - loss: 0.6953 - accuracy: 0.8714 - val_loss: 0.7553 - val_accuracy: 0.8483\n",
      "Epoch 103/200\n",
      "1400/1400 [==============================] - 0s 9us/step - loss: 0.6837 - accuracy: 0.8793 - val_loss: 0.7661 - val_accuracy: 0.8433\n",
      "Epoch 104/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6935 - accuracy: 0.8729 - val_loss: 0.7678 - val_accuracy: 0.8450\n",
      "Epoch 105/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 0.6938 - accuracy: 0.8771 - val_loss: 0.7609 - val_accuracy: 0.8450\n",
      "Epoch 106/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6684 - accuracy: 0.8800 - val_loss: 0.7492 - val_accuracy: 0.8467\n",
      "Epoch 107/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 0.6422 - accuracy: 0.8921 - val_loss: 0.7081 - val_accuracy: 0.8667\n",
      "Epoch 108/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 0.6702 - accuracy: 0.8793 - val_loss: 0.7034 - val_accuracy: 0.8717\n",
      "Epoch 109/200\n",
      "1400/1400 [==============================] - 0s 16us/step - loss: 0.6714 - accuracy: 0.8800 - val_loss: 0.7387 - val_accuracy: 0.8517\n",
      "Epoch 110/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 0.6505 - accuracy: 0.8871 - val_loss: 0.7398 - val_accuracy: 0.8517\n",
      "Epoch 111/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 0.6500 - accuracy: 0.8957 - val_loss: 0.7251 - val_accuracy: 0.8583\n",
      "Epoch 112/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6613 - accuracy: 0.8900 - val_loss: 0.7024 - val_accuracy: 0.8683\n",
      "Epoch 113/200\n",
      "1400/1400 [==============================] - 0s 12us/step - loss: 0.6493 - accuracy: 0.8893 - val_loss: 0.6650 - val_accuracy: 0.8900\n",
      "Epoch 114/200\n",
      "1400/1400 [==============================] - 0s 22us/step - loss: 0.6514 - accuracy: 0.8836 - val_loss: 0.6903 - val_accuracy: 0.8783\n",
      "Epoch 115/200\n",
      "1400/1400 [==============================] - 0s 39us/step - loss: 0.6391 - accuracy: 0.8821 - val_loss: 0.7424 - val_accuracy: 0.8467\n",
      "Epoch 116/200\n",
      "1400/1400 [==============================] - 0s 24us/step - loss: 0.6481 - accuracy: 0.8936 - val_loss: 0.7332 - val_accuracy: 0.8533\n",
      "Epoch 117/200\n",
      "1400/1400 [==============================] - 0s 43us/step - loss: 0.6423 - accuracy: 0.8957 - val_loss: 0.6994 - val_accuracy: 0.8783\n",
      "Epoch 118/200\n",
      "1400/1400 [==============================] - 0s 23us/step - loss: 0.6365 - accuracy: 0.8993 - val_loss: 0.6846 - val_accuracy: 0.8833\n",
      "Epoch 119/200\n",
      "1400/1400 [==============================] - 0s 24us/step - loss: 0.6480 - accuracy: 0.8921 - val_loss: 0.7020 - val_accuracy: 0.8700\n",
      "Epoch 120/200\n",
      "1400/1400 [==============================] - 0s 21us/step - loss: 0.6246 - accuracy: 0.9057 - val_loss: 0.7273 - val_accuracy: 0.8517\n",
      "Epoch 121/200\n",
      "1400/1400 [==============================] - 0s 23us/step - loss: 0.6262 - accuracy: 0.8986 - val_loss: 0.7352 - val_accuracy: 0.8467\n",
      "Epoch 122/200\n",
      "1400/1400 [==============================] - 0s 24us/step - loss: 0.6252 - accuracy: 0.9029 - val_loss: 0.7081 - val_accuracy: 0.8650\n",
      "Epoch 123/200\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.6355 - accuracy: 0.8914 - val_loss: 0.6790 - val_accuracy: 0.8817\n",
      "Epoch 124/200\n",
      "1400/1400 [==============================] - 0s 73us/step - loss: 0.6200 - accuracy: 0.8979 - val_loss: 0.6642 - val_accuracy: 0.8933\n",
      "Epoch 125/200\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.6272 - accuracy: 0.8971 - val_loss: 0.6843 - val_accuracy: 0.8767\n",
      "Epoch 126/200\n",
      "1400/1400 [==============================] - 0s 20us/step - loss: 0.6211 - accuracy: 0.8943 - val_loss: 0.7152 - val_accuracy: 0.8633\n",
      "Epoch 127/200\n",
      "1400/1400 [==============================] - 0s 69us/step - loss: 0.6299 - accuracy: 0.8971 - val_loss: 0.7091 - val_accuracy: 0.8650\n",
      "Epoch 128/200\n",
      "1400/1400 [==============================] - 0s 21us/step - loss: 0.6247 - accuracy: 0.8893 - val_loss: 0.6726 - val_accuracy: 0.8817\n",
      "Epoch 129/200\n",
      "1400/1400 [==============================] - 0s 26us/step - loss: 0.6177 - accuracy: 0.9007 - val_loss: 0.6393 - val_accuracy: 0.8967\n",
      "Epoch 130/200\n",
      "1400/1400 [==============================] - 0s 14us/step - loss: 0.6351 - accuracy: 0.8857 - val_loss: 0.6341 - val_accuracy: 0.9033\n",
      "Epoch 131/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6385 - accuracy: 0.8871 - val_loss: 0.6722 - val_accuracy: 0.8917\n",
      "Epoch 132/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6437 - accuracy: 0.8814 - val_loss: 0.7295 - val_accuracy: 0.8567\n",
      "Epoch 133/200\n",
      "1400/1400 [==============================] - 0s 18us/step - loss: 0.6351 - accuracy: 0.8950 - val_loss: 0.7157 - val_accuracy: 0.8617\n",
      "Epoch 134/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6086 - accuracy: 0.9057 - val_loss: 0.6755 - val_accuracy: 0.8833\n",
      "Epoch 135/200\n",
      "1400/1400 [==============================] - 0s 13us/step - loss: 0.6133 - accuracy: 0.9050 - val_loss: 0.6545 - val_accuracy: 0.8933\n",
      "Epoch 136/200\n",
      "1400/1400 [==============================] - 0s 15us/step - loss: 0.6016 - accuracy: 0.9036 - val_loss: 0.6488 - val_accuracy: 0.8933\n",
      "Epoch 137/200\n",
      "1400/1400 [==============================] - 0s 24us/step - loss: 0.6263 - accuracy: 0.8907 - val_loss: 0.6563 - val_accuracy: 0.8883\n",
      "Epoch 138/200\n",
      "1400/1400 [==============================] - 0s 23us/step - loss: 0.6202 - accuracy: 0.8929 - val_loss: 0.6626 - val_accuracy: 0.8833\n",
      "Epoch 139/200\n",
      "1400/1400 [==============================] - 0s 24us/step - loss: 0.6113 - accuracy: 0.9093 - val_loss: 0.6634 - val_accuracy: 0.8850\n",
      "Epoch 140/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5927 - accuracy: 0.9171 - val_loss: 0.6792 - val_accuracy: 0.8800\n",
      "Epoch 141/200\n",
      "1400/1400 [==============================] - 0s 10us/step - loss: 0.6019 - accuracy: 0.9071 - val_loss: 0.6851 - val_accuracy: 0.8783\n",
      "Epoch 142/200\n",
      "1400/1400 [==============================] - 0s 10us/step - loss: 0.6119 - accuracy: 0.8986 - val_loss: 0.6757 - val_accuracy: 0.8833\n",
      "Epoch 143/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5844 - accuracy: 0.9057 - val_loss: 0.6572 - val_accuracy: 0.8950\n",
      "Epoch 144/200\n",
      "1400/1400 [==============================] - 0s 20us/step - loss: 0.6068 - accuracy: 0.8964 - val_loss: 0.6251 - val_accuracy: 0.9017\n",
      "Epoch 145/200\n",
      "1400/1400 [==============================] - 0s 10us/step - loss: 0.5995 - accuracy: 0.8957 - val_loss: 0.6347 - val_accuracy: 0.9033\n",
      "Epoch 146/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6025 - accuracy: 0.9093 - val_loss: 0.6342 - val_accuracy: 0.9033\n",
      "Epoch 147/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5963 - accuracy: 0.9064 - val_loss: 0.6414 - val_accuracy: 0.8983\n",
      "Epoch 148/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6262 - accuracy: 0.8936 - val_loss: 0.6555 - val_accuracy: 0.8867\n",
      "Epoch 149/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6045 - accuracy: 0.9021 - val_loss: 0.6688 - val_accuracy: 0.8817\n",
      "Epoch 150/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6073 - accuracy: 0.9000 - val_loss: 0.6410 - val_accuracy: 0.8917\n",
      "Epoch 151/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5924 - accuracy: 0.9036 - val_loss: 0.6059 - val_accuracy: 0.9083\n",
      "Epoch 152/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5868 - accuracy: 0.9071 - val_loss: 0.6136 - val_accuracy: 0.9050\n",
      "Epoch 153/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5910 - accuracy: 0.9014 - val_loss: 0.6458 - val_accuracy: 0.8950\n",
      "Epoch 154/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5886 - accuracy: 0.9093 - val_loss: 0.6726 - val_accuracy: 0.8783\n",
      "Epoch 155/200\n",
      "1400/1400 [==============================] - 0s 31us/step - loss: 0.5852 - accuracy: 0.9150 - val_loss: 0.6747 - val_accuracy: 0.8733\n",
      "Epoch 156/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5996 - accuracy: 0.8986 - val_loss: 0.6757 - val_accuracy: 0.8733\n",
      "Epoch 157/200\n",
      "1400/1400 [==============================] - 0s 10us/step - loss: 0.5972 - accuracy: 0.9057 - val_loss: 0.6711 - val_accuracy: 0.8767\n",
      "Epoch 158/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5984 - accuracy: 0.9100 - val_loss: 0.6495 - val_accuracy: 0.8933\n",
      "Epoch 159/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.6069 - accuracy: 0.9057 - val_loss: 0.6411 - val_accuracy: 0.8933\n",
      "Epoch 160/200\n",
      "1400/1400 [==============================] - 0s 17us/step - loss: 0.5934 - accuracy: 0.9057 - val_loss: 0.6428 - val_accuracy: 0.8950\n",
      "Epoch 161/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5877 - accuracy: 0.9036 - val_loss: 0.6494 - val_accuracy: 0.8867\n",
      "Epoch 162/200\n",
      "1400/1400 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.91 - 0s 11us/step - loss: 0.5929 - accuracy: 0.9086 - val_loss: 0.6592 - val_accuracy: 0.8883\n",
      "Epoch 163/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5886 - accuracy: 0.9014 - val_loss: 0.6624 - val_accuracy: 0.8783\n",
      "Epoch 164/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5898 - accuracy: 0.9100 - val_loss: 0.6340 - val_accuracy: 0.8950\n",
      "Epoch 165/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5846 - accuracy: 0.9093 - val_loss: 0.6126 - val_accuracy: 0.9000\n",
      "Epoch 166/200\n",
      "1400/1400 [==============================] - 0s 11us/step - loss: 0.5819 - accuracy: 0.9029 - val_loss: 0.6211 - val_accuracy: 0.8967\n",
      "Epoch 00166: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model_cnn_adm.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=1, callbacks=[es, mc],batch_size=1024)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "#saved_model = load_model('best_model_cnn_reg.h5')\n",
    "saved_model = model_cnn_adm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.898, Test: 0.897\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = saved_model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[306   0   4  33]\n",
      " [  0 344   5   0]\n",
      " [  4  59 246  38]\n",
      " [  0   0   0 361]]\n",
      "0.8978571428571429\n",
      "[[140   0   0  17]\n",
      " [  0 151   0   0]\n",
      " [  2  24 108  19]\n",
      " [  0   0   0 139]]\n",
      "0.8966666666666666\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "train_predicted=saved_model.predict(trainX)\n",
    "test_predicted=saved_model.predict(testX)\n",
    "\n",
    "#Confusion Matrix for Training\n",
    "from sklearn import metrics\n",
    "confusion = metrics.confusion_matrix(trainy.argmax(axis=1), train_predicted.argmax(axis=1))\n",
    "print(confusion)\n",
    "\n",
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(trainy.argmax(axis=1), train_predicted.argmax(axis=1)))\n",
    "\n",
    "#Confusion Matrix for Testing\n",
    "from sklearn import metrics\n",
    "confusion1 = metrics.confusion_matrix(testy.argmax(axis=1), test_predicted.argmax(axis=1))\n",
    "print(confusion1)\n",
    "\n",
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(testy.argmax(axis=1), test_predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89171975 1.         0.70588235 1.        ]\n",
      "[0.99548533 0.94654788 1.         0.92190889]\n",
      "[0.96833333 0.96       0.925      0.94      ]\n"
     ]
    }
   ],
   "source": [
    "FP = confusion1.sum(axis=0) - np.diag(confusion1)  \n",
    "FN = confusion1.sum(axis=1) - np.diag(confusion1)\n",
    "TP = np.diag(confusion1)\n",
    "TN = confusion1.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(TPR)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "print(TNR)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
